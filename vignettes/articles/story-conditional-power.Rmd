---
title: "Conditional power under non-proportional hazards"
author: "Yujie Zhao, Shiyu Zhang, and Keaven M. Anderson"
output:
  rmarkdown::html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    number_sections: true
    highlight: "textmate"
    css: "custom.css"
bibliography: "gsDesign2.bib"
vignette: >
  %\VignetteIndexEntry{Conditional power under non-proportional hazards}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png"
)
options(width = 58)
```

```{r, message=FALSE, warning=FALSE}
# R packages for design and simulation
library(gsDesign)
library(gsDesign2)
library(simtrial)

# R packages for parallel computation
library(doFuture)
library(doRNG)

library(dplyr)
library(tibble)
library(gt)
library(tictoc)
```

# Example for consideration

Here we set up enrollment, failure and dropout rates along with assumptions for enrollment duration and times of analyses. We assume there are 3 analysis (2 interim analyses + 1 final analysis) conducted 12, 24, and 36 months after trial enrollment is opened. 

We assume there is a single stratum and enrollment targeted to last for 14 months. For the first 2 months, second 2 months, and the remaining months, the relative enrollment rates are 1:2:3. These rates will be updated by a constant multiple at the time of design as we will note below.

We assume a hazard ratio (HR) of 0.6. We also assume the the control time-to-event follows a piecewise exponential distribution with a median of 9 months.
```{r}
alpha <- 0.025
beta <- 0.1
ratio <- 1

# Enrollment
enroll_rate <- define_enroll_rate(
  duration = c(2, 2, 10),
  rate = (1:3) / 3)

# Failure and dropout
fail_rate <- define_fail_rate(
  duration = Inf, fail_rate = log(2) / 9,
  hr = 0.6, dropout_rate = .0001)

# IA and FA analysis time
analysis_time <- c(12, 24, 36)

# Randomization ratio
ratio <- 1
```

We now consider a group sequential design with bounds derived using spending functions. We target the interim analysis for 12 months and 24 months and the final analysis for 36 months. Spending for both efficacy and futility is based on the proportion of events expected at each analysis divided by the total expected events at the final analysis.

The original design is summarized below.
```{r}
upper <- gs_spending_bound
lower <- gs_b
upar <- list(sf = sfLDOF, total_spend = alpha)
lpar <- rep(-Inf, 3)

x <- gs_design_ahr(
  enroll_rate = enroll_rate, fail_rate = fail_rate,
  alpha = alpha, beta = beta, ratio = ratio,
  info_scale = "h0_h1_info",
  info_frac = NULL,
  analysis_time = c(12, 24, 36),
  upper = upper, upar = upar, test_upper = TRUE, 
  lower = lower, lpar = lpar, test_lower = FALSE,
  ) |> 
  to_integer()

x |> 
  summary() |>
  as_gt(title = "Original AHR design")
```
We provide a simulation below where observed events the IA and FA is same as planned. We also assume the protocol specifies that the full $\alpha$ will be spent at the final analysis even in a case like this when there is a shortfall of events versus the design plan. The observed IA1 data below (showing the first 6 rows only). Please note that, in practice, the column `treatment` is commonly blinded. 
```{r, echo=FALSE}
set.seed(123)

observed_data <- simtrial::sim_pw_surv(
  n = max(x$analysis$n),
  stratum = data.frame(stratum = "All", p = 1),
  block = c(rep("control", 2), rep("experimental", 2)),
  enroll_rate = x$enroll_rate,
  fail_rate = (fail_rate |> simtrial::to_sim_pw_surv())$fail_rate,
  dropout_rate = (fail_rate |> simtrial::to_sim_pw_surv())$dropout_rate)

observed_data |>
  head() |>
  gt()
```

With the IA1 blinded data observed, we can update the design as follows.
```{r}
observed_data_ia1 <- observed_data |> simtrial::cut_data_by_date(x$analysis$time[1])
observed_event_ia1 <- sum(observed_data_ia1$event)
planned_event_ia1 <- x$analysis$event[1]
planned_event_fa <- x$analysis$event[3]

xu <- gs_update_ahr(
  x = x,
  ustime = c(observed_event_ia1 / planned_event_fa, x$analysis$info_frac[2], 1),
  observed_data = list(observed_data_ia1, NULL, NULL))

xu |>
  summary() |>
  as_gt(title = "Updated AHR design")
```

# Conditional power from analytical formula

We focus on study designs that involve two treatment groups, and conduct $k$. For any analysis $i$, the statistical information under the null hypothesis is denoted as $\mathcal{I}_{i, H_0}$, and the information under the alternative hypothesis is denoted as $\mathcal{I}_{i, H_1}$. The information fraction at analysis $i$ is defined as $t_i = \mathcal{I}_{i, H_0} / \mathcal{I}_{k, H_0}$.

The conditional power of declare efficacy at the $j$-th analysis, given the Z-score of $i$-th analysis as $a$ is $\text{Pr}(Z_j > b ~|~ Z_i = a)$. Let's take $Z_i$ as the test statistic used is the Z-value version of the logrank test, and it has the following structure:

- $Z_1, Z_2, \ldots, Z_k$ follow a multivariate normal distribution;
- $E(Z_i) = \theta_i \sqrt{\mathcal I_{i, H_0}}$.
- $\text{Cov}(Z_i, Z_j \; | \; H_0) = \sqrt{\frac{t_i}{t_j}}$
  and
  $\text{Cov}(Z_i, Z_j \;|\; H_1) = \sqrt{\frac{t_i}{t_j}} \frac{\mathcal I_{i, H_0}}{\mathcal I_{i, H_1}}.$

We now re-write bounds and boundary crossing probabilities in terms of B-values, i.e., $B_i = \sqrt{t_i} Z_i$. we can rewrite the conditional power as
$$
\begin{eqnarray*}
    \text{Pr}(Z_j > b ~|~ Z_i = a) 
    & = &
    \text{Pr}(B_j - B_i + B_i > \sqrt{t_j}b ~|~ B_i = \sqrt{t_i}a) \\
    & = &  
    \text{Pr}(B_j - B_i + \sqrt{t_i}a > \sqrt{t_j}b ~|~ B_i = \sqrt{t_i}a) \\
    & = &
    \text{Pr}(B_j - B_i   > \sqrt{t_j}b - \sqrt{t_i}a ) 
\end{eqnarray*}
$$
The key to solve the above conditional power is the asymptotic distribution of $B_j - B_i$. As shown in @proschan2006statistical, the continuous form of the B-values $B(t)$ has the following structure:

- $B(t_1),B(t_2), . . .,B(t_k)$ have a multivariate normal distribution.
- $E(B(t)) = \theta_i \sqrt{t_i \;\mathcal I_{i, H_0}}$.
- $\text{Cov}(B(t_i),B(t_j)) = t_i$ under the null hypothesis and $\text{Cov}(B(t_i),B(t_j)) = t_i \frac{\mathcal I_{i, H_0}}{\mathcal I_{i, H_1}}$ under the alternative hypothesis, for any $1 \leq i \leq j \leq k$.

When the sample size is large, we get $B(t)$ as a standard Brownian motion, a random, continuous, but non-differentiable, function $B(t)$ satisfying the above 3 proprieties. In this paper, we consider a discrete version of the above Brownian motion formulation of @proschan2006statistical:

- $B_j - B_i$ follows univariate normal distribution.
- $E(B_j - B_i) = \theta_j \sqrt{t_j \;\mathcal I_{j, H_0}} - \theta_i \sqrt{t_i \;\mathcal I_{i, H_0}}$.
- $\text{Var}(B_j - B_i) = t_j - t_i$ under the null hypothesis and $\text{Var}(B_j - B_i) = t_j \frac{\mathcal I_{j, H_0}}{\mathcal I_{j, H_1}} - t_i \frac{\mathcal I_{i, H_0}}{\mathcal I_{i, H_1}}$ under the alternative hypothesis.

Under proportional hazard, the $\theta_i = \log(\text{HR})$ for any $1\leq i \leq k$, which is a constant over time. In this paper, we focus on non-proportional hazard, where the $\theta$ is time varying. To model the time varying pattern of $\theta$, we follow the piecewise model assumption in @zhao2023group and assume it is a piecewise constant, i.e., $\theta(t) = \theta_1 \mathbbm 1\{0 < t \leq t_1\} + \theta_2 \mathbbm 1\{t_1 < t \leq t_2\} + \ldots \theta_k \mathbbm 1\{t_{k-1} < t \leq t_k\}$.

Using the aforementioned foundational components, we can derive an analytical expression for the conditional power.

## Conditional error under null hypothesis

For any $i$, we have $\theta_i = 0$. The distribution of $B_j - B_i$ can be simplified into 
$$
  B_j - B_i \;|\; H_0  
  \sim
  N\left(0, t_j - t_i\right).
$$
This leads the conditional error as
$$
  \text{Pr}(Z_j > b ~|~ Z_i = a) 
  =
  1 - \Phi\left(\frac{\sqrt{t_j}b - \sqrt{t_i}a}{\sqrt{t_j - t_i}}\right),
$$
where $\Phi(\cdot)$ is the c.d.f of $N(0,1)$.

## Conditional power under alternative hypothesis.

Similar as our previous work in \cite{zhao2023group}, we assume the time-to-event rates are piecewise constant, i.e., in the $m$-th interval (total of $M$ intervals), it equals $\lambda_{1,m} \geq 0$ for the experimental arm and $\lambda_{0,m} \geq 0$ for the control arm. We constrain that, for each arm, at least one interval, we have positive hazards. 

Based on these assumed time-to-event rates, we can derive the average hazard ratio following @zhao2023group:
$$
  \theta_i
  = 
  \sum_{m=1}^M w_m
  \log(\lambda_{1,m} /\lambda_{0,m}),
$$
where $w_m$ is an inverse variance weight, i.e.,
$w_m = \left( \frac{1}{1/d_{0,m}+1/d_{1,m}} \right)^{-1} \bigg/ \sum_{i=1}^M \left( \frac{1}{1/d_{0,i}+1/d_{1,i}} \right)^{-1},$
with $d_{j, m}$ is the number of expected events of group $j$ before analysis $i$, in the $m$-th interval, 

Under the alternative hypothesis, the distribution of $B_j - B_i$ is
$$
\begin{equation*}
  B_j - B_i
  \sim
  N
  \left(
  \theta_j \sqrt{t_j \;\mathcal I_{j, H_0}} - \theta_i \sqrt{t_i \;\mathcal I_{i, H_0}},
  \;\;
  t_j \frac{\mathcal I_{j, H_0}}{\mathcal I_{j, H_1}} - t_i \frac{\mathcal I_{i, H_0}}{\mathcal I_{i, H_1}}
  \right),
\end{equation*}
$$
leading the conditional power as
$$
  \text{Pr}(Z_j > b ~|~ Z_i = a) 
  =
  1 - 
  \Phi\left(
  \frac{
    \sqrt{t_j}b - \sqrt{t_i}a 
    - 
    \left(\theta_j \sqrt{t_j \;\mathcal I_{j, H_0}} - \theta_i \sqrt{t_i \;\mathcal I_{i, H_0}}
    \right)
  }{
    \sqrt{t_j \frac{\mathcal I_{j, H_0}}{\mathcal I_{j, H_1}} - t_i \frac{\mathcal I_{i, H_0}}{\mathcal I_{i, H_1}}}
  }\right).
$$


## Conditional power hybridizing the observed and future assumed treatment effect.

Assume at analysis $i$, we observed blinded data, which gives us a blinded estimation of the treatment effect, i.e.,
$$
  \widehat\theta_i 
  =
  w_1 \log(\text{HR}_1) + w_2 \log(\text{HR}_2) + \ldots
  +
  w_M \log(\text{HR}_M),
$$
where $w_i = D_i / D_{all}$ with $D_i$ as the observed blinded events of two arms at the $i$-th interval. With the blinded data observed at analysis $i$, the hybrid treatment effect is 
$(\widehat\theta_1, \ldots, \widehat\theta_i, \theta_{i+1}, \ldots, \theta_k),$
where the treatment effect is estimated before and at analysis $i$, and take the value from the alternative hypothesis after analysis $i$. Accordingly, we have the statistical information under the null hypothesis as
$$
  (\widehat{\mathcal I}_{1, H_0}, 
  \ldots, 
  \widehat{\mathcal I}_{i, H_0}, 
  \mathcal I_{i+1, H_0}, 
  \ldots, 
  \mathcal I_{k, H_0}).
$$

The statistical information under the alternative hypothesis is 
$$
  (\mathcal I_{1, H_1}, \ldots, \mathcal I_{i, H_1}, \mathcal I_{i+1, H_1}, \ldots, \mathcal I_{k, H_1}).
$$
So the conditional power given the observed treatment effect is 
$$
  \text{Pr}(Z_j > b | Z_i = a) 
  =
  1 - 
  \Phi\left(
    \frac{
    \sqrt{t_j}b - \sqrt{t_i}a 
    - 
    \left(\theta_j \sqrt{t_j \;\mathcal{I}_{j, H_0}} - \widehat{\theta}_i \sqrt{t_i \; \widehat{\mathcal I}_{i, H_0}}
    \right)
  }{
    \sqrt{t_j \frac{\mathcal{I}_{j, H_0}}{\mathcal{I}_{j, H_1}} - t_i \frac{\widehat{\mathcal I}_{i, H_0}}{\mathcal{I}_{i, H_1}}}
  }
  \right).
$$

We assume an interim p-value of 0.04, one-sided.
This does not come close to the first efficacy or futility bound above. However, it is a trend in the right direction.
The calculation of conditional power depends on the `gs_cp_npe` with the specified

- theta under H0, H1, and IA blined estimation
- statistical information under H0, H1, and IA blinded estimation.

```{r}
gs_cp_npe
```

When we apply the logrank test, the above 3 theta and 3 statistical information can be calculated. 

The conditional power at IA2 under $H_0$, $H_1$ and interim estimation are:
```{r}
cp12 <- gs_cp_ahr(x = x, xu = xu,
                  i = 1, z_i = -qnorm(0.04),
                  j = 2, z_j = x$bound$z[x$bound$bound == "upper" & x$bound$analysis == 2],
                  local_alternative = TRUE) 

cp12 |>
  gt() |>
  fmt_number(columns = c(3, 5, 6), decimals = 4)
```

The conditional power at FA under $H_0$, $H_1$ and interim estimation are:
```{r}
cp13 <- gs_cp_ahr(x = x, xu = xu,
                  i = 1, z_i = -qnorm(0.04),
                  j = 3, z_j = x$bound$z[x$bound$bound == "upper" & x$bound$analysis == 3],
                  local_alternative = TRUE) 

cp13 |>
  gt() |>
  fmt_number(columns = c(3, 5, 6), decimals = 4)
```

# Comparision with gsDesign under PH
```{r}
# ------------------------------ #
# conditional power of gsDesign  #
# ------------------------------ #
# reference: https://keaven.github.io/gsDesign/articles/ConditionalPowerPlot.html
# original design
x_gsd <- gsSurv(k = 3, test.type = 1, alpha = alpha, beta = beta,
                astar = 0, timing = x$analysis$info_frac, 
                sfu = sfLDOF, sfupar = 0,
                sfl = sfLDOF, sflpar = 0, 
                lambdaC = log(2) / 9, hr = 0.6, hr0 = 1,
                eta = fail_rate$dropout_rate |> unique(), 
                gamma = enroll_rate$rate, 
                R = enroll_rate$duration, 
                S = NULL, T = analysis_time[3],
                minfup = analysis_time[3] - sum(enroll_rate$duration),
                ratio = ratio) |>
  toInteger()

# update the design at IA1
xu_gsd <- gsDesign(k = x_gsd$k, test.type = x_gsd$test.type,
                   alpha = x_gsd$alpha, beta = x_gsd$beta,
                   delta = x_gsd$delta, delta1 = x_gsd$delta1, delta0 = x_gsd$delta0,
                   n.I = c(observed_event_ia1, x_gsd$n.I[2:3]),
                   maxn.IPlan = x_gsd$n.I[3],
                   sfu = sfLDOF, sfupar = 0,
                   sfl = sfLDOF, sflpar = 0)
# conditional power of gsDesign
xcp_gsd <- gsCP(x_gsd, i = 1, zi = -qnorm(0.04))
```

```{r, echo=FALSE}
# ------------------------------ #
#       comparison               #
# ------------------------------ #
tibble(`R pkg` = rep(c("gsDesign", "gsDesign2"), each = 3),
       Analysis = rep(c("IA1", "IA2", "FA"), 2),
       `Sample size` = c((x_gsd$eNC + x_gsd$eNE),
                         x$analysis$n) ,
       `Events of original design` = c(x_gsd$n.I,
                                       x$analysis$event) ,
       `Events of updated design` = c(xu_gsd$n.I,
                                      xu$analysis$event),
       `Time of original design` = c((x_gsd$T) |> as.vector(),
                                     x$analysis$time) ,
       `Crossing prob under H1 of original design` = c(x_gsd$upper$prob[, 2] |> cumsum(),
                                                       x$bound$probability[x$bound$bound == "upper"]),
       `Crossing prob under H1 of updated design` = c(xu_gsd$upper$prob[, 2] |> cumsum(),
                                                      xu$bound$probability[xu$bound$bound == "upper"]),
       `Crossing prob under H0 of original design` = c(x_gsd$upper$prob[, 1] |> cumsum(),
                                                       x$bound$probability0[x$bound$bound == "upper"])
       ) |>
  group_by(Analysis) |>
  gt() |>
  tab_header("Comparision of designs from gsDesign and gsDesign2") |>
  fmt_number(columns = 2:5, decimals = 2) |>
  fmt_number(columns = 6:8, decimals = 4)

tibble(`R pkg` = c("gsDesign", "gsDesign2"),
       `Conditional power` = c(xcp_gsd$upper$prob[1, 2], 
                               cp12$cond_power[cp12$scenario == "Under H0"])) |>
  gt() |>
  tab_header(title = "Comparision of conditional power under H0",
             subtitle = "Given IA1 observed blinded data and compute IA2 conditional power")

tibble(`R pkg` = c("gsDesign", "gsDesign2"),
       `Conditional power` = c(sum(xcp_gsd$upper$prob[, 2]), 
                               cp13$cond_power[cp13$scenario == "Under H0"])) |>
  gt() |>
  tab_header(title = "Comparision of conditional power under H0",
             subtitle = "Given IA1 observed blinded data and compute FA conditional power")


# under H1
tibble(`R pkg` = c("gsDesign", "gsDesign2"),
       `Conditional power` = c(xcp_gsd$upper$prob[1, 3], 
                               cp12$cond_power[cp12$scenario == "Under H1"])) |>
  gt() |>
  tab_header(title = "Comparision of conditional power under H1",
             subtitle = "Given IA1 observed blinded data and compute IA2 conditional power")

tibble(`R pkg` = c("gsDesign", "gsDesign2"),
       `Conditional power` = c(sum(xcp_gsd$upper$prob[, 3]), 
                               cp13$cond_power[cp13$scenario == "Under H1"])) |>
  gt() |>
  tab_header(title = "Comparision of conditional power under H1",
             subtitle = "Given IA1 observed blinded data and compute FA conditional power")

# under interim estimation
tibble(`R pkg` = c("gsDesign", "gsDesign2"),
       `Conditional power` = c(xcp_gsd$upper$prob[1, 1], 
                               cp12$cond_power[cp12$scenario == "Under interim estimation"])) |>
  gt() |>
  tab_header(title = "Comparision of conditional power under interim estimation",
             subtitle = "Given IA1 observed blinded data and compute IA2 conditional power")

tibble(`R pkg` = c("gsDesign", "gsDesign2"),
       `Conditional power` = c(sum(xcp_gsd$upper$prob[, 1]), 
                               cp13$cond_power[cp13$scenario == "Under interim estimation"])) |>
  gt() |>
  tab_header(title = "Comparision of conditional power under interim estimation",
             subtitle = "Given IA1 observed blinded data and compute FA conditional power")
```


# Another definition of conditional power via simulations 

People may have varying definitions of conditional power: it can refer to the probability that futility is crossed at IA1 and demonstrates efficacy at either IA2 or FA.

```{r}
# a unit function to run single simulations
one_sim <- function(sim_id = 1, x) {
  
    # generate data
    sim_data <- sim_pw_surv(
      n = max(x$analysis$n),
      stratum = data.frame(stratum = "All", p = 1),
      block = rep(c("experimental", "control"), 2),
      enroll_rate = x$enroll_rate,
      fail_rate = to_sim_pw_surv(x$fail_rate)$fail_rate,
      dropout_rate = to_sim_pw_surv(x$fail_rate)$dropout_rate) 
    
    # cut data
    ia1_data <- sim_data |> cut_data_by_event(x$analysis$event[1])
    ia2_data <- sim_data |> cut_data_by_event(x$analysis$event[2])
    fa_data <- sim_data |> cut_data_by_event(x$analysis$event[3])
    
    # logrank test
    ia1_z <- (ia1_data |> wlr(fh(rho = 0, gamma = 0)))$z
    ia2_z <- (ia2_data |> wlr(fh(rho = 0, gamma = 0)))$z
    fa_z <- (fa_data |> wlr(fh(rho = 0, gamma = 0)))$z
    
    ans_1sim <- tibble(sim_id = sim_id,
                       analysis = 1:3, 
                       z = c(ia1_z, ia2_z, fa_z))
      
    return(ans_1sim)
}

# run simulations
tic()
registerDoFuture()
registerDoRNG()
plan("multisession", workers = 24)
set.seed(2024)

sim_res <- foreach(
  sim_id = seq_len(1e4),
  .combine = "rbind",
  .errorhandling = "stop"
  ) %dorng% {
    ans_new <- one_sim(sim_id = sim_id, x = x)
    ans_new
  }

plan("sequential")
toc()

# summarize simulations
sim_res |>
  left_join(tibble(analysis = 1:3, 
                   futility_bound = c(-1, -Inf, -Inf),
                   efficacy_bound = x$bound$z[x$bound$bound == "upper"])) |>
  filter(sim_id %in% (sim_res |> filter(z <= futility_bound))$sim_id) %>% 
  group_by(sim_id) |>
  summarize(efficacy_flag = sum(z > efficacy_bound)) |>
  ungroup() |>
  summarize(cond_power = sum(efficacy_flag != 0) / nrow(sim_res) * 3 * 100) |>
  gt() |>
  cols_label(cond_power = "Conditional power: probability that futility is crossed at IA1 and demonstrates efficacy at either IA2 or FA.")
```

# References
