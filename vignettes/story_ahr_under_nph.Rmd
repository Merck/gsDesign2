---
title: "Average hazard ratio and sample size under non-proportional hazards"
output:
  rmarkdown::html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    number_sections: true
    highlight: "textmate"
    css: "custom.css"
bibliography: "ggsd.bib"
vignette: >
  %\VignetteIndexEntry{Average hazard ratio and sample size under non-proportional hazards}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  dev = "png"
)
options(width = 58)
```

# Introduction

This document demonstrates applications of the average hazard ratio concept in the design of fixed designs without interim analysis.
Throughout we consider a 2-arm trial with an experimental and control group and a time-to-event endpoint.
Testing for differences between treatment groups is performed using the stratified logrank test.
In the above setting, the `gsDesign2::AHR()` routine provides an average hazard ratio that can be used for sample size using the function `gsDesign::nSurv()`.
The approach assumes piecewise constant enrollment rates and piecewise exponential failure rates with the option of including multiple strata.
This approach allows the flexibility to approximate a wide variety of scenarios.
We evaluate the approximations used via simulation using the **simtrial** package; we specifically provide a simulation routine  so that any changes specified by the user should be easily incorporated.
We consider both non-proportional hazards for a single stratum and multiple strata with different underlying proportional hazards assumptions.

There are two things to note regarding differences between `simtrial::simfix()` and `gsDesign2::AHR()`:

1. `simtrial::simfix()` is less flexible in that it requires all strata are enrolled at the same relative rates throughout the trial whereas `gsDesign2::AHR()` allows, for example, enrollment to start or stop at different times in different strata. In this document, we use the more restrictive parameterization of `simtrial::simfix()` so that we can confirm the asymptotic sample size approximation based on `gsDesign2::AHR()` by simulation.
2. `simtrial::simfix()` provides more flexibility in test statistics used than `gsDesign2::AHR()` as documented in the pMaxCombo vignette demonstrating use of Fleming-Harrington weighted logrank tests and combinations of such tests.

## Document organization

This vignette is organized as follows:

- Two non-proportional hazards examples are introduced for fixed sample size approximation, one with a single stratum and one with two strata.
    - The single stratum design assumes a delayed treatment benefit.
    - The stratified example assumes different proportional hazards in 3 strata.
- Each of these examples have the following subsections:
    - Decription of the design scenario.
    - Deriving an average hazard ratio.
    - Deriving sample size based on average hazard ratio.
    - Computing and plotting the average hazard ratio as a function of time.
    - Simulation to verify that the sample size approximation provides the targeted power.

Each simulation is done with data cutoff performed in 5 different ways:

- Based on targeted trial duration
- Based on targeted minimum follow-up duration only
- Based on targeted event count only
- Based on the maximum of targeted event count and targeted trial duration
- Based on the maximum of targeted event count and targeted minimum follow-up

The method based on waiting to achieve targeted event count and targeted minimum follow-up appears to be both practical and to provide the targeted power.

### Intial setup

We begin by setting two parameters that will be used throughout in simulations used to verify accuracy of power approximations; either could be customized for each simulation.
First, we set the number of simulations to be performed.
You can increase this to improve accuracy of simulation estimates of power.

```{r nsim,warning=FALSE,message=FALSE}
nsim <- 2000
```

Simulations using the `simtrial::simfix()` routine below use blocked randomization.
We set that here and do not change for individual simulations.
Based on balanced randomization in `block` we set the randomization ratio of experimental to control to 1.

```{r block,warning=FALSE,message=FALSE}
block <- rep(c("Control", "Experimental"), 2)
ratio <- 1
```

We load packages needed below.

- **gsDesign** is used for its implementation of the @Schoenfeld1981 approximation to compute the number of events required to power a trial under the proportional hazards assumption.
- **dplyr** and **tibble** to work with tabular data and the 'data wrangling' approach to coding.
- **simtrial** to enable simulations.
- **survival** to enable Cox proportional hazards estimation of the (average) hazard ratio for each simulation to compare with the approximation provided by the `gsDesign2::AHR()` routine that computes an expected average hazard ratio for the trial (@Kalbfleisch1981, @Schemper2009).
- Hidden underneath this is the `gsDesign2::eEvents_df()` routine that provides expected event counts for each period and stratum where the hazard ratio differs. This is the basic calculation used in the `gsDesign2::AHR()` routine.

```{r libraries,message=FALSE,warning=FALSE}
devtools::load_all()
library(gsDesign)
library(ggplot2)
library(dplyr)
library(tibble)
library(simtrial)
library(survival)
library(knitr)
library(gt)
```

# Single stratum non-proportional hazards example

## Design scenario

We set up the first scenario design parameters.
Enrollment ramps up over the course of the first 4 months follow-up by a steady state enrollment thereafter.
This will be adjusted proportionately to power the trial later.
The control group has a piecewise exponential distribution with median 9 for the first 3 months and 18 thereafter.
The hazard ratio of the experimental group versus control is 1 for the first 3 months followed by 0.55 thereafter.

```{r scenario1,warning=FALSE,message=FALSE}
enrollRates <- tibble::tibble(
  Stratum = "All", # Note: this is done differently for multiple strata; see below!
  duration = c(2, 2, 10),
  rate = c(3, 6, 9)
)
failRates <- tibble::tibble(
  Stratum = "All",
  duration = c(3, 100),
  failRate = log(2) / c(9, 18),
  hr = c(1, .55),
  dropoutRate = .001
)
totalDuration <- 30
```

Since there is a single stratum, we set `strata` to the default:

```{r strata1,message=FALSE,warning=FALSE}
strata <- tibble::tibble(Stratum = "All", p = 1)
```

## Computing average hazard ratio

We compute an average hazard ratio using the `gsDesign2::AHR()` (average hazard ratio) routine. We will modify enrollment rates proportionately below when the sample size is computed. This result is for the given enrollment rates which will be adjusted in our next step. However, since they will be adjusted proportionately with relative enrollment timing not changing, the average hazard ratio will not change. Approximations of statistical information under the null (`info0`) and alternate (`info`) hypotheses are provided here.
Recall that the parameterization here is in terms of $\log(HR)$, and, thus the information is intended to approximate 1 over the variance for the Cox regression coefficient for treatment effect; this will be checked with simulation later.

```{r avehr,warning=FALSE,message=FALSE}
avehr <- AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = as.numeric(totalDuration)
)
avehr %>% gt()
```

This result can be explained by the number of events observed before and after the first 3 months of treatment in each treatment group.

```{r}
xx <- AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = as.numeric(totalDuration),
  simple = FALSE)
xx %>% gt()
```

Now we can replicate the geometric average hazard ratio (AHR) computed using the `AHR()` routine above.
We compute the logarithm of each HR above and computed a weighted average weighting by the expected number of events under each hazard ratio.
Exponentiating the resulting weighted average gives the geometric mean hazard ratio, which we label as AHR.

```{r, message=FALSE}
xx %>%
  summarize(AHR = exp(sum(Events * log(HR) / sum(Events)))) %>%
  gt()
```

## Deriving the design

With this average hazard ratio, we use the call for `gsDesign::nEvents()` which uses the @Schoenfeld1981 approximation to derive a targeted number of events.
All you need for this is the average hazard ratio from above, the randomization ratio (experimental/control), Type I error and Type II error (1 - power).

```{r}
targetEvents <- nEvents(
  hr = avehr$AHR, # average hazard ratio computed above
  ratio = 1, # randomization ratio
  alpha = .025, # 1-sided Type I error
  beta = .1 # Type II error (1-power)
)
targetEvents <- ceiling(targetEvents)
targetEvents
```

We also compute proportionately increase the enrollment rates to achieve this targeted number of events; we round up the number of events required to the next higher integer.

```{r}
# Update enrollRates to obtain targeted events
enrollRates$rate <- ceiling(targetEvents) / avehr$Events * enrollRates$rate
avehr <- AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = as.numeric(totalDuration)
)
avehr %>% gt()
```

We also compute sample size, rounding up to the nearest even integer.

```{r}
# round up sample size in both treatment groups
sampleSize <- ceiling(sum(enrollRates$rate * enrollRates$duration) / 2) * 2
sampleSize
```

## Average hazard ratio and expected event accumulation over time

We examine the average hazard ratio as a function of trial duration with the modified enrollment required to power the trial. We also plot expected event accrual over time; although the graphs go through 40 months, recall that the targeted trial duration is 30 months.
A key design consideration is selecting trial duration based on things like the degree of AHR improvement over time versus the urgency of completing the trial as quickly as possible, noting that the required sample size will decrease with longer follow-up.

```{r avehrplot, warning=FALSE, message=FALSE, fig.width=3.5}
avehrtbl <- AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = 1:(totalDuration + 10))

ggplot(avehrtbl, aes(x = Time, y = AHR)) +
  geom_line() +
  ylab("Average HR") +
  ggtitle("Average HR as a function of study duration") #+
  #scale_x_continuous(breaks = seq(0, 48, 6))

ggplot(avehrtbl, aes(x = Time, y = Events)) +
  geom_line() +
  ylab("Expected events") +
  ggtitle("Expected event accumulation as a function of study duration") #+
  #scale_x_continuous(breaks = seq(0, 48, 6))
```

## Simulation to verify power

We use function `simtrial::simfix()` to simplify setting up and executing a simulation to evaluate the sample size derivation above.
Arguments for `simtrial::simfix()` are slightly different than the set-up that was used for the `gsDesign2::AHR()` function used above.
Thus, there is some reformatting of input parameters involved.
One difference from the `gsDesign2::AHR()` parameterization in `simtrial::simfix()` is that `block` is provided to specify fixed block randomization as opposed to `ratio` for `gsDesign2::AHR()`.

```{r simfix1,cache = FALSE,warning = FALSE,message = FALSE, eval=FALSE}
# do simulations
# Cut at targeted study duration
results1 <- simtrial::simfix(
  nsim = nsim,
  block = block,
  sampleSize = sampleSize,
  strata = strata,
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = totalDuration,
  targetEvents = ceiling(targetEvents),
  timingType = 1:5
)
# save(results1, file = './fixutes/results1.Rdata') # Save the data
```

The following summarizes outcomes by the data cutoff chosen. Regardless of cutoff chosen, we see that the power approximates the targeted 90% quite well. 
The statistical information computed in the simulation is computed as one over the simulation variance of the Cox regression coefficient for treatment (i.e., the log hazard ratio).

```{r summary1,message=FALSE,warning=FALSE}
load("./fixtures/results1.Rdata") # loading the data previously saved
results1$Positive <- results1$Z <= qnorm(.025)
results1 %>%
  group_by(cut) %>%
  summarise(
    Simulations = n(), Power = mean(Positive), sdDur = sd(Duration), Duration = mean(Duration),
    sdEvents = sd(Events), Events = mean(Events),
    HR = exp(mean(lnhr)), sdlnhr = sd(lnhr), info = 1 / sdlnhr^2
  ) %>%
  kable(digits = 3)
```

The column `HR` above is the exponentiated mean of the Cox regression coefficients (geometric mean of HR).
We see that the `HR` estimate below matches the simulations above quite well.
The column `info` here is the estimated statistical information under the alternate hypothesis, while `info0` is the estimate under the null hypothesis. The value of `info0` is 1/4 of the expected events calculated below.
In this case, the information approximation under the alternate hypothesis appears slightly small, meaning that the asymptotic approximation used will overpower the trial.
Nonetheless, the approximation for power appear quite good as noted above.

```{r}
avehr %>% gt()
```

# Different proportional hazards by strata

## Design scenario

We set up the design scenario parameter.
We are limited here to simultaneous enrollment of strata since the `simtrial::simfix()` routine uses `simtrial::simPWSurv()` which is limited to this scenario.
We specify three strata:

- High risk: 1/3 of the population with median time-to-event of 6 months and a treatment effect hazard ratio of 1.2.
- Moderate risk: 1/2 of the population with median time-to-event of 9 months and a hazard ratio of 0.2.
- Low risk: 1/6 of the population that is essentially cured in both arms (median 100, HR = 1).

```{r scenario2,warning=FALSE,message=FALSE}
strata <- tibble::tibble(Stratum = c("High", "Moderate", "Low"), p = c(1 / 3, 1 / 2, 1 / 6))

enrollRates <- tibble::tibble(
  Stratum = c(array("High", 4), array("Moderate", 4), array("Low", 4)),
  duration = rep(c(2, 2, 2, 18), 3),
  rate = c((1:4) / 3, (1:4) / 2, (1:4) / 6)
)

failRates <- tibble::tibble(
  Stratum = c("High", "Moderate", "Low"),
  duration = 100,
  failRate = log(2) / c(6, 9, 100),
  hr = c(1.2, 1 / 3, 1),
  dropoutRate = .001
)

totalDuration <- 36
```

## Computing average hazard ratio

Now we transform the enrollment rates to account for stratified population.

```{r avehr2,warning = FALSE,message = FALSE}
ahr2 <- AHR(enrollRates, failRates, totalDuration)
ahr2 %>% gt()
```

We examine the expected events by stratum.

```{r}
xx <- AHR(enrollRates, failRates, totalDuration, simple = FALSE)
xx %>% gt()
```

Getting the average of `log(HR)` weighted by `Events` and exponentiating, we get the overall `AHR` just derived.

```{r, message=FALSE}
xx %>%
  ungroup() %>%
  summarise(lnhr = sum(Events * log(HR)) / sum(Events), AHR = exp(lnhr)) %>%
  gt()
```

## Deriving the design

We derive the sample size as before. We plan the sample size based on the average hazard ratio for the overall population and use that across strata.
First, we derive the targeted events:

```{r gsDesign2,warning = FALSE,message = FALSE}
targetEvents <- gsDesign::nEvents(
  hr = ahr2$AHR,
  ratio = 1,
  alpha = .025,
  beta = .1
)
targetEvents <- ceiling(targetEvents)
targetEvents
```

Next, we adapt enrollment rates proportionately so that the trial will be powered for the targeted failure rates and follow-up duration.

```{r inflate2, message=FALSE}
enrollRates <- enrollRates %>% mutate(rate = targetEvents / ahr2$Events * rate)

AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = totalDuration
) %>% gt()
```

The targeted sample size, rounding up to an even integer, is:

```{r}
sampleSize <- ceiling(sum(enrollRates$rate * enrollRates$duration) / 2) * 2
sampleSize
```

## Average HR and expected event accumulation over time

Plotting the average hazard ratio as a function of study duration, we see that it improves considerably over the course of the study. 
We also plot expected event accumulation. 
As before, we plot for 10 months more than the planned study duration of 36 months to allow evaluation of event accumulation versus treatment effect for different trial durations.

```{r avehrplot2,warning=FALSE,message=FALSE,fig.width=4.5}
avehrtbl <- AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = 1:(totalDuration + 10)
)

ggplot(avehrtbl, aes(x = Time, y = AHR)) +
  geom_line() +
  ylab("Average HR") +
  ggtitle("Average HR as a function of study duration") #+
  #scale_x_continuous(breaks = seq(0, 48, 6))

ggplot(avehrtbl, aes(x = Time, y = Events)) +
  geom_line() +
  ylab("Expected events") +
  ggtitle("Expected event accumulation as a function of study duration") #+
  #scale_x_continuous(breaks = seq(0, 48, 6))
```

## Simulation to verify power

We change the enrollment rates by stratum produced by `gsDesign::nSurv()`
to overall enrollment rates needed for `simtrial::simfix()`.


```{r, message = FALSE}
er <- enrollRates %>%
  group_by(Stratum) %>%
  mutate(period = 1:n()) %>%
  group_by(period) %>%
  summarise(rate = sum(rate), duration = last(duration))

er %>% gt()
```


Now we simulate and summarize results.
Once again, we see that the expected statistical information from the simulation is greater than what would be expected by the Schoenfeld approximation which is the expected events divided by 4.

```{r simfix2,cache=FALSE,warning=FALSE,message=FALSE, eval=FALSE}
results2 <- simtrial::simfix(
    nsim = nsim,
    block = block,
    sampleSize = sampleSize,
    strata = strata,
    enrollRates = er,
    failRates = failRates,
    totalDuration = as.numeric(totalDuration),
    targetEvents = as.numeric(targetEvents),
    timingType = 1:5
  )
# save(results2, file = './fixtures/results2.Rdata') # Save data
```

```{r summary2,warning=FALSE,message=FALSE}
load("./fixtures/results2.Rdata")
results2$Positive <- (pnorm(results2$Z) <= .025)
results2 %>%
  group_by(cut) %>%
  summarize(
    Simulations = n(), Power = mean(Positive), sdDur = sd(Duration), Duration = mean(Duration),
    sdEvents = sd(Events), Events = mean(Events),
    HR = exp(mean(lnhr)), sdlnhr = sd(lnhr), info = 1 / sdlnhr^2
  ) %>%
  kable(digits = 3)
```

Finally, compare the simulation results above to the asymptotic approximation below.
The achieved power by simulation is just below the targeted 90%; noting that the simulation standard error is 0.006, the asymptotic approximation is quite good.
Using the final cutoff that requires both the targeted events and minimum follow-up seems a reasonable convention to preserved targeted design power.

```{r}
AHR(
  enrollRates = enrollRates,
  failRates = failRates,
  totalDuration = totalDuration
) %>% gt()
```

# References