[{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Futility bounds at design and analysis under non-proportional hazards","text":"set futility bounds non-proportional hazards assumption. consider methods presented Korn Freidlin (2018) setting bounds consider alternate futility bound based \\(\\beta-\\)spending delayed crossing treatment effect simplify implementation. Finally, show update \\(\\beta-\\)spending bound based blinded interim data. consider example reproduce line Korn Freidlin (2018) Table 1 alternative futility bounds considered.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"initial-design-set-up-for-fixed-analysis","dir":"Articles","previous_headings":"Overview","what":"Initial design set-up for fixed analysis","title":"Futility bounds at design and analysis under non-proportional hazards","text":"Korn Freidlin (2018) considered delayed effect scenarios proposed futility bound modification earlier method proposed Wieand, Schroeder, O’Fallon (1994). begin enrollment failure rate assumptions Korn Freidlin (2018) based example Chen (2013). now derive fixed sample size based assumptions. Ideally, allow targeted event count variable follow-fixed_design() study duration computed automatically.","code":"# Enrollment assumed to be 680 patients over 12 months with no ramp-up enrollRates <- tibble(Stratum = \"All\", duration = 12, rate = 680 / 12) # Failure rates ## Control exponential with median of 12 mos ## Delayed effect with HR = 1 for 3 months and HR = .693 thereafter ## Censoring rate is 0 failRates <- tibble(Stratum = \"All\", duration = c(3, 100),                     failRate = -log(.5) / 12, hr = c(1, .693), dropoutRate = 0) ## Study duration was 34.8 in Korn & Freidlin Table 1 ## We change to 34.86 here to obtain 512 expected events more precisely studyDuration <- 34.86 fixedevents <- fixed_design(x = \"AHR\", alpha = 0.025, power = NULL,                        enrollRates = enrollRates,                       failRates = failRates,                       studyDuration = studyDuration) fixedevents %>% summary() %>%    select(-Bound) %>%   as_gt(footnote=\"Power based on 512 events\") %>%   fmt_number(columns = 3:4, decimals = 2) %>%    fmt_number(columns = 5:6, decimals = 3)"},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"modified-wieand-futility-bound","dir":"Articles","previous_headings":"","what":"Modified Wieand futility bound","title":"Futility bounds at design and analysis under non-proportional hazards","text":"Wieand, Schroeder, O’Fallon (1994) rule recommends stopping 50% planned events accrue observed HR > 1. kornfreidlin2018 modified adding second interim analysis 75% planned events stop observed HR > 1 implemented requiring trend favor control direction \\(Z\\)-bound 0 resulting Nominal p bound 0.5 interim analyses table . fixed bound specified ’gs_b()function forupperandlowerand correspoinding parametersuparfor upper (efficacy) bound andlpar` lower (futility) bound. final efficacy bound 1-sided nominal p-value 0.025; futility bound lowers 0.0247 noted lower-right-hand corner table . last row Alternate hypothesis see power 88.44%. Korn Freidlin (2018) computed 88.4% power design 100,000 simulations estimate standard error power calculation 0.1%.","code":"wieand <- gs_power_ahr(enrollRates = enrollRates, failRates = failRates,                        upper = gs_b, upar = c(rep(Inf, 2), qnorm(.975)),                        lower = gs_b, lpar = c(0, 0, -Inf),                        events = 512 * c(.5, .75, 1)) wieand %>% summary() %>%    as_gt(title=\"Group sequential design with futility only at interim analyses\",         subtitle=\"Wieand futility rule stops if HR > 1\")"},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"beta-spending-futility-bound-with-ahr","dir":"Articles","previous_headings":"","what":"Beta-spending futility bound with AHR","title":"Futility bounds at design and analysis under non-proportional hazards","text":"Need summarize .","code":"betaspending <- gs_power_ahr(enrollRates = enrollRates, failRates = failRates,                        upper = gs_b, upar = c(rep(Inf, 2), qnorm(.975)),                        lower = gs_spending_bound,                         lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025,                                    param = NULL, timing = NULL),                        events = 512 * c(.5, .75, 1),                        test_lower = c(TRUE, TRUE, FALSE)) betaspending %>%    summary() %>% as_gt(title=\"Group sequential design with futility only\",                       subtitle=\"Beta-spending futility bound\")"},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"classical-beta-spending-futility-bound","dir":"Articles","previous_headings":"","what":"Classical beta-spending futility bound","title":"Futility bounds at design and analysis under non-proportional hazards","text":"classical \\(\\beta-\\)spending bound assume constant treatment effect time using proportional hazards assumption. use average hazard ratio fixed design analysis purpose.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"korn-and-freidlin-futility-bound","dir":"Articles","previous_headings":"","what":"Korn and Freidlin futility bound","title":"Futility bounds at design and analysis under non-proportional hazards","text":"Korn Freidlin (2018) futility bound set least 50% expected events occurred least two thirds observed events occurred later 3 months randomization. expected timing demonstrated .","code":""},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"accumulation-of-events-by-time-interval","dir":"Articles","previous_headings":"Korn and Freidlin futility bound","what":"Accumulation of events by time interval","title":"Futility bounds at design and analysis under non-proportional hazards","text":"consider accumulation events time occur -effect interval first 3 months randomization events time interval. done overall trial without dividing treatment group using gsDesign2::AHR() function. consider monthly accumulation events 34.86 months planned trial duration. note summary early expected events events first 3 months -study expected prior first interim analysis. can look proportion events first 3 months follows:  Korn Freidlin (2018) bound targeted timing 50% events occurred least 2/3 3 months enrollment 3 months delayed effect period. see 1/3 events still within 3 months enrollment month 20.","code":"event_accumulation <-  AHR(enrollRates = enrollRates,     failRates = failRates,     totalDuration = c(1:34, 34.86),     ratio = 1,     simple = FALSE) head(event_accumulation, n = 7) %>% gt() event_accumulation %>%    group_by(Time) %>%   summarize(`Total events` = sum(Events), \"Proportion early\" = first(Events) /  `Total events`) %>%   ggplot(aes(x=Time, y=`Proportion early`)) + geom_line()"},{"path":"https://merck.github.io/gsDesign2/articles/NPH_Futility.html","id":"korn-and-freidlin-bound","dir":"Articles","previous_headings":"Korn and Freidlin futility bound","what":"Korn and Freidlin bound","title":"Futility bounds at design and analysis under non-proportional hazards","text":"bound proposed Korn Freidlin (2018)","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Average hazard ratio and sample size under non-proportional hazards","text":"document demonstrates applications average hazard ratio concept design fixed designs without interim analysis. Throughout consider 2-arm trial experimental control group time--event endpoint. Testing differences treatment groups performed using stratified logrank test. setting, gsDesign2::AHR() routine provides average hazard ratio can used sample size using function gsDesign::nSurv(). approach assumes piecewise constant enrollment rates piecewise exponential failure rates option including multiple strata. approach allows flexibility approximate wide variety scenarios. evaluate approximations used via simulation using simtrial package; specifically provide simulation routine changes specified user easily incorporated. consider non-proportional hazards single stratum multiple strata different underlying proportional hazards assumptions. two things note regarding differences simtrial::simfix() gsDesign2::AHR(): simtrial::simfix() less flexible requires strata enrolled relative rates throughout trial whereas gsDesign2::AHR() allows, example, enrollment start stop different times different strata. document, use restrictive parameterization simtrial::simfix() can confirm asymptotic sample size approximation based gsDesign2::AHR() simulation. simtrial::simfix() provides flexibility test statistics used gsDesign2::AHR() documented pMaxCombo vignette demonstrating use Fleming-Harrington weighted logrank tests combinations tests.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"document-organization","dir":"Articles","previous_headings":"Introduction","what":"Document organization","title":"Average hazard ratio and sample size under non-proportional hazards","text":"vignette organized follows: single stratum design assumes delayed treatment benefit. stratified example assumes different proportional hazards 3 strata. Decription design scenario. Deriving average hazard ratio. Deriving sample size based average hazard ratio. Computing plotting average hazard ratio function time. Simulation verify sample size approximation provides targeted power. simulation done data cutoff performed 5 different ways: Based targeted trial duration Based targeted minimum follow-duration Based targeted event count Based maximum targeted event count targeted trial duration Based maximum targeted event count targeted minimum follow-method based waiting achieve targeted event count targeted minimum follow-appears practical provide targeted power.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"intial-setup","dir":"Articles","previous_headings":"Introduction > Document organization","what":"Intial setup","title":"Average hazard ratio and sample size under non-proportional hazards","text":"begin setting two parameters used throughout simulations used verify accuracy power approximations; either customized simulation. First, set number simulations performed. can increase improve accuracy simulation estimates power. Simulations using simtrial::simfix() routine use blocked randomization. set change individual simulations. Based balanced randomization block set randomization ratio experimental control 1. load packages needed . gsDesign used implementation Schoenfeld (1981) approximation compute number events required power trial proportional hazards assumption. dplyr tibble work tabular data ‘data wrangling’ approach coding. simtrial enable simulations. survival enable Cox proportional hazards estimation (average) hazard ratio simulation compare approximation provided gsDesign2::AHR() routine computes expected average hazard ratio trial (Kalbfleisch Prentice (1981), Schemper, Wakounig, Heinze (2009)). Hidden underneath gsDesign2::eEvents_df() routine provides expected event counts period stratum hazard ratio differs. basic calculation used gsDesign2::AHR() routine.","code":"nsim <- 2000 block <- rep(c(\"Control\", \"Experimental\"), 2) ratio <- 1 devtools::load_all() #> Exports from /home/runner/work/gsDesign2/gsDesign2/src/gridpts_h1_hupdate.cpp: #>    List gridptsRcpp(int r, double mu, double a, double b) #>    List h1Rcpp(int r, double theta, double I, double a, double b) #>    List hupdateRcpp(int r, double theta, double I, double a, double b, double thetam1, double Im1, List gm1) #>  #> /home/runner/work/gsDesign2/gsDesign2/src/RcppExports.cpp updated. #> /home/runner/work/gsDesign2/gsDesign2/R/RcppExports.R updated. #> * installing *source* package ‘gsDesign2’ ... #> ** using staged installation #> ** libs #> g++ -std=gnu++14 -I\"/opt/R/4.2.1/lib/R/include\" -DNDEBUG  -I'/home/runner/work/_temp/Library/Rcpp/include' -I/usr/local/include   -fpic  -g -O2  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c RcppExports.cpp -o RcppExports.o #> g++ -std=gnu++14 -I\"/opt/R/4.2.1/lib/R/include\" -DNDEBUG  -I'/home/runner/work/_temp/Library/Rcpp/include' -I/usr/local/include   -fpic  -g -O2  -UNDEBUG -Wall -pedantic -g -O0 -fdiagnostics-color=always -c gridpts_h1_hupdate.cpp -o gridpts_h1_hupdate.o #> g++ -std=gnu++14 -shared -L/opt/R/4.2.1/lib/R/lib -L/usr/local/lib -o gsDesign2.so RcppExports.o gridpts_h1_hupdate.o -L/opt/R/4.2.1/lib/R/lib -lR #> installing to /tmp/RtmpQfquD4/devtools_install_380b6d0e1612/00LOCK-gsDesign2/00new/gsDesign2/libs #> ** checking absolute paths in shared objects and dynamic libraries #> * DONE (gsDesign2) library(gsDesign) library(ggplot2) library(dplyr) library(tibble) library(simtrial) library(survival) library(knitr) library(gt)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"design-scenario","dir":"Articles","previous_headings":"Single stratum non-proportional hazards example","what":"Design scenario","title":"Average hazard ratio and sample size under non-proportional hazards","text":"set first scenario design parameters. Enrollment ramps course first 4 months follow-steady state enrollment thereafter. adjusted proportionately power trial later. control group piecewise exponential distribution median 9 first 3 months 18 thereafter. hazard ratio experimental group versus control 1 first 3 months followed 0.55 thereafter. Since single stratum, set strata default:","code":"enrollRates <- tibble::tibble(   Stratum = \"All\", # Note: this is done differently for multiple strata; see below!   duration = c(2, 2, 10),   rate = c(3, 6, 9) ) failRates <- tibble::tibble(   Stratum = \"All\",   duration = c(3, 100),   failRate = log(2) / c(9, 18),   hr = c(1, .55),   dropoutRate = .001 ) totalDuration <- 30 strata <- tibble::tibble(Stratum = \"All\", p = 1)"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"computing-average-hazard-ratio","dir":"Articles","previous_headings":"Single stratum non-proportional hazards example","what":"Computing average hazard ratio","title":"Average hazard ratio and sample size under non-proportional hazards","text":"compute average hazard ratio using gsDesign2::AHR() (average hazard ratio) routine. modify enrollment rates proportionately sample size computed. result given enrollment rates adjusted next step. However, since adjusted proportionately relative enrollment timing changing, average hazard ratio change. Approximations statistical information null (info0) alternate (info) hypotheses provided . Recall parameterization terms \\(\\log(HR)\\), , thus information intended approximate 1 variance Cox regression coefficient treatment effect; checked simulation later. result can explained number events observed first 3 months treatment treatment group. Now can replicate geometric average hazard ratio (AHR) computed using AHR() routine . compute logarithm HR computed weighted average weighting expected number events hazard ratio. Exponentiating resulting weighted average gives geometric mean hazard ratio, label AHR.","code":"avehr <- AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = as.numeric(totalDuration) ) avehr %>% gt() xx <- AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = as.numeric(totalDuration),   simple = FALSE) xx %>% gt() xx %>%   summarize(AHR = exp(sum(Events * log(HR) / sum(Events)))) %>%   gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"deriving-the-design","dir":"Articles","previous_headings":"Single stratum non-proportional hazards example","what":"Deriving the design","title":"Average hazard ratio and sample size under non-proportional hazards","text":"average hazard ratio, use call gsDesign::nEvents() uses Schoenfeld (1981) approximation derive targeted number events. need average hazard ratio , randomization ratio (experimental/control), Type error Type II error (1 - power). also compute proportionately increase enrollment rates achieve targeted number events; round number events required next higher integer. also compute sample size, rounding nearest even integer.","code":"targetEvents <- nEvents(   hr = avehr$AHR, # average hazard ratio computed above   ratio = 1, # randomization ratio   alpha = .025, # 1-sided Type I error   beta = .1 # Type II error (1-power) ) targetEvents <- ceiling(targetEvents) targetEvents #> [1] 309 # Update enrollRates to obtain targeted events enrollRates$rate <- ceiling(targetEvents) / avehr$Events * enrollRates$rate avehr <- AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = as.numeric(totalDuration) ) avehr %>% gt() # round up sample size in both treatment groups sampleSize <- ceiling(sum(enrollRates$rate * enrollRates$duration) / 2) * 2 sampleSize #> [1] 576"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"average-hazard-ratio-and-expected-event-accumulation-over-time","dir":"Articles","previous_headings":"Single stratum non-proportional hazards example","what":"Average hazard ratio and expected event accumulation over time","title":"Average hazard ratio and sample size under non-proportional hazards","text":"examine average hazard ratio function trial duration modified enrollment required power trial. also plot expected event accrual time; although graphs go 40 months, recall targeted trial duration 30 months. key design consideration selecting trial duration based things like degree AHR improvement time versus urgency completing trial quickly possible, noting required sample size decrease longer follow-.","code":"avehrtbl <- AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = 1:(totalDuration + 10))  ggplot(avehrtbl, aes(x = Time, y = AHR)) +   geom_line() +   ylab(\"Average HR\") +   ggtitle(\"Average HR as a function of study duration\") #+ #scale_x_continuous(breaks = seq(0, 48, 6))  ggplot(avehrtbl, aes(x = Time, y = Events)) +   geom_line() +   ylab(\"Expected events\") +   ggtitle(\"Expected event accumulation as a function of study duration\") #+ #scale_x_continuous(breaks = seq(0, 48, 6))"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"simulation-to-verify-power","dir":"Articles","previous_headings":"Single stratum non-proportional hazards example","what":"Simulation to verify power","title":"Average hazard ratio and sample size under non-proportional hazards","text":"use function simtrial::simfix() simplify setting executing simulation evaluate sample size derivation . Arguments simtrial::simfix() slightly different set-used gsDesign2::AHR() function used . Thus, reformatting input parameters involved. One difference gsDesign2::AHR() parameterization simtrial::simfix() block provided specify fixed block randomization opposed ratio gsDesign2::AHR(). following summarizes outcomes data cutoff chosen. Regardless cutoff chosen, see power approximates targeted 90% quite well. statistical information computed simulation computed one simulation variance Cox regression coefficient treatment (.e., log hazard ratio). column HR exponentiated mean Cox regression coefficients (geometric mean HR). see HR estimate matches simulations quite well. column info estimated statistical information alternate hypothesis, info0 estimate null hypothesis. value info0 1/4 expected events calculated . case, information approximation alternate hypothesis appears slightly small, meaning asymptotic approximation used overpower trial. Nonetheless, approximation power appear quite good noted .","code":"# do simulations # Cut at targeted study duration results1 <- simtrial::simfix(   nsim = nsim,   block = block,   sampleSize = sampleSize,   strata = strata,   enrollRates = enrollRates,   failRates = failRates,   totalDuration = totalDuration,   targetEvents = ceiling(targetEvents),   timingType = 1:5 ) # save(results1, file = './fixutes/results1.Rdata') # Save the data load(\"./fixtures/results1.Rdata\") # loading the data previously saved results1$Positive <- results1$Z <= qnorm(.025) results1 %>%   group_by(cut) %>%   summarise(     Simulations = n(), Power = mean(Positive), sdDur = sd(Duration), Duration = mean(Duration),     sdEvents = sd(Events), Events = mean(Events),     HR = exp(mean(lnhr)), sdlnhr = sd(lnhr), info = 1 / sdlnhr^2   ) %>%   kable(digits = 3) avehr %>% gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"design-scenario-1","dir":"Articles","previous_headings":"Different proportional hazards by strata","what":"Design scenario","title":"Average hazard ratio and sample size under non-proportional hazards","text":"set design scenario parameter. limited simultaneous enrollment strata since simtrial::simfix() routine uses simtrial::simPWSurv() limited scenario. specify three strata: High risk: 1/3 population median time--event 6 months treatment effect hazard ratio 1.2. Moderate risk: 1/2 population median time--event 9 months hazard ratio 0.2. Low risk: 1/6 population essentially cured arms (median 100, HR = 1).","code":"strata <- tibble::tibble(Stratum = c(\"High\", \"Moderate\", \"Low\"), p = c(1 / 3, 1 / 2, 1 / 6))  enrollRates <- tibble::tibble(   Stratum = c(array(\"High\", 4), array(\"Moderate\", 4), array(\"Low\", 4)),   duration = rep(c(2, 2, 2, 18), 3),   rate = c((1:4) / 3, (1:4) / 2, (1:4) / 6) )  failRates <- tibble::tibble(   Stratum = c(\"High\", \"Moderate\", \"Low\"),   duration = 100,   failRate = log(2) / c(6, 9, 100),   hr = c(1.2, 1 / 3, 1),   dropoutRate = .001 )  totalDuration <- 36"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"computing-average-hazard-ratio-1","dir":"Articles","previous_headings":"Different proportional hazards by strata","what":"Computing average hazard ratio","title":"Average hazard ratio and sample size under non-proportional hazards","text":"Now transform enrollment rates account stratified population. examine expected events stratum. Getting average log(HR) weighted Events exponentiating, get overall AHR just derived.","code":"ahr2 <- AHR(enrollRates, failRates, totalDuration) ahr2 %>% gt() xx <- AHR(enrollRates, failRates, totalDuration, simple = FALSE) xx %>% gt() xx %>%   ungroup() %>%   summarise(lnhr = sum(Events * log(HR)) / sum(Events), AHR = exp(lnhr)) %>%   gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"deriving-the-design-1","dir":"Articles","previous_headings":"Different proportional hazards by strata","what":"Deriving the design","title":"Average hazard ratio and sample size under non-proportional hazards","text":"derive sample size . plan sample size based average hazard ratio overall population use across strata. First, derive targeted events: Next, adapt enrollment rates proportionately trial powered targeted failure rates follow-duration. targeted sample size, rounding even integer, :","code":"targetEvents <- gsDesign::nEvents(   hr = ahr2$AHR,   ratio = 1,   alpha = .025,   beta = .1 ) targetEvents <- ceiling(targetEvents) targetEvents #> [1] 216 enrollRates <- enrollRates %>% mutate(rate = targetEvents / ahr2$Events * rate)  AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = totalDuration ) %>% gt() sampleSize <- ceiling(sum(enrollRates$rate * enrollRates$duration) / 2) * 2 sampleSize #> [1] 340"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"average-hr-and-expected-event-accumulation-over-time","dir":"Articles","previous_headings":"Different proportional hazards by strata","what":"Average HR and expected event accumulation over time","title":"Average hazard ratio and sample size under non-proportional hazards","text":"Plotting average hazard ratio function study duration, see improves considerably course study. also plot expected event accumulation. , plot 10 months planned study duration 36 months allow evaluation event accumulation versus treatment effect different trial durations.","code":"avehrtbl <- AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = 1:(totalDuration + 10) )  ggplot(avehrtbl, aes(x = Time, y = AHR)) +   geom_line() +   ylab(\"Average HR\") +   ggtitle(\"Average HR as a function of study duration\") #+ #scale_x_continuous(breaks = seq(0, 48, 6))  ggplot(avehrtbl, aes(x = Time, y = Events)) +   geom_line() +   ylab(\"Expected events\") +   ggtitle(\"Expected event accumulation as a function of study duration\") #+ #scale_x_continuous(breaks = seq(0, 48, 6))"},{"path":"https://merck.github.io/gsDesign2/articles/story_ahr_under_nph.html","id":"simulation-to-verify-power-1","dir":"Articles","previous_headings":"Different proportional hazards by strata","what":"Simulation to verify power","title":"Average hazard ratio and sample size under non-proportional hazards","text":"change enrollment rates stratum produced gsDesign::nSurv() overall enrollment rates needed simtrial::simfix(). Now simulate summarize results. , see expected statistical information simulation greater expected Schoenfeld approximation expected events divided 4. Finally, compare simulation results asymptotic approximation . achieved power simulation just targeted 90%; noting simulation standard error 0.006, asymptotic approximation quite good. Using final cutoff requires targeted events minimum follow-seems reasonable convention preserved targeted design power.","code":"er <- enrollRates %>%   group_by(Stratum) %>%   mutate(period = 1:n()) %>%   group_by(period) %>%   summarise(rate = sum(rate), duration = last(duration))  er %>% gt() results2 <- simtrial::simfix(     nsim = nsim,     block = block,     sampleSize = sampleSize,     strata = strata,     enrollRates = er,     failRates = failRates,     totalDuration = as.numeric(totalDuration),     targetEvents = as.numeric(targetEvents),     timingType = 1:5   ) # save(results2, file = './fixtures/results2.Rdata') # Save data load(\"./fixtures/results2.Rdata\") results2$Positive <- (pnorm(results2$Z) <= .025) results2 %>%   group_by(cut) %>%   summarize(     Simulations = n(), Power = mean(Positive), sdDur = sd(Duration), Duration = mean(Duration),     sdEvents = sd(Events), Events = mean(Events),     HR = exp(mean(lnhr)), sdlnhr = sd(lnhr), info = 1 / sdlnhr^2   ) %>%   kable(digits = 3) AHR(   enrollRates = enrollRates,   failRates = failRates,   totalDuration = totalDuration ) %>% gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_arbitrary_distribution.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Approximating an Arbitrary Survival Distribution","text":"demonstrate approximate arbitrary continuous survival distibutions piecewise exponential approximations. enables sample size computations arbitrary survival models using software designed piecewise exponential distribution. Three functions particular demonstrated: s2pwe() translates arbitrary survival distribution piecewise exponential. ppwe() computes cumulative survival distribution upper tail distribution form generated s2pwe(). pPM() provides cumulative survival distribution Poisson mixture distribution.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_arbitrary_distribution.html","id":"lognormal-approximation","dir":"Articles","previous_headings":"","what":"Lognormal approximation","title":"Approximating an Arbitrary Survival Distribution","text":"demonstrate s2pwe() approximating lognormal distribution piecewise exponential failure rates. Note resulting lnormRates used, final piecewise exponential duration extended. , arbitrarily approximated 6 piecewise exponential rates duration 1 unit time (say, month) followed final rate extends infinity. compare resulting approximation actual lognormal survival using ppwe() compute survival probabilities \\(P\\{T>t\\}\\). better approximation, use larger number points. plot log scale y-axis since piecewise exponential survival ppwe() piecewise linear scale. note beginning rate period approximation actual survival distribution approximation match exactly indicated circles graph.  considered lognormal distribution due flexibility allows hazard rates time; see, example, Wikipedia.","code":"lnormRates <- s2pwe(   times = c(1:6, 9),   survival = plnorm(c(1:6, 9), meanlog = 0, sdlog = 2, lower.tail = FALSE) ) lnormRates ## # A tibble: 7 × 2 ##   duration  rate ##      <dbl> <dbl> ## 1        1 0.693 ## 2        1 0.316 ## 3        1 0.224 ## 4        1 0.177 ## 5        1 0.148 ## 6        1 0.128 ## 7        3 0.103 # Use a large number of points to plot lognormal survival times <- seq(0, 12, .025)  plot(times, plnorm(times, meanlog = 0, sdlog = 2, lower.tail = FALSE),   log = \"y\", type = \"l\",   main = \"Lognormal Distribution vs. Piecewise Approximation\", yaxt = \"n\",   ylab = \"log(Survival)\", col = 1)  # Now plot the pieceise approximation using the 7-point approximation from above lines(times, ppwe(x = times, failRates = lnormRates), col = 2) # Finally, add point markers at the points used in the approximation points(x = c(0:6), plnorm(c(0:6), meanlog = 0, sdlog = 2, lower.tail = FALSE), col = 1) text(x = c(5, 5), y = c(.5, .4), labels = c(\"Log-normal\", \"Piecewise Approximation (7 pts)\"), col = 1:2, pos = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_arbitrary_distribution.html","id":"poisson-mixture-model","dir":"Articles","previous_headings":"","what":"Poisson mixture model","title":"Approximating an Arbitrary Survival Distribution","text":"consider Poisson mixture model incorporate cure model sample size planning. form survival function \\[S(t)=\\exp(-\\theta F_0(t))\\] \\(t\\ge 0\\) \\(F_0(t)\\) continuous cumulative distribution function non-negative random variable \\(F_0(0)=0\\) \\(F_0(t)\\uparrow 1\\) \\(t\\uparrow \\infty\\). note \\(t\\uparrow \\infty\\), \\(S(t)\\downarrow \\exp(-\\theta)=c\\) refer \\(c\\) cure rate. function pPM() assumes \\(F_0(t)=1-\\exp(-\\lambda t)\\) exponential cumulative distribution function resulting survival distribution \\(t\\ge 0\\): \\[S(t; \\theta, \\lambda) = \\exp(-\\theta(1-\\exp(-\\lambda t))).\\] Note set default lower.tail=FALSE survival function computation default: plot \\(\\lambda = \\log(2) / 10\\) make \\(F_0(t)\\) exponential distribution median 10. set \\(\\theta = -\\log(.4)\\) obtain cure rate 0.4. overlay piecewise exponential approximation.  note two different \\(\\theta\\) values provide proportional hazards model ratio cumulative hazard function \\(H(t; \\theta, \\lambda) = \\theta\\exp(-\\lambda t)\\) constant: \\[\\frac{\\log(S(t; \\theta_1, \\lambda))}{\\log(S(t; \\theta_2, \\lambda))} = \\theta_1/\\theta_2.\\] given \\(\\theta\\) value can compute \\(\\lambda\\) provide survival rate \\(c_1 > \\exp(-\\theta)\\) arbitrary time \\(t_1>0\\) setting: \\[\\lambda = -\\log\\left(\\frac{\\theta - \\log(c_1)}{\\theta}\\right)/t_1.\\] compute \\(\\theta\\) \\(\\lambda\\) values cure rate 0.4 survival rate 0.6 30 months: confirm survival time 30:","code":"pPM <- function(x, theta, lambda, lower.tail = FALSE) {   exp(-theta * (1 - exp(-lambda * x))) } lambda <- log(2) / 10 theta <- -log(.4) times <- 0:40 plot(times, pPM(times, theta, lambda), type = \"l\", ylab = \"Survival\", xlab = \"Time\", log = \"y\")  # Now compute piecewise expoential approximation x <- seq(8, 40, 8) pmRates <- s2pwe(   times = x,   survival = pPM(x, theta = theta, lambda = lambda))  # Now plot the pieceise approximation using the 7-point approximation from above lines(c(0, x), ppwe(x = c(0, x), failRates = pmRates), col = 2) points(c(0, x), pPM(c(0, x), theta, lambda)) theta <- -log(0.4) lambda <- -log((theta + log(.6)) / theta) / 30 pPM(30, theta, lambda) ## [1] 0.6"},{"path":"https://merck.github.io/gsDesign2/articles/story_compare_power_delay_effect.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Power for Delayed Effect Scenarios","text":"consider delayed effect scenario control group time--event distribution exponential median 15 months. experimental group hazard ratio vs. control 1 6 months 0.6 thereafter. Enrollment constant rate 12 months. Total study duration 20 48 months. Exponential dropout rate 0.001 per month. scenarios, investigate power, sample size events 6 tests: FH05: Fleming-Harrington \\(\\rho=0, \\gamma=0.5\\) test obtain power 85% given 1-sided Type error 0.025. FH00: regular logrank test \\(\\rho=0, \\gamma=0\\) fixed study duration \\(\\\\{20, 24, 28, \\ldots, 60\\}\\). mc2_test: Max Combo test including 2 WLR tests, .e., \\(\\{(\\rho=0, \\gamma=0, \\tau = -1), (\\rho=0, \\gamma=0.5, \\tau = -1)\\}\\). mc2_test: Max Combo test including 3 WLR tests, .e., \\(\\{(\\rho=0, \\gamma=0, \\tau = -1), (\\rho=0, \\gamma=0.5, \\tau = -1), (\\rho=0.5, \\gamma=0.5, \\tau = -1)\\}\\). mc4_test: Max Combo test including 4 WLR tests, .e., \\(\\{(\\rho=0, \\gamma=0, \\tau = -1), (\\rho=0, \\gamma=0.5, \\tau = -1), (\\rho=0.5, \\gamma=0.5, \\tau = -1), (\\rho=0.5, \\gamma=0, \\tau = -1)\\}\\). MB6: Magirr-Burman \\(\\rho=-1, \\gamma=0, \\tau = 6\\) test fixed study duration \\(\\\\{20, 24, 28, \\ldots, 60\\}\\). compute power logrank test. general summary Fleming-Harrington test meaningful power gain relative logrank regardless study durations evaluated.","code":"enrollRates <- tibble(Stratum = \"All\", duration = 12, rate = 1) failRates <- tibble(Stratum = \"All\",                             duration = c(6, 100),                             failRate = log(2) / 15,                             hr = c(1, .6),                             dropoutRate = 0.001) enrollRates %>% gt() %>% tab_header(title = \"Enrollment Table of Scenario 1\") failRates %>% gt() %>% tab_header(title = \"Failure Table of Scenario 1\") tab <- NULL  for(trial_duration in seq(24, 60, 4)){      # Fleming-Harrington rho=0, gamma=0.5 test   FH05 <- gs_design_wlr(enrollRates = enrollRates,                          failRates = failRates,                         ratio = 1,                          alpha = 0.025, beta = 0.15,                         weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)},                         upar = qnorm(.975),                         lpar = -Inf,                         analysisTimes = trial_duration)       # regular logrank test   FH00 <- gs_power_wlr(enrollRates = FH05$enrollRates,                         failRates = failRates,                        ratio = 1,                         weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)},                        upar = qnorm(.975),                        lpar = -Inf,                        analysisTimes = trial_duration,                        events = .1)       # max combo test 1   mc2_test <- data.frame(rho = 0, gamma = c(0, .5), tau = -1,                          test = 1:2, Analysis = 1, analysisTimes = trial_duration)      MC2 <- gs_power_combo(enrollRates = FH05$enrollRates,                          failRates = failRates,                          fh_test = mc2_test,                         upper = gs_spending_combo,                    upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                    lower = gs_spending_combo,                    lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.01))      # max combo test 2   mc3_test <- data.frame(rho = c(0, 0, .5), gamma = c(0, .5, .5), tau = -1,                          test = 1:3, Analysis = 1, analysisTimes = trial_duration)      MC3 <- gs_power_combo(enrollRates = FH05$enrollRates,                          failRates = failRates,                          fh_test = mc3_test,                         upper = gs_spending_combo,                         upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                         lower = gs_spending_combo,                         lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.01))      # max combo test    mc4_test <- data.frame(rho = c(0, 0, .5, .5), gamma = c(0, .5, .5, 0), tau = -1,                          test = 1:4, Analysis = 1, analysisTimes = trial_duration)      MC4 <- gs_power_combo(enrollRates = FH05$enrollRates,                          failRates = failRates,                          fh_test = mc4_test,                         upper = gs_spending_combo,                         upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                         lower = gs_spending_combo,                         lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.01))      # Magirr-Burman rho=-1, gamma=0, tau = 6 test   MB6 <- gs_power_wlr(enrollRates = FH05$enrollRates,                        failRates = failRates,                       ratio = 1,                        weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = -1, gamma = 0, tau = 20)},                       upar = qnorm(.975),                       lpar = -Inf,                       analysisTimes = trial_duration,                       events = .1)       tab_new <- tibble(`Study duration` = trial_duration,                     N = FH05$analysis$N[1],                     Events = FH05$analysi$Events[1],                      `Events/N` = Events/N,                      # we use the AHR from regular WLR as the AHR of different max combo test                     AHR = as.numeric(FH00$analysis$AHR[1]),                      `FH(0, 0.5) power` = FH05$bounds$Probability[1],                     `FH(0, 0) power` = FH00$bounds$Probability[1],                     `MC2 power` = MC2$bounds$Probability[1],                     `MC4 power` = MC4$bounds$Probability[1],                     `MC3 power` = MC3$bounds$Probability[1],                     `MB6 power` = MB6$bounds$Probability[1])   tab <- rbind(tab, tab_new) }  tab %>%    gt() %>%   fmt_number(columns = c(2, 3), decimals = 1) %>%   fmt_number(columns = 4, decimals = 2) %>%   fmt_number(columns = 5, decimals = 4) %>%   fmt_number(columns = 6:11, decimals = 2)"},{"path":"https://merck.github.io/gsDesign2/articles/story_compare_power_delay_effect.html","id":"an-alternative-scenario","dir":"Articles","previous_headings":"","what":"An Alternative Scenario","title":"Power for Delayed Effect Scenarios","text":"Now consider alternate scenario placebo group starts median, piecewise change median 30 16 months hazard ratio 0.85 late period.","code":"enrollRates <- tibble(Stratum = \"All\", duration = 12, rate = 1) failRates <- tibble(Stratum = \"All\",                     duration = c(6, 10, 100),                     # in Scenario 1: failRate = log(2) / 15,                     failRate = log(2) / c(15, 15, 30),                     # in Scenario 1: hr = c(1, .6)                     hr = c(1, .6, .85),                     dropoutRate = 0.001) enrollRates %>% gt() %>% tab_header(title = \"Enrollment Table of Scenario 2\") failRates %>% gt() %>% tab_header(title = \"Failure Table of Scenario 2\") tab <- NULL  for(trial_duration in seq(20, 60, 4)){   # Fleming-Harrington rho=0, gamma=0.5 test   FH05 <- gs_design_wlr(enrollRates = enrollRates,                          failRates = failRates,                         ratio = 1,                         alpha = 0.025, beta = 0.15,                         weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)},                         upper = gs_b,                         upar = qnorm(.975),                         lower = gs_b,                         lpar = -Inf,                         analysisTimes = trial_duration)       # regular logrank test   FH00 <- gs_power_wlr(enrollRates = FH05$enrollRates,                         failRates = failRates,                        ratio = 1,                         weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)},                        upper = gs_b,                        upar = qnorm(.975),                        lower = gs_b,                        lpar = -Inf,                        analysisTimes = trial_duration,                        events = .1)      # max combo test    mc2_test <- data.frame(rho = 0, gamma = c(0, .5), tau = -1,                          test = 1:2, Analysis = 1, analysisTimes = trial_duration)   MC2 <- gs_power_combo(enrollRates = FH05$enrollRates,                          failRates = failRates,                          fh_test = mc2_test,                         upper = gs_spending_combo,                         upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                         lower = gs_spending_combo,                         lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.01))      # max combo test    mc3_test <- data.frame(rho = c(0,0,.5), gamma = c(0, .5, .5), tau = -1,                          test = 1:3, Analysis = 1, analysisTimes = trial_duration)      MC3 <- gs_power_combo(enrollRates = FH05$enrollRates,                          failRates = failRates,                          fh_test = mc3_test,                         upper = gs_spending_combo,                         upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                         lower = gs_spending_combo,                         lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.01))      # max combo test    mc4_test <- data.frame(rho = c(0,0,.5,.5), gamma = c(0, .5, .5, 0), tau = -1,                          test = 1:4, Analysis = 1, analysisTimes = trial_duration)      MC4 <- gs_power_combo(enrollRates = FH05$enrollRates,                          failRates = failRates, fh_test = mc4_test,                         upper = gs_spending_combo,                         upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),                         lower = gs_spending_combo,                         lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.01))      # Magirr-Burman rho=-1, gamma=0, tau = 6 test   MB6 <- gs_power_wlr(enrollRates = FH05$enrollRates,                        failRates = failRates,                       ratio = 1,                        weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = -1, gamma = 0, tau = 6)},                       upar = qnorm(.975),                       lpar = -Inf,                       analysisTimes = trial_duration,                       events = .1)       tab_new <- tibble(`Study duration` = trial_duration,                     N = FH05$analysis$N[1],                     Events = FH05$analysi$Events[1],                      `Events/N` = Events/N,                      # we use the AHR from regular WLR as the AHR of different max combo test                     AHR = as.numeric(FH00$analysis$AHR[1]),                      `FH(0, 0.5) power` = FH05$bounds$Probability[1],                     `FH(0, 0) power` = FH00$bounds$Probability[1],                     `MC2 power` = MC2$bounds$Probability[1],                     `MC4 power` = MC4$bounds$Probability[1],                     `MC3 power` = MC3$bounds$Probability[1],                     `MB6 power` = MB6$bounds$Probability[1])      tab <- rbind(tab, tab_new) }  tab %>%    gt() %>%   fmt_number(columns = c(2, 3), decimals = 1) %>%   fmt_number(columns = 4, decimals = 2) %>%   fmt_number(columns = 5, decimals = 4) %>%   fmt_number(columns = 6:11, decimals = 2)"},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_expected_events.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Computing expected events by interval at risk","text":"document derives algorithm computing expected events observed model piecewise constant enrollment, failure dropout rates similar Lachin Foulkes (1986). Specifically, design enable computation average hazard ratio use elsewhere approximate sample size fixed group sequential designs non-proportional hazards assumption (Kalbfleisch Prentice (1981), Schemper, Wakounig, Heinze (2009)). expected events calculation outlined implemented function eEvents_df().","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_expected_events.html","id":"general-formulation-and-notation","dir":"Articles","previous_headings":"","what":"General formulation and notation","title":"Computing expected events by interval at risk","text":"notation, study time scale denoted \\(\\omega\\) study start first opening enrollment \\(\\omega=0\\). use variable \\(t\\) indicate patient time \\(t=0\\) representing time patient enrolled. assume patient time enrollment event independent identically distributed subjects enrolled. also assume patient time censoring independent identically distributed subjects enrolled. individual, let \\(X>0\\) denote patient time event \\(Y>0\\) denote patient time loss--follow-. also let \\(U\\) denote (independent) study time entry patient. assume triplet \\(X\\), \\(Y\\), \\(U\\) independent. consider single treatment group stratum assume subjects enroll according Poisson process entry rate \\(g(\\omega)\\geq 0\\) \\(0\\le \\omega\\). expected number subjects enrolled study time \\(\\omega\\) simply \\[\\begin{equation} G(\\omega)=\\int_0^\\omega g(u)du. \\end{equation}\\] Analysis time--event data done using time enrollment patient event, drops , censored prior event time data cutoff; consider data cutoff fixed time \\(\\Omega\\). key counts consider : \\(\\bar{N}(t)\\) : number patients events study least duration \\(0<t \\le \\Omega\\) time data cutoff study time \\(\\Omega\\). \\(\\bar{n}(t_1,t_2)\\equiv E\\{\\bar{N}(t_2)-\\bar{N}(t_1)\\}\\) : number patients events interval \\((t_1,t_2]\\), \\(0\\le t_1< t_2\\le \\Omega\\). focus expected value \\(\\bar{n}(t_1,t_2)\\) due usefulness computing average hazard ratio piecewise model outlined . patient count \\(\\bar{n}(t_1,t_2)\\) must enrolled prior time \\(\\Omega - t_1\\). Also, patient enrolled time \\(0<u<\\Omega\\) maximum time observed occurrence event \\(\\Omega - u\\). Thus, \\[\\begin{align} E\\{\\bar{n}(t_1,t_2)\\}&=\\int_0^{\\Omega-{t_1}} g(u)  P\\{t_1<X\\leq \\min(t_2,\\Omega-u), X\\leq Y\\} du\\nonumber\\\\ &=\\int_0^{\\Omega-t_2} g(u) P\\{t_1<X\\leq t_2, X\\leq Y\\} du+ \\int_{\\Omega-t_2}^{\\Omega-t_1} g(u) P\\{t_1< X\\leq \\Omega-u, X\\leq Y\\} du\\nonumber\\\\ &=G(\\Omega-t_2)P\\{t_1<X\\leq t_2, X\\leq Y\\}+  \\int_{\\Omega-t_2}^{\\Omega-t_1} g(u) P\\{t_1< X\\leq \\Omega-u, X\\leq Y\\} du.\\nonumber \\end{align}\\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_expected_events.html","id":"the-piecewise-model","dir":"Articles","previous_headings":"","what":"The piecewise model","title":"Computing expected events by interval at risk","text":"model follows: Piecewise constant enrollment rates allowed given enrollment rate often accelerates early trial. Piecewise exponential failure rates allowed allow changing outcome incidence time. Piecewise exponential censoring rates allow changing dropout rates time. fixed study duration. Lachin Foulkes (1986) provided general formulation calculating expected number events time scenario described . However, alter algorithm compute expected number events \\(E\\{\\bar n(t_1,t_2)\\}\\) follow-period constant failure rate; later enable computing average hazard ratio (Kalbfleisch Prentice (1981), Schemper, Wakounig, Heinze (2009)). define piecewise time--event dropout random variables patient time scale. assume \\(0=t_0<t_1<...<t_M=\\infty\\) \\(m=1,2,\\ldots,M\\). \\(m=1,2,\\ldots,M\\), assume \\(X_m>0\\), \\(Y_m>0\\) random variables independent study entry time \\(U\\). let \\(X_m\\) \\(Y_m\\) define \\(X\\) \\(Y\\), respectively, interval \\((t_{m-1},t_m]\\), \\(m=1,2,\\ldots,M\\), follows: \\[\\begin{align} X&=\\sum_{m=1}^M \\min(X_m,t_m-t_{m-1}) \\prod_{j=1}^{m-1}\\{X_j>t_j-t_{j-1}\\}\\label{eq:Xdef}\\\\ Y&=\\sum_{m=1}^M \\min(Y_m,t_m-t_{m-1})\\prod_{j=1}^{m-1}\\{Y_j>t_j-t_{j-1}\\}\\label{eq:Ydef}. \\end{align}\\] assume \\(X_m\\) \\(Y_m\\) independent exponentially distributed failure rates \\(\\lambda_m\\) \\(\\eta_m\\), respectively, \\(m=1,2,\\ldots,M\\). now assume subjects enroll constant rate \\(J\\) intervals defined \\(0=\\omega_0<\\omega_1<\\ldots<\\omega_J<\\infty\\). denote enrollment rates \\[\\begin{equation}g(\\omega)=\\gamma_j\\geq 0\\label{eq:gj}\\end{equation}\\] \\(\\omega\\) interval \\((\\omega_{j-1},\\omega_j]\\), \\(j=0,1,2,\\ldots,J\\). assume \\(\\gamma_1>0\\), \\(j>1\\) assume \\(\\gamma_j\\ge 0\\). Letting \\(G_0=0\\) recursively define \\(j=1,\\ldots,J\\) \\[\\begin{equation}G_j=G(\\omega_j)=G_{j-1}+\\gamma_j(\\omega_j-\\omega_{j-1})\\label{eq:Gj}\\end{equation}\\] thus \\(\\omega\\[\\omega_{j-1},\\omega_j]\\) expected enrollment study time \\(\\omega\\) \\[\\begin{equation}G(\\omega)=G_{j-1}+\\gamma_j(\\omega-\\omega_{j-1}).\\label{eq:ENpw}\\end{equation}\\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_expected_events.html","id":"an-example-under-the-piecewise-model","dir":"Articles","previous_headings":"The piecewise model","what":"An example under the piecewise model","title":"Computing expected events by interval at risk","text":"consider example piecewise model assuming \\(J=3\\), \\(\\omega_j=1,2,7\\) \\(\\gamma_j=3,2,0\\) \\(j=1,2,3\\). assume \\(M=2\\) \\(t_m=4,\\infty\\), failure rates \\(\\lambda_m=.03,.06\\), dropout rates \\(\\eta_m=0.001,.002\\). plot following plot enrollment rate axis right failure dropout rate axis left. plot \\(\\omega\\) reverse order related integration equation \\(E\\{\\bar{n}(t_1,t_2)\\}\\) . also plotted vertical dot-dashed line point either enrollment rate failure (dropout) rate changes.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_expected_events.html","id":"organizing-calculations-under-the-piecewise-model","dir":"Articles","previous_headings":"The piecewise model","what":"Organizing calculations under the piecewise model","title":"Computing expected events by interval at risk","text":"now proceed define algorithms computing expected events observed interval model piecewise constant enrollment, failure rates, dropout rates. assume study duration \\(\\Omega=t_M\\). assume without loss generality sequence \\(t_m\\), \\(m=1,2,\\ldots, M\\) constant failure rate \\(\\lambda_m\\) dropout rate \\(\\eta_m\\) interval \\((t_{m-1},t_m]\\) well constant enrollment rate \\(\\gamma_m\\) interval \\((t_M-t_m,t_M-t_{m-1}]\\). Deriving intervals relatively straightforward exercise shown example . example, example , change points vertical lines drawn following scenario calculation purposes. define \\(m=1,\\ldots,M\\) intermediate probability calculations use calculating \\(\\bar n(t_{m-1},t_m)\\) follows: \\[\\begin{align} q_m&=P\\{\\min(X_m,Y_m)>t_m-t_{m-1}\\}=\\exp^{-(\\lambda_m+\\eta_m)(t_m-t_{m-1})} \\label{eq:qm}\\\\ Q_m&=P\\{\\min(X,Y)>t_m\\}=\\prod_{j=1}^m q_j\\label{eq:Qm}\\\\ d_m&=P\\{t_{m-1}<X\\le t_m,X\\le Y\\}\\\\ &=P\\{\\min(X,Y)>t_{m-1}\\}\\cdot P\\{0<\\min (X_m,Y_m)\\le t_m-t_{m-1},X_m\\le Y_m\\}\\\\ &=P\\{\\min(X,Y)>t_{m-1}\\}\\cdot P\\{0<\\min (X_m,Y_m)\\le t_m-t_{m-1}\\}\\cdot P\\{X_m\\le Y_m|0<\\min (X_m,Y_m)\\le t_m-t_{m-1}\\}\\\\ &=Q_{m-1}(1-e^{-(\\lambda_m+\\eta_m)(t_m-t_{m-1})}) \\frac{\\lambda_m}{\\lambda_m+\\eta_m}\\\\ \\bar n_m&=E\\{\\bar n(t_{m-1},t_m)\\} \\end{align}\\] Note \\(\\lambda_m+\\eta_m=0\\), \\(d_m=0\\). , \\[\\begin{align} \\bar n_m&=G(t_M-t_m)P\\{t_{m-1}<X\\leq t_m, X\\leq Y\\}+  \\int_{t_M-t_m}^{t_M-t_{m-1}} g(u) P\\{t_{m-1}< X\\leq t_M-u, X\\leq Y\\} du\\\\ &=G_{M+1-m}d_m+P\\{\\min(X,Y)>t_{m-1}\\}  \\int_0^{t_m-t_{m-1}}g_{M+1-m}P\\{X_m\\le v, X_m\\le Y_m\\}dv\\\\ &=G_{M+1-m}d_m  + \\frac{Q_{m-1}g_{M+1-m}\\lambda_m}{\\lambda_m+\\eta_m}  \\int_0^{t_m-t_{m-1}}\\left(1-\\exp^{-(\\lambda_m+\\eta_m)v}\\right)dv\\\\ &=G_{M+1-m}d_m  + \\frac{Q_{m-1}g_{M+1-m}\\lambda_m}{\\lambda_m+\\eta_m} \\left(t_m-t_{m-1}-\\frac{1-\\exp^{-(\\lambda_m+\\eta_m)(t_m-t_{m-1})}}{\\lambda_m+\\eta_m}\\right)\\\\ &=G_{M+1-m}d_m  + \\frac{Q_{m-1}g_{M+1-m}\\lambda_m}{\\lambda_m+\\eta_m} \\left(t_m-t_{m-1}-\\frac{1-q_m}{\\lambda_m+\\eta_m}\\right) \\end{align}\\] now add \\(q_m\\), \\(Q_m\\), \\(d_m\\) calculations enable computation \\(\\bar n_m\\), expected events time interval.","code":"namesTem <- names(x)  names(x) <- c(\"m\", \"tm\", \"lambda\", \"eta\", \"j\", \"omega\", \"gamma\")  y <- x %>%   mutate(     tdel = tm - lag(tm, default = 0),     q = exp(-(lambda + eta) * tdel),     Q = lag(cumprod(q), default = 1),     d = Q * (1 - q) * lambda / (lambda + eta),     G = c(5, 5, 3, 0),     nbar = G * d + (lambda * Q * gamma) / (lambda + eta) * (tdel - (1 - q) / (lambda + eta)))  yy <- y  names(yy) <- c(   \"$m$\", \"$t_m$\", \"$\\\\lambda_m$\", \"$\\\\eta_m$\", \"$j$\",   \"$\\\\omega_j=t_M-t_{m-1}$\",   \"$\\\\gamma_j$\", \"$t_m-t_{m-1}$\", \"$q_m$\", \"$Q_{m-1}$\",   \"$d_m$\", \"$G_{j-1}$\", \"$\\\\bar{n}_m$\" )  yy <- yy %>% select(c(1:7, 12, 8:11, 13))  yy %>%   kable(digits = 4) %>%   kable_styling(c(\"striped\", \"bordered\")) %>%   add_header_above(c(     \"Failure and dropout rates\" = 4,     \"Enrollment\" = 4,     \"Events by time period\" = 5))"},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_expected_events.html","id":"verifying-calculations","dir":"Articles","previous_headings":"The piecewise model","what":"Verifying calculations","title":"Computing expected events by interval at risk","text":"check total number events using gsDesign function eEvents(). First, sum \\(\\bar{n}_m\\) values sum(y$nbar) get 1.083773 compare : Next, examine periods defined failRates: Now group rows y intervals. Finally, approximate specific numbers using simulation. First, simulate large dataset confirm simulation targeted enrollment pattern. Now confirm expected events follow-interval given targeted enrollment.","code":"Events <- gsDesign::eEvents(   lambda = y$lambda,   eta = y$eta,   gamma = y$gamma[length(y$gamma):1],   S = y$tdel[1:(length(y$tdel) - 1)],   R = y$tdel[(length(y$tdel):1)],   T = max(y$tm))$d  Events #> [1] 1.083773 eEvents_df(   enrollRates = tibble(duration = c(1, 1), rate = c(3, 2)),   failRates = tibble(duration = c(4, 3), failRate = c(.03, .06), dropoutRate = c(.001, .002)),   totalDuration = 7,   simple = FALSE) #> # A tibble: 2 × 3 #>       t failRate Events #>   <dbl>    <dbl>  <dbl> #> 1     0     0.03  0.564 #> 2     4     0.06  0.519 y %>%   mutate(t = c(0, 4, 4, 4)) %>%   group_by(t) %>%   summarise(     failRate = first(lambda),     Events = sum(nbar)) #> # A tibble: 2 × 3 #>       t failRate Events #>   <dbl>    <dbl>  <dbl> #> 1     0     0.03  0.564 #> 2     4     0.06  0.519 nsim <- 1e6 xx <- simtrial::simPWSurv(   n = nsim,   block = (rep(\"xx\", 4)),   enrollRates = tibble(rate = c(3, 2) * nsim / 5, duration = c(1, 1)),   failRates = tibble(     Stratum = \"All\", period = 1:2, Treatment = \"xx\",     rate = c(.03, .06), duration = c(4, Inf)   ),   dropoutRates = tibble(     Stratum = \"All\", period = 1:2, Treatment = \"xx\",     rate = c(.001, .002), duration = c(4, Inf)   ))  save(xx, file = \"./fixtures/compute_expected_events.Rdata\") load(\"./fixtures/compute_expected_events.Rdata\") ecat <- 1 + (xx$enrollTime > 1) + (xx$enrollTime > 2) cat(\"Enrollment pattern: \", table(ecat) / nsim) #> Enrollment pattern:  0.599697 0.399995 0.000308 yy <- xx %>%   simtrial::cutData(7) %>%   filter(event == 1) %>%   mutate(tcat = 4 + (tte > 4) + (tte > 5) + (tte > 6)) cat(\"Event by interval: \", table(yy$tcat) / nsim * 5, \"\\n\") #> Event by interval:  0.56421 0.2591 0.19403 0.067865 cat(\"Total events: \", sum(yy$event) / nsim * 5) #> Total events:  1.085205"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_npe_bound.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Computing Bounds Under Non-Constant Treatment Effect","text":"consider group sequential designs possibly non-constant treatment effects time. can useful situations assumed non-proportional hazards model laid vignette(\"NPEbackground\", package=\"gsdmvn\"). general, assume \\(K\\ge 1\\) analyses statistical information \\(\\mathcal{}_k\\) information fraction \\(t_k=\\mathcal{}_k/\\mathcal{}_k\\) analysis \\(k\\), \\(1\\le k\\le K\\). denote null hypothesis \\(H_{0}\\): \\(\\theta(t)=0\\) alternate hypothesis \\(H_1\\): \\(\\theta(t)=\\theta_1(t)\\) \\(t> 0\\) \\(t\\) represents information fraction study. study planned stop information fraction \\(t=1\\), define \\(\\theta(t)\\) \\(t>0\\) since trial can overrun planned statistical information final analysis. , use shorthand notation \\(\\theta\\) represent \\(\\theta()\\), \\(\\theta=0\\) represent \\(\\theta(t)\\equiv 0\\) \\(t\\) \\(\\theta_1\\) represent \\(\\theta_i(t_k)\\), effect size analysis \\(k\\), \\(1\\le k\\le K\\). purposes, \\(H_0\\) represent treatment difference, represent non-inferiority hypothesis. Recall assume \\(K\\) analyses bounds \\(-\\infty \\le a_k< b_k<\\le \\infty\\) \\(1\\le k < K\\) \\(-\\infty \\le a_K\\le b_K<\\infty\\). denote probability crossing upper boundary analysis \\(k\\) without previously crossing bound \\[\\alpha_{k}(\\theta)=P_{\\theta}(\\{Z_{k}\\geq b_{k}\\}\\cap_{j=1}^{k-1}\\{a_{j}\\le Z_{j}< b_{j}\\}),\\] \\(k=1,2,\\ldots,K.\\) total probability crossing upper bound prior crossing lower bound denoted \\[\\alpha(\\theta)\\equiv\\sum_{k=1}^K\\alpha_k(\\theta).\\] non-binding bounds, define probability \\[\\alpha_{k}^{+}(\\theta)=P_{\\theta}\\{\\{Z_{k}\\geq b_{k}\\}\\cap_{j=1}^{k-1} \\{Z_{j}< b_{j}\\}\\}\\] ignores lower bounds computing upper boundary crossing probabilities. non-binding Type error probability ever crossing upper bound \\(\\theta=0\\). value \\(\\alpha^+_{k}(0)\\) commonly referred amount Type error spent analysis \\(k\\), \\(1\\leq k\\leq K\\). total upper boundary crossing probability trial denoted one-sided scenario \\[\\alpha^+(\\theta) \\equiv\\sum_{k=1}^{K}\\alpha^+_{k}(\\theta).\\] primarily interested \\(\\alpha(\\theta)\\) compute power \\(\\theta > 0\\). Type error, may interested \\(\\alpha(0)\\) binding lower bounds, often consider non-binding Type error calculations, \\(\\alpha^{+}(0)\\). denote probability crossing lower bound analysis \\(k\\) without previously crossing bound \\[\\beta_{k}(\\theta)=P_{\\theta}((Z_{k}< a_{k}\\}\\cap_{j=1}^{k-1}\\{ a_{j}\\le Z_{j}< b_{j}\\}).\\] Efficacy bounds \\(b_k\\), \\(1\\le k\\le K\\), group sequential design derived control Type level \\(\\alpha=\\alpha(0)\\). Lower bounds \\(a_k\\), \\(1\\le k\\le K\\) may used control boundary crossing probabilities either null hypothesis (2-sided testing), alternate hypothesis hypothesis (futility testing). Thus, may consider 3 values \\(\\theta(t)\\): null hypothesis \\(\\theta_0(t)=0\\) computing efficacy bounds, value \\(\\theta_1(t)\\) computing lower bounds, value \\(\\theta_a(t)\\) computing sample size power. refer information 3 assumptions \\(\\mathcal{}^{(0)}(t)\\), \\(\\mathcal{}^{(1)}(t)\\), \\(\\mathcal{}^{()}(t)\\), respectively. Often assume \\(\\mathcal{}(t)=\\mathcal{}^{(0)}(t)=\\mathcal{}^{(1)}(t)=\\mathcal{}^{()}(t).\\) note information may differ different values \\(\\theta(t)\\). fixed designs,  computes sample size based different variances null alternate hypothesis.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_npe_bound.html","id":"spending-bounds","dir":"Articles","previous_headings":"","what":"Spending bounds","title":"Computing Bounds Under Non-Constant Treatment Effect","text":"consider different boundary types gsDesign package simplify two types according whether lower bounds binding non-binding. concept implicitly derive Z-value bounds \\(a_k, b_k, k=1,\\cdots,K\\) based probabilities specified following table. include test.type argument gsDesign::gsDesign() function reference. Boundary crossing probabilities used set Z-value boundaries can reduced just two types distinguishing whether lower bounds binding non-binding: Reduced options boundary crossing probabilities used set Z-value boundaries second table used \\(\\theta=0\\) derive upper bound control Type error cases. chosen arbitrary \\(\\theta\\) 0 test.type, \\(\\theta_a\\) \\(\\beta\\)-spending arbitrary \\(\\theta_1\\) otherwise. note one-sided design let \\(\\beta_k(\\theta)=0\\) \\(a_k=-\\infty, k=1,\\cdots,K\\). test.type=3, 4 let \\(\\theta=\\theta_a\\), test.type=5, 6 \\(\\theta\\ge 0\\) arbitrary. note asymmetric \\(\\alpha\\)-spending bounds can derived using test.type > 2 \\(\\theta=0.\\)","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_npe_bound.html","id":"two-sided-testing-and-design","dir":"Articles","previous_headings":"","what":"Two-sided testing and design","title":"Computing Bounds Under Non-Constant Treatment Effect","text":"denote alternative \\(H_{}\\): \\(\\theta(t)=\\theta_a(t)\\); always assume \\(H_a\\) power calculations; using \\(\\beta\\)-spending also use \\(H_a\\) controlling lower boundary \\(a_k\\) crossing probabilities letting \\(\\theta=\\theta_a\\) lower bound spending. value \\(\\theta(t)>0\\) reflect positive benefit. restrict alternate hypothesis \\(\\theta_a(t)>0\\) \\(t\\). value \\(\\theta(t)\\) referred (standardized) treatment effect information fraction \\(t\\). assume interest stopping early good evidence reject one hypothesis favor . \\(a_k= -\\infty\\) analysis \\(k\\) \\(1\\le k\\le K\\) alternate hypothesis rejected analysis \\(k\\); .e., futility bound analysis \\(k\\). \\(k=1,2,\\ldots,K\\), trial stopped analysis \\(k\\) reject \\(H_0\\) \\(a_j<Z_j< b_j\\), \\(j=1,2,\\dots,-1\\) \\(Z_k\\geq b_k\\). trial continues stage \\(k\\) without crossing bound \\(Z_k\\leq a_k\\) \\(H_1\\) rejected favor \\(H_0\\), \\(k=1,2,\\ldots,K\\). Note \\(a_K< b_K\\) possibility completing trial without rejecting \\(H_0\\) \\(H_1\\) unless \\(a_K=b_K.\\)","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_npe_bound.html","id":"haybittle-peto-and-spending-bounds","dir":"Articles","previous_headings":"Two-sided testing and design","what":"Haybittle-Peto and spending bounds","title":"Computing Bounds Under Non-Constant Treatment Effect","text":"recursive algorithm previous section allows computation spending bounds Haybittle-Peto bounds. Haybittle-Peto efficacy bound, one normally set \\(b_k=\\Phi^{-1}(1-\\epsilon)\\) \\(k=1,2,\\ldots,K-1\\) small \\(\\epsilon>0\\) \\(\\epsilon= 0.001\\) yields \\(b_k=3.09\\). original proposal use \\(b_K=\\Phi^{-1}(1-\\alpha)\\) final analysis, fully control one-sided Type error level \\(\\alpha\\) suggest computing final bound \\(b_K\\) using algorithm \\(\\alpha(0)=\\alpha\\). Bounds computed spending \\(\\alpha_k(0)\\) analysis \\(k\\) can computed using equation (9) \\(b_1\\). \\(k=2,\\ldots,K\\) algorithm previous section used. noted Jennison Turnbull (1999), \\(b_1,\\ldots,b_K\\) determined null hypothesis depend \\(t_k\\) \\(\\alpha_k(0)\\) dependence \\(\\mathcal{}_k\\), \\(k=1,\\ldots,K\\). computing bounds based \\(\\beta_k(\\theta)\\), \\(k=1,\\ldots,K\\), \\(\\theta(t_k)\\neq 0\\) additional dependency \\(a_k\\) depending \\(t_k\\) \\(b_k\\), \\(k=1,\\ldots,K\\), also final total information \\(\\mathcal{}_K\\). Thus, spending bound something null hypothesis needs recomputed time \\(\\mathcal{}_K\\) changes, whereas needs computed \\(\\theta(t_k)=0\\), \\(k=1,\\ldots,K\\).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_npe_bound.html","id":"bounds-based-on-boundary-families","dir":"Articles","previous_headings":"Two-sided testing and design","what":"Bounds based on boundary families","title":"Computing Bounds Under Non-Constant Treatment Effect","text":"Assume constants \\(b_1^*,\\ldots,b_K^*\\) total targeted one-sided Type error \\(\\alpha\\). wish find \\(C_u\\) function \\(t_1,\\ldots t_K\\) \\(b_k=C_ub_k^*\\) \\(\\alpha(0)=\\alpha.\\) Thus, problem solve \\(C_u\\). \\(a_k\\), \\(k=1,2,\\ldots,K\\) fixed simple root finding problem. Since one normally normally uses non-binding efficacy bounds, normally case \\(a_k=-\\infty\\), \\(k=1,\\ldots,K\\) problem. Now assume constants \\(a_k^*\\) wish find \\(C_l\\) \\(a_k=C_la_k^*+\\theta(t_k)\\sqrt{\\mathcal{}_k}\\) \\(k=1,\\ldots,K\\) \\(\\beta(\\theta)=\\beta\\). use constant upper bounds previous paragraph, finding \\(C_l\\) simple root-finding problem. 2-sided symmetric bounds \\(a_k=-b_k\\), \\(k=1,\\ldots,K\\), need solve \\(C_u\\) use simple root finding. point, solve type bound asymmetric upper lower bounds.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_compute_npe_bound.html","id":"sample-size","dir":"Articles","previous_headings":"","what":"Sample size","title":"Computing Bounds Under Non-Constant Treatment Effect","text":"sample size, assume \\(t_k\\), \\(\\theta(t_k)\\) \\(1,\\ldots,K\\) fixed. assume \\(\\beta(\\theta)\\) decreasing \\(\\mathcal{}\\) decreasing. automatically case \\(\\theta(t_k)>0\\), \\(k=1,\\ldots,K\\) many cases. Thus, information required done search \\(\\mathcal{I_K}\\) yields \\(\\alpha(\\theta)\\) yields targeted power.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Design Using Average Hazard Ratio","text":"consider fixed group sequential design non-proportional hazards testing logrank test. focus primarily average hazard ratio approach, expanding asymptotic approach Mukhopadhyay et al. (2020) group sequential design complex enrollment assumptions. theoretical background provided vignettes package. provide basic examples along lines Lin et al. (2020) illustration design considerations following assumptions: Proportional hazards Short delayed effect Longer delayed effect Crossing survival Illustrations include Expected average hazard ratio (AHR) time. Expected event accumulation time. impact planned study duration required number events. Power across scenarios trial designed assumption short delayed effect. Timing interim analyses. \\(\\alpha\\)-spending considerations. focus results rather code, hidden code can revealed examples.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"packages-used","dir":"Articles","previous_headings":"","what":"Packages used","title":"Design Using Average Hazard Ratio","text":"primary packages needed gsdmvn gsDesign2 likely combined gsDesign2 near future. packages used supportive.","code":"library(gsDesign) library(ggplot2) library(dplyr) library(gt) library(tidyr) library(tibble) devtools::load_all()"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"scenarios","dir":"Articles","previous_headings":"","what":"Scenarios","title":"Design Using Average Hazard Ratio","text":"Expected enrollment duration 18 months piecewise constant enrollment rates escalating every 2 months month 6 enrollment assumed reached steady state. later assume similar ramp-period 24 months expected enrollment duration. consider following failure rate assumptions: Control group exponential failure rate median 14 months. Constant hazard ratio 0.7 (experimental/control). Control group exponential failure rate median 10 months. Hazard ratio 1 6 months followed hazard ratio 0.6. Control group exponential failure rate median 10 months. Hazard ratio 1 6 months followed hazard ratio 0.6. Control group exponential failure rate median 10 months. Hazard ratio 1.5 4 months followed hazard ratio 0.5.  survival curves 4 scenarios shown :  average hazard ratio 4 scenarios shown . note Shorter delayed effect scenario, average hazard ratio approaches PH scenario study duration 36 months.  number events 4 scenarios shown . 3 NPH scenarios events accumulate faster PH scenario due lower control median /delayed effect. , see slight variations control failure rates potential delayed effect can substantially accelerate accumulation events. event-based cutoff analysis slight variations can lead earlier analyses anticipated average hazard ratio expected longer follow-never achieved. examine implications .","code":"# Set the enrollment table of totally 24 month  enroll24 <- tibble(   Stratum = rep(\"All\", 4),     # un-stratified   duration = c(rep(2, 3), 18), # 6 month ramp-up of enrollment, 24 months enrollment time target   rate = 1:4                   # ratio of the enrollment rate   ) # Adjust enrollment rates to enroll 100 subjects enroll24$rate <- enroll24$rate * 100 / sum(enroll24$duration * enroll24$rate)  # Set the enrollment table for 18 month expected enrollment   enroll18 <- tibble(   Stratum = rep(\"All\", 4),     # un-stratified   duration = c(rep(2, 3), 12), # 6 month ramp-up of enrollment, 18 months enrollment time target   rate = 1:4                   # ratio of the enrollment rate   ) # Adjust enrollment rates to enroll 100 subjects enroll18$rate <- enroll18$rate * 100 / sum(enroll18$duration * enroll18$rate)  # Put these in a single tibble by scenario # We will use 18 month enrollment for delayed effect and crossing hazards scenarios enrollRates <- rbind(   enroll18 %>% mutate(Scenario = \"PH\"),   enroll18 %>% mutate(Scenario = \"Shorter delayed effect\"),   enroll18 %>% mutate(Scenario = \"Longer delayed effect\"),   enroll18 %>% mutate(Scenario = \"Crossing\") ) Month <- c(0, 4, 6, 44) duration <- Month - c(0, Month[1:3]) control_rate <- log(2) / c(rep(16, 4), rep(14, 4), rep(14, 4)) s <- tibble(Scenario = c(rep(\"PH\", 4), rep(\"Delayed effect\", 4), rep(\"Crossing\", 4)),             Treatment = rep(\"Control\", 12),             Month = rep(Month, 3),             duration = rep(duration, 3),             rate = control_rate,             hr = c(rep(.7, 4), c(1, 1, 1, .575), c(1.5,1.5, .5, .5)))  s <- rbind(s,            s %>% mutate(Treatment = \"Experimental\", rate = rate * hr)) %>%   group_by(Scenario, Treatment) %>%   mutate(Survival = exp(-cumsum(duration * rate))) ggplot(s, aes(x = Month, y = Survival, col = Scenario, lty = Treatment)) +    geom_line() +   scale_y_log10(breaks = (1 : 10) / 10, lim = c(.1, 1))+   scale_x_continuous(breaks = seq(0, 42, 6)) # get 4 scenarios control_median <- c(14, 12, 12, 12) Month <- c(0, 4, 6, 44) duration <- Month - c(0, Month[1:3]) # HR by time period for each scenario hr <- c(rep(.7, 4),         # constant hazard ratio of 0.7         1, 1, .6, .6,       # hazard ratio of 1 for 4 months followed by a hazard ratio of 0.6.         1, 1, 1, .6,        # hr = 1 for 6 months followed by hr = .6         1.5, 1.5, .5, .5)   # hazard ratio of 1.5 for 4 months followed by a hazard ratio of 0.5. # Put parameters together in a tibble s <- tibble(   Scenario = c(rep(\"PH\", 4), rep(\"Shorter delayed effect\", 4), rep(\"Longer delayed effect\", 4), rep(\"Crossing\", 4)),   Treatment = rep(\"Control\", 16),   Month = rep(Month, 4), # Periods for constant HR    duration = rep(duration, 4),   rate = log(2) / c(rep(control_median[1], 4),                      rep(control_median[2], 4),                      rep(control_median[3], 4),                      rep(control_median[4], 4)),   hr = hr)  # calculate the survival at each change point for each scenario s <- rbind(s, s %>% mutate(Treatment = \"Experimental\", rate = rate * hr)) %>%      group_by(Scenario, Treatment) %>%      mutate(Survival = exp(-cumsum(duration * rate))) # plot the survival curve ggplot(s, aes(x = Month, y = Survival, col = Scenario, lty = Treatment, shape = Treatment)) +    geom_line() +    annotate(\"text\", x = 18, y = .1, label = \"Control for scenarios other than PH have same survival\") +   scale_y_log10(breaks = (1:10) /10, lim = c(.07, 1)) +   scale_x_continuous(breaks = seq(0, 42, 6)) +   ggtitle(\"Survival over time for 4 scenarios studied\") # Durations to be used in common for all failure rate scenarios dur <- Month[2:4] - Month[1:3]  # Set the failure table  # We use exponential failure, proportional hazards failRates <- rbind(   tibble(Scenario = \"PH\", Stratum = \"All\",           duration = dur, failRate = log(2) / 14,          hr = hr[1], dropoutRate = .001),   tibble(Scenario = \"Shorter delayed effect\", Stratum = \"All\",           duration = dur, failRate = log(2) / 11,          hr = hr[6:8], dropoutRate = .001),   tibble(Scenario = \"Longer delayed effect\", Stratum = \"All\",           duration = dur, failRate = log(2) / 11,          hr = hr[10:12], dropoutRate = .001),   tibble(Scenario = \"Crossing\", Stratum = \"All\",           duration = dur, failRate = log(2) / 11,          hr = hr[14:16], dropoutRate = .001))  hr <- do.call(   rbind,   lapply(     c(\"PH\", \"Shorter delayed effect\", \"Longer delayed effect\", \"Crossing\"),      function(x){       AHR(enrollRates = enrollRates %>% filter(Scenario == x),            failRates = failRates %>% filter(Scenario == x),           totalDuration = c(.001, seq(4, 44, 4))) %>% mutate(Scenario = x)     })) ggplot(hr, aes(x = Time, y = AHR, col = Scenario)) +    geom_line() +    scale_x_continuous(breaks = seq(0, 42, 6)) +   ggtitle(\"Average hazard ratio (AHR) by study duration\",           subtitle = \"Under the 4 scenarios examined\") ggplot(hr, aes(x = Time, y = `Events`, col = Scenario)) +    geom_line() +    scale_x_continuous(breaks = seq(0, 42, 6)) +   ylab(\"Expected events per 100 enrolled\") +   ggtitle(\"Expected event accumulation under the 4 scenarios studied\")"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"fixed-design-using-ahr-and-logrank","dir":"Articles","previous_headings":"Sample Size and Events by Scenarios","what":"Fixed Design using AHR and Logrank","title":"Design Using Average Hazard Ratio","text":"power fixed design 90% 2.5% one-sided Type error different scenarios consideration. now assume 18 month enrollment pattern scenarios. PH Shorter delayed effect scenarios need similar AHR, number events sample size 36 month study. two scenarios crossing survival curves large effect delay require substantially larger sample sizes due achieving similar AHR month 36. Assuming shorter delayed effect primary scenario wish protect power, long trial optimize tradeoffs sample size, AHR events required? inform tradeoff looking sizing trial different assumed trial durations failure rates assumed relative enrollment rates. counts events required perhaps interesting 24 month trial requires almost twice events powered 90% compared trial 42 months duration. study, consider 36 month trial duration reasonable tradeoff time, sample size power presumed delayed effect 4 months followed hazard ratio 0.6 thereafter.","code":"ss_ahr_fixed <- do.call(   rbind,   lapply(c(\"PH\", \"Shorter delayed effect\", \"Longer delayed effect\", \"Crossing\"),           function(x) {            xx <- gs_design_ahr(enrollRates = enrollRates %>% filter(Scenario == x),                                failRates = failRates %>% filter(Scenario == x),                                analysisTimes = 36,                                upper = gs_b,                                 upar = qnorm(.975),                                lower = gs_b,                                 lpar = -Inf,                                alpha = .025,                                beta = .1)            ans <- xx$analysis %>% select(Time, N, Events, AHR) %>%  mutate(Scenario = x)            return(ans)          }          )   )   ss_ahr_fixed %>%    gt() %>%    fmt_number(columns = 1:3,decimals = 0) %>%    fmt_number(columns = 4, decimals = 3)  %>%   tab_header(title = \"Sample Size and Events Required by Scenario\",              subtitle = \"36 Month Trial duration, 2.5% One-sided Type 1 Error, 90% Power\") do.call(   rbind,   lapply(c(24, 30, 36, 42),           function(x){            ans <- gs_design_ahr(enrollRates = enrollRates %>% filter(Scenario == \"Shorter delayed effect\"),                                 failRates = failRates %>% filter(Scenario == \"Shorter delayed effect\"),                                 analysisTimes = x,                                 upper = gs_b, upar = qnorm(.975),                                 lower = gs_b, lpar = -Inf,                                 alpha = .025,                                 beta = .1)$analysis %>%               select(Time, N, Events, AHR) %>%               mutate(Scenario = \"Shorter delayed effect\")            return(ans)          }     )   ) %>%    gt() %>%    fmt_number(columns = 1:3, decimals = 0) %>%    fmt_number(columns = 4, decimals = 3) %>%   tab_header(title = \"Sample Size and Events Required by Trial Duration\",              subtitle = \"Delayed Effect of 4 Months, HR = 0.6 Thereafter; 90% Power\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"alternate-hypothesis-mapping","dir":"Articles","previous_headings":"Sample Size and Events by Scenarios","what":"Alternate Hypothesis Mapping","title":"Design Using Average Hazard Ratio","text":"different scenarios interest, can examine expected number events time periods interest. Recall alternate hypothesis assumes treatment effect (HR=1) 4 months HR = 0.6 thereafter. scenarios, wish base futility bound assumption plus number events first 4 months 4 months, can compute average hazard ratio alternate hazard ratio scenario 20 months follows. can see interim futility spending bound based alternate hypothesis can depend fairly heavily enrollment control failure rate. Note also time interim analysis, alternate hypothesis AHR can computed fashion based observed events time period. Note can quite different scenario HR; e.g., PH, assume HR=0.7 throughout, futility bound comparison, compute blinded AHR decreases analysis alternate hypothesis.","code":"events_by_time_period <- NULL  for(g in c(\"PH\", \"Shorter delayed effect\", \"Longer delayed effect\", \"Crossing\")){     events_by_time_period <- rbind(       events_by_time_period,              AHR(enrollRates = enrollRates %>% filter(Scenario == g),           failRates = failRates %>% filter(Scenario == g),           totalDuration = c(12, 20, 28, 36), simple = FALSE) %>% mutate(Scenario = g)) } # Time periods for each scenario were 0-4, 4-6, and 6+ # Thus H1 has HR as follows hr1 <- tibble(t = c(0, 4, 6), hr1 = c(1, .6, .6))  ahr_by_analysis <- events_by_time_period %>%    full_join(hr1) %>%   group_by(Scenario, Time) %>%   summarize(AHR1 = exp(sum(Events * log(hr1))/ sum(Events)))  ahr_by_analysis %>%    pivot_wider(names_from = Scenario, values_from = AHR1) %>%    gt() %>%    fmt_number(columns=2:5, decimals = 3)"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"group-sequential-design","dir":"Articles","previous_headings":"Sample Size and Events by Scenarios","what":"Group Sequential Design","title":"Design Using Average Hazard Ratio","text":"assume design delayed effect model delay long long-term average hazard ratio benefit strong. proportional hazards scenario, look power alternate scenarios. plan 36 month group sequential design Shorter delayed effect scenario. Interim analyses planned 12, 20, 28 months.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"ahr-method","dir":"Articles","previous_headings":"Sample Size and Events by Scenarios > Group Sequential Design","what":"AHR method","title":"Design Using Average Hazard Ratio","text":"scenario, now wish compute adjusted expected futility bounds power implied.","code":"analysisTimes <- c(12, 20, 28, 36) upar <- list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL, theta = 0) lpar <- list(sf = gsDesign::sfHSD, total_spend = .1, param = -2, timing = NULL, theta = NULL)  NPHasymmetric <- gs_design_ahr(enrollRates = enrollRates,                                failRates = failRates,                                ratio = 1, alpha = .025, beta = 0.1,                                # Information fraction not required (but available!)                                analysisTimes = analysisTimes,                                # Function to enable spending bound                                upper = gs_spending_bound,                                 lower = gs_spending_bound,                                # Spending function and parameters used                                upar = upar,                                 lpar = lpar)  summary(NPHasymmetric) %>% as_gt() do.call(   rbind,   lapply(     c(\"PH\", \"Shorter delayed effect\",\"Longer delayed effect\", \"Crossing\"),      function(x){       AHR1 <- (ahr_by_analysis %>% filter(Scenario == x))$AHR1              lparx <- lpar       lparx$theta1 <- -log(AHR1)              yy <- gs_power_ahr(enrollRates = enrollRates %>% filter(Scenario == x),                          failRates = failRates %>% filter(Scenario == x),                           events = NULL,                          analysisTimes = c(12, 20, 28, 36),                          upper = gs_spending_bound,                           upar = upar,                          lower = gs_spending_bound,                          lpar = lparx)$analysis %>%          mutate(Scenario = x)     }     )   ) %>%    gt() %>%    fmt_number(columns = \"Events\", decimals = 1) %>%    fmt_number(columns = 5:10, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_ahr.html","id":"weighted-logrank-method","dir":"Articles","previous_headings":"Sample Size and Events by Scenarios > Group Sequential Design","what":"Weighted Logrank Method","title":"Design Using Average Hazard Ratio","text":"investigate two types weighting scheme weight logrank method. fixed design first weighting scheme four scenario summarized follows. fixed design second weighting scheme four scenario summarized follows.","code":"do.call(   rbind,   lapply(     c(\"PH\", \"Shorter delayed effect\",\"Longer delayed effect\", \"Crossing\"),      function(x){       gs_design_wlr(enrollRates = enrollRates %>% filter(Scenario == x),                      failRates = failRates %>% filter(Scenario == x),                      weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5, tau = 4)},                     alpha = .025,                      beta = .1,                     upar = qnorm(.975),                     lpar = -Inf,                     analysisTimes = 44)$analysis %>%          mutate(Scenario = x)       }     )) %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4) # Ignore tau or (tau can be -1)  do.call(   rbind,   lapply(     c(\"PH\", \"Shorter delayed effect\",\"Longer delayed effect\", \"Crossing\"),      function(x){       gs_design_wlr(enrollRates = enrollRates %>% filter(Scenario == x),                      failRates = failRates %>% filter(Scenario == x),                      weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)},                     alpha = .025,                      beta = .1,                     upar = qnorm(.975),                     lpar = -Inf,                     analysisTimes = 44)$analysis %>%          mutate(Scenario = x)       }     )) %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_spending.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Trial design with spending under NPH","text":"vignette covers implement designs trials spending assuming non-proportional hazards. primarily concerned practical issues implementation rather design strategies, ignore design strategy.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_spending.html","id":"scenario-for-consideration","dir":"Articles","previous_headings":"","what":"Scenario for Consideration","title":"Trial design with spending under NPH","text":"set enrollment, failure dropout rates along assumptions enrollment duration times analyses. example, assume 4 analysis (3 interim analysis + 1 final analysis), conducted 18, 24, 30, 36 months trail starts. assume stratum enrollment last 12 months. first 2 months, second 2 months, third 2 months reminder month, enrollment rate \\(8:12:16:24\\). Please note \\(8:12:16:24\\) real enrollment rate. Instead, specifies enrollment rate ratio different duration. Moreover, assume hazard ratio (HR) first 3 month 0.9 thereafter 0.6. also assume survival time follow piecewise exponential distribution median 8 month first 3 months 14 month thereafter.","code":"K <- 4 analysisTimes <- c(18, 24, 30, 36) enrollRates <- tibble(   Stratum = \"All\",   duration = c(2, 2, 2, 6),   rate = c(8, 12, 16, 24))  enrollRates %>%    gt() %>%    tab_header(title = \"Table of Enrollment\") failRates <- tibble(   Stratum = \"All\",   duration = c(3, 100),   failRate = log(2) / c(8, 14),   hr = c(.9, .6),   dropoutRate = .001)  failRates %>%    gt() %>%    tab_header(title = \"Table of Failure Rate\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_spending.html","id":"deriving-power-for-a-given-sample-size","dir":"Articles","previous_headings":"","what":"Deriving Power for a Given Sample Size","title":"Trial design with spending under NPH","text":"section, discuss drive power, given known sample size. First, calculate number events statistical information (H0 H1) targeted analysis times. , can use gs_info_ahr() calculate (1) treatment effect (theta), (2) AHR, (3) statistical information (H0 H1) targeted number events. Finally, can calculate power yy using gs_power_npe(). table, find power 0.6267.","code":"xx <- AHR(enrollRates = enrollRates,            failRates = failRates,            totalDuration = analysisTimes)  xx %>% gt() #Events <- ceiling(xx$Events) yy <- gs_info_ahr(enrollRates = enrollRates,                    failRates = failRates,                    events = ceiling(xx$Events)) %>%    mutate(timing = info0 / max(info0))  yy %>%    gt() %>%    fmt_number(columns = 2:8, decimals = 4) zz <- gs_power_npe(   # set the treatment effet   theta = yy$theta,    # set the statistical information under H0 and H1   info = yy$info,    info0 = yy$info0,   # set the upper bound   upper = gs_b,    upar = gsDesign(k = K, test.type = 2, sfu = sfLDOF, alpha = .025, timing = yy$timing)$upper$bound,   # set the lower bound   lower = gs_b,   lpar = gsDesign(k = K, test.type = 2, sfu = sfLDOF, alpha = .025, timing = yy$timing)$lower$bound)  zz %>%    filter(Bound == \"Upper\") %>%   select(Analysis, Bound, Z, Probability, IF) %>%    gt() %>%    fmt_number(columns = 3:5, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_spending.html","id":"deriving-sample-size-for-a-given-power","dir":"Articles","previous_headings":"","what":"Deriving Sample Size for a Given Power","title":"Trial design with spending under NPH","text":"section, discuss calculate sample size given power (take given power 0.9 section). discuss calulation 2 scenario: (1) fixed design (2) group sequential design.","code":"target_power <- 0.9"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_spending.html","id":"fixed-design","dir":"Articles","previous_headings":"Deriving Sample Size for a Given Power","what":"Fixed Design","title":"Trial design with spending under NPH","text":"using fixed design, approximate sample size follows: inflate enrollment rates minx use fixed design, see achieves targeted power.","code":"minx <- ((qnorm(.025) / sqrt(zz$info0[K]) + qnorm(1 - target_power) / sqrt(zz$info[K])) / zz$theta[K])^2 minx #> [1] 1.875516 gs_power_npe(   theta = yy$theta[K],    info = yy$info[K] * minx,    info0 = yy$info0[K] * minx,   upar = qnorm(.975),    lpar = -Inf) %>%   filter(Bound == \"Upper\") %>%   select(Probability) #> # A tibble: 1 × 1 #>   Probability #>         <dbl> #> 1         0.9"},{"path":"https://merck.github.io/gsDesign2/articles/story_design_with_spending.html","id":"group-sequential-design","dir":"Articles","previous_headings":"Deriving Sample Size for a Given Power","what":"Group Sequential Design","title":"Trial design with spending under NPH","text":"power group sequential design final sample size bit lower: inflate bit overpowered. Now use gs_design_npe() inflate information proportionately power trial.","code":"gs_power_npe(   theta = yy$theta,    info = yy$info * minx,    info0 = yy$info0 * minx,   upper = gs_spending_bound,    lower = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)   ) %>%    filter(Bound == \"Upper\", Analysis == K) %>%    select(Probability) %>%    gt() gs_power_npe(   theta = yy$theta,    info = yy$info * minx * 1.2,    info0 = yy$info0 * minx * 1.2,   upper = gs_spending_bound,    lower = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)) %>%    filter(Bound == \"Upper\", Analysis == K) %>%    select(Probability) %>%    gt() gs_design_npe(   theta = yy$theta,    info = yy$info,    info0 = yy$info0,   upper = gs_spending_bound,    lower = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)) %>%    filter(Bound == \"Upper\", Analysis == K) %>%    select(Probability) %>%    gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Non-Proportional Effect Size in Group Sequential Design","text":"acronym NPES short non-proportional effect size. motivated primarily use designing time--event trial non-proportional hazards (NPH), simplified generalized concept . model likely useful rank-based survival tests beyond logrank test considered initially Tsiatis (1982). also useful situations treatment effect may vary time trial reason. generalize framework Chapter 2 Proschan, Lan, Wittes (2006) incorporate possibility treatment effect changing course trial systematic way. vignettes addresses distribution theory initial technical issues around computing boundary crossing probabilities bounds satisfying targeted boundary crossing probabilities applied generalize computational algorithms provided Chapter 19 Jennison Turnbull (1999) used compute boundary crossing probabilities well boundaries group sequential designs. Additional specifics around boundary computation, power sample size provided separate vignette.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"the-continuous-model-and-e-process","dir":"Articles","previous_headings":"The probability model","what":"The continuous model and E-process","title":"Non-Proportional Effect Size in Group Sequential Design","text":"consider simple example motivate distribution theory quite general applies across many situations. instance Proschan, Lan, Wittes (2006) immediately suggest paired observations, time--event binary outcomes endpoints theory applicable. assume given integer \\(N>0\\) \\(X_{}\\) independent, \\(=1,2,\\ldots\\). integer \\(K\\le N\\) assume perform analysis \\(K\\) times \\(0<n_1<n_2,\\ldots ,n_K = N\\) observations available analysis. Note confined \\(n\\le N\\), \\(N\\) can considered final planned sample size. Proschan, Lan, Wittes (2006) refer estimation E-process extend \\[\\hat{\\theta}_k = \\frac{\\sum_{=1}^{n_k} X_{}}{n_k}\\equiv \\bar X_{k}.\\] Proschan, Lan, Wittes (2006) used \\(\\delta\\) instead \\(\\theta\\) notation, stick closely notation Jennison Turnbull (1999) \\(\\theta\\) used. example, see \\(\\hat{\\theta}_k\\equiv\\bar X_k\\) represents sample average analysis \\(k\\), \\(1\\le k\\le K\\). survival endpoint, \\(\\hat\\theta_k\\) typically represent Cox model coefficient representing logarithm hazard ratio experimental vs control treatment \\(n_k\\) represent planned number events analysis \\(k\\), \\(1\\le k\\le K.\\) Denoting \\(t_k=n_k/N\\), assume real-valued function \\(\\theta(t)\\) \\(t\\ge 0\\) \\(1\\le k\\le K\\) \\[E(\\hat{\\theta}_k) =\\theta(t_k) =E(\\bar X_k).\\] models Proschan, Lan, Wittes (2006) Jennison Turnbull (1999) \\(\\theta(t)\\) equal constant \\(\\theta\\). assume \\(=1,2,\\ldots\\) \\[\\hbox{Var}(X_{})=1.\\] sample average variance assumption \\(1\\le k\\le K\\) \\[\\hbox{Var}(\\hat\\theta(t_k))=\\hbox{Var}(\\bar X_k) =  1/ n_k.\\] statistical information estimate \\(\\hat\\theta(t_k)\\) \\(1\\le k\\le K\\) case \\[ \\mathcal{}_k \\equiv \\frac{1}{\\hbox{Var}(\\hat\\theta(t_k))} = n_k.\\] now see \\(t_k\\), \\(1\\le k\\le K\\) -called information fraction analysis \\(k\\) \\(t_k=\\mathcal{}_k/\\mathcal{}_K.\\)","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"z-process","dir":"Articles","previous_headings":"The probability model","what":"Z-process","title":"Non-Proportional Effect Size in Group Sequential Design","text":"Z-process commonly used (e.g., Jennison Turnbull (1999)) used extend computational algorithm Chapter 19 Jennison Turnbull (1999) defining equivalently first second lines \\(k=1,\\ldots,K\\) \\[Z_{k} = \\frac{\\hat\\theta_k}{\\sqrt{\\hbox{Var}(\\hat\\theta_k)}}= \\sqrt{\\mathcal{}_k}\\hat\\theta_k= \\sqrt{n_k}\\bar X_k.\\] variance \\(1\\le k\\le K\\) \\[\\hbox{Var}(Z_k) = 1\\] expected value \\[E(Z_{k})= \\sqrt{\\mathcal{}_k}\\theta(t_{k})= \\sqrt{n_k}E(\\bar X_k) .\\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"b-process","dir":"Articles","previous_headings":"The probability model","what":"B-process","title":"Non-Proportional Effect Size in Group Sequential Design","text":"B-values mnemonic Brownian motion. \\(1\\le k\\le K\\) define \\[B_{k}=\\sqrt{t_k}Z_k\\] implies \\[ E(B_{k}) = \\sqrt{t_{k}\\mathcal{}_k}\\theta(t_k) = t_k \\sqrt{\\mathcal{}_K} \\theta(t_k) = \\mathcal{}_k\\theta(t_k)/\\sqrt{\\mathcal{}_K}\\] \\[\\hbox{Var}(B_k) = t_k.\\] example, \\[B_k=\\frac{1}{\\sqrt N}\\sum_{=1}^{n_k}X_i.\\] can useful think \\(B_k\\) sum independent random variables.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"conditional-independence-covariance-and-canonical-form","dir":"Articles","previous_headings":"The probability model","what":"Conditional independence, covariance and canonical form","title":"Non-Proportional Effect Size in Group Sequential Design","text":"assume independent increments B-process. , \\(1\\le j < k\\le K\\) \\[\\tag{1} B_k - B_j \\sim \\hbox{Normal} (\\sqrt{\\mathcal{}_K}(t_k\\theta(t_k)- t_j\\theta(t_j)), t_k-t_j)\\] independent \\(B_1,\\ldots,B_j\\). noted , given \\(1\\le k\\le K\\) example \\[B_j=\\sum_{=1}^{n_j}X_i / \\sqrt N.\\] independence sequence \\(X_i\\), \\(=1,2,\\ldots\\), immediately \\(1\\le j\\le k\\le K\\) \\[\\hbox{Cov}(B_j,B_k) = \\hbox{Var}(B_j) = t_j.\\] leads \\[\\hbox{Corr}(B_j,B_k)=\\frac{t_j}{\\sqrt{t_jt_k}}=\\sqrt{t_j/t_k}=\\hbox{Corr}(Z_j,Z_k)=\\hbox{Cov}(Z_j,Z_k)\\] covariance structure -called canonical form Jennison Turnbull (1999). example, \\[B_k=\\frac{1}{\\sqrt N}\\sum_{=1}^{n_k}X_i\\] \\[B_k-B_j=\\frac{1}{\\sqrt N}\\sum_{=n_j + 1}^{n_k}X_i\\] covariance obvious. assume independent increments B-process demonstrated simple example . , \\(1\\le j < k\\le K\\) \\[\\tag{1} B_k - B_j \\sim \\hbox{Normal} (\\mathcal{}_k\\theta(t_k)- \\mathcal{}_j\\theta(t_j), t_k-t_j)\\] independent \\(B_1,\\ldots,B_j\\). given \\(1\\le j\\le k\\le K\\) example \\[B_j=\\sum_{=1}^{n_j}X_i / (\\sqrt N\\sigma).\\] independence sequence \\(X_i\\), \\(=1,2,\\ldots\\), immediately \\(1\\le j\\le k\\le K\\) \\[\\hbox{Cov}(B_j,B_k) = \\hbox{Var}(B_j) = t_j/t_k =\\mathcal{}_j/\\mathcal{}_k.\\] leads \\[\\mathcal{}_j/\\mathcal{}_k=\\sqrt{t_j/t_k}=\\hbox{Corr}(B_j,B_k)=\\hbox{Corr}(Z_j,Z_k)=\\hbox{Cov}(Z_j,Z_k)\\] covariance structure -called canonical form Jennison Turnbull (1999). independence \\(B_j\\) \\[B_k-B_j=\\sum_{=n_j + 1}^{n_k}X_i/(\\sqrt N\\sigma)\\] obvious example.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"test-bounds-and-crossing-probabilities","dir":"Articles","previous_headings":"","what":"Test bounds and crossing probabilities","title":"Non-Proportional Effect Size in Group Sequential Design","text":"section define notation bounds boundary crossing probabilities group sequential design. also define algorithm computing bounds based targeted boundary crossing probability analysis. notation used elsewhere defining one- two-sided group sequential hypothesis testing. value \\(\\theta(t)>0\\) reflect positive benefit. \\(k=1,2,\\ldots,K-1\\), interim cutoffs \\(-\\infty \\le a_k< b_k\\le \\infty\\) set; final cutoffs \\(-\\infty \\le a_K\\leq b_K <\\infty\\) also set. infinite efficacy bound analysis means bound crossed analysis. Thus, \\(3K\\) parameters define group sequential design: \\(a_k\\), \\(b_k\\), \\(\\mathcal{}_k\\), \\(k=1,2,\\ldots,K\\).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_background.html","id":"notation-for-boundary-crossing-probabilities","dir":"Articles","previous_headings":"Test bounds and crossing probabilities","what":"Notation for boundary crossing probabilities","title":"Non-Proportional Effect Size in Group Sequential Design","text":"now apply distributional assumptions compute boundary crossing probabilities. use shorthand notation section \\(\\theta\\) represent \\(\\theta()\\) \\(\\theta=0\\) represent \\(\\theta(t)\\equiv 0\\) \\(t\\). denote probability crossing upper boundary analysis \\(k\\) without previously crossing bound \\[\\alpha_{k}(\\theta)=P_{\\theta}(\\{Z_{k}\\geq b_{k}\\}\\cap_{j=1}^{-1}\\{a_{j}\\le Z_{j}< b_{j}\\}),\\] \\(k=1,2,\\ldots,K.\\) Next, consider analogous notation lower bound. \\(k=1,2,\\ldots,K\\) denote probability crossing lower bound analysis \\(k\\) without previously crossing bound \\[\\beta_{k}(\\theta)=P_{\\theta}((Z_{k}< a_{k}\\}\\cap_{j=1}^{k-1}\\{ a_{j}\\le Z_{j}< b_{j}\\}).\\] symmetric testing analysis \\(k\\) \\(a_k= - b_k\\), \\(\\beta_k(0)=\\alpha_k(0),\\) \\(k=1,2,\\ldots,K\\). total lower boundary crossing probability trial denoted \\[\\beta(\\theta)\\equiv\\sum_{k=1}^{K}\\beta_{k}(\\theta).\\] Note can also set \\(a_k= -\\infty\\) analyses lower bound desired, \\(k=1,2,\\ldots,K\\). \\(k<K\\), can set \\(b_k=\\infty\\) upper bound desired. Obviously, \\(k\\), want either \\(a_k>-\\infty\\) \\(b_k<\\infty\\).","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"provided asymptotic distribution theory notation group sequential boundaries vignette(\"NPEbackground\", package=\"gsdmvn\"). vignettes generalize computational algorithms provided Chapter 19 Jennison Turnbull (1999) used compute boundary crossing probabilities well derive boundaries group sequential designs.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"asymptotic-normal-and-boundary-crossing-probabilities","dir":"Articles","previous_headings":"","what":"Asymptotic normal and boundary crossing probabilities","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"assume \\(Z_1,\\cdots,Z_K\\) multivariate normal distribution variance \\(1\\le k\\le K\\) \\[\\hbox{Var}(Z_k) = 1\\] expected value \\[E(Z_{k})= \\sqrt{\\mathcal{}_k}\\theta(t_{k})= \\sqrt{n_k}E(\\bar X_k) .\\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"notation-for-boundary-crossing-probabilities","dir":"Articles","previous_headings":"","what":"Notation for boundary crossing probabilities","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"use shorthand notation section \\(\\theta\\) represent \\(\\theta()\\) \\(\\theta=0\\) represent \\(\\theta(t)\\equiv 0\\) \\(t\\). denote probability crossing upper boundary analysis \\(k\\) without previously crossing bound \\[\\alpha_{k}(\\theta)=P_{\\theta}(\\{Z_{k}\\geq b_{k}\\}\\cap_{j=1}^{-1}\\{a_{j}\\le Z_{j}< b_{j}\\}),\\] \\(k=1,2,\\ldots,K.\\) Next, consider analogous notation lower bound. \\(k=1,2,\\ldots,K\\) denote probability crossing lower bound analysis \\(k\\) without previously crossing bound \\[\\beta_{k}(\\theta)=P_{\\theta}((Z_{k}< a_{k}\\}\\cap_{j=1}^{k-1}\\{ a_{j}\\le Z_{j}< b_{j}\\}).\\] symmetric testing analysis \\(k\\) \\(a_k= - b_k\\), \\(\\beta_k(0)=\\alpha_k(0),\\) \\(k=1,2,\\ldots,K\\). total lower boundary crossing probability trial denoted \\[\\beta(\\theta)\\equiv\\sum_{k=1}^{K}\\beta_{k}(\\theta).\\] Note can also set \\(a_k= -\\infty\\) analyses lower bound desired, \\(k=1,2,\\ldots,K\\); thus, use \\(\\alpha^+(\\theta)\\) notation . \\(k<K\\), can set \\(b_k=\\infty\\) upper bound desired. Obviously, \\(k\\), want either \\(a_k>-\\infty\\) \\(b_k<\\infty\\).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"recursive-algorithms-for-numerical-integration","dir":"Articles","previous_headings":"","what":"Recursive algorithms for numerical integration","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"now provide small update algorithm Chapter 19 Jennison Turnbull (1999) numerical integration required compute boundary crossing probabilites previous section also identifying group sequential boundaries satisfying desired characteristics. key calculations conditional power identitity equation (1) allows building recursive numerical integration identities enable simple, efficient numerical integration. define \\[g_1(z;\\theta) = \\frac{d}{dz}P(Z_1\\le z) = \\phi\\left(z - \\sqrt{\\mathcal{}_1}\\theta(t_1)\\right)\\tag{2}\\] \\(k=2,3,\\ldots K\\) recursively define subdensity function \\[\\begin{align} g_k(z; \\theta) &= \\frac{d}{dz}P_\\theta(\\{Z_k\\le z\\}\\cap_{j=1}^{k-1}\\{a_j\\le Z_j<b_j\\}) \\\\  &=\\int_{a_{k-1}}^{b_{k-1}}\\frac{d}{dz}P_\\theta(\\{Z_k\\le z |Z_{k-1}=z_{k-1}\\})g_{k-1}(z_{k-1}; \\theta)dz_{k-1}\\\\  &=\\int_{a_{k-1}}^{b_{k-1}}f_k(z_{k-1},z;\\theta)g_{k-1}(z_{k-1}; \\theta)dz_{k-1}.\\tag{3}  \\end{align}\\] bottom line notation p. 347 Jennison Turnbull (1999). However, \\(f_k()\\) takes slightly different form. \\[\\begin{align} f_k(z_{k-1},z;\\theta) &=\\frac{d}{dz}P_\\theta(\\{Z_k\\le z |Z_{k-1}=z_{k-1}\\})\\\\  &=\\frac{d}{dz}P_\\theta(B_k - B_{k-1} \\le z\\sqrt{t_k}-z_{k-1}\\sqrt{t_{k-1}})\\\\  &=\\frac{d}{dz}\\Phi\\left(\\frac{z\\sqrt{t_k}-z_{k-1}\\sqrt{t_{k-1}}-\\sqrt{\\mathcal{}_K}(t_k\\theta(t_k)- t_{k-1}\\theta(t_{k-1}))}{\\sqrt{t_k-t_{k-1}}}\\right)\\\\  &=\\frac{\\sqrt{t_k}}{\\sqrt{t_k-t_{k-1}}}\\phi\\left(\\frac{z\\sqrt{t_k}-z_{k-1}\\sqrt{t_{k-1}}-\\sqrt{\\mathcal{}_K}(t_k\\theta(t_k)- t_{k-1}\\theta(t_{k-1}))}{\\sqrt{t_k-t_{k-1}}}\\right)\\\\  &=\\frac{\\sqrt{\\mathcal{}_k}}{\\sqrt{\\mathcal{}_k-\\mathcal{}_{k-1}}}\\phi\\left(\\frac{z\\sqrt{\\mathcal{}_k}-z_{k-1}\\sqrt{\\mathcal{}_{k-1}}-(\\mathcal{}_k\\theta(t_k)- \\mathcal{}_{k-1}\\theta(t_{k-1}))}{\\sqrt{\\mathcal{}_k-\\mathcal{}_{k-1}}}\\right).\\tag{3} \\end{align}\\] worked towards last line due comparability equation (19.4) p. 347 Jennison Turnbull (1999) assumes \\(\\theta(t_k)=\\theta\\) constant \\(\\theta\\); re-write equation slightly : \\[f_k(z_{k-1},z;\\theta) = \\frac{\\sqrt{\\mathcal{}_k}}{\\sqrt{\\mathcal{}_k-\\mathcal{}_{k-1}}}\\phi\\left(\\frac{z\\sqrt{\\mathcal{}_k}-z_{k-1}\\sqrt{\\mathcal{}_{k-1}}-\\theta(\\mathcal{}_k- \\mathcal{}_{k-1})}{\\sqrt{\\mathcal{}_k-\\mathcal{}_{k-1}}}\\right).\\tag{4}\\] really difference computational algorithm boundary crossing probabilities Jennison Turnbull (1999) algorithm. Using recursive approach can compute \\(k=1,2,\\ldots,K\\) \\[\\alpha_{k}(\\theta)=\\int_{b_k}^\\infty g_k(z;\\theta)dz\\tag{5}\\] \\[\\beta_{k}(\\theta)=\\int_{-\\infty}^{a_k} g_k(z;\\theta)dz.\\tag{6}\\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"deriving-spending-boundaries","dir":"Articles","previous_headings":"","what":"Deriving spending boundaries","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"can now derive boundaries satisfying given boundary crossing probabilities using equations (2-6) . Suppose specified \\(b_1,\\ldots,b_{k-1}\\) \\(a_1,\\ldots,a_{k-1}\\) now wish derive \\(a_k\\) \\(b_k\\) equations (5) (6) hold. write upper bound function probability crossing wish derive. \\[\\pi_k(b;\\theta) = \\int_b^\\infty g_k(z;\\theta)dz\\] \\[\\pi_k^\\prime(b;\\theta) =\\frac{d}{db}\\pi_k(b;\\theta)= -g_k(b; \\theta).\\tag{7}\\] value \\(\\pi_k(b^{()};\\theta)\\) can use first order Taylor’s series expansion approximate \\[\\pi_k(b;\\theta)\\approx \\pi_k(b^{()};\\theta)+(b-b^{()})\\pi_k^\\prime(b^{()};\\theta)\\] set \\(b^{(+1)}\\) \\[\\alpha_k(\\theta)=\\pi_k(b^{()}; \\theta) + (b^{(+1)}-b^{()})\\pi^\\prime(b^{()};\\theta).\\] Solving \\(b^{(+1)}\\) \\[b^{(+)} = b^{()} + \\frac{\\alpha_k(\\theta) - \\pi_k(b^{()};\\theta)}{\\pi_k^\\prime(b^{()}; \\theta)}= b^{()} - \\frac{\\alpha_k(\\theta) - \\pi_k(b^{()};\\theta)}{g_k(b^{()}; \\theta)}\\tag{8}\\] iterate \\(|b^{(+1)}-b^{()}|<\\epsilon\\) tolerance level \\(\\epsilon>0\\) \\(\\pi_k(b^{(+1)};\\theta)-\\alpha_k(\\theta)\\) suitably small. simple starting value \\(k\\) \\[b^{(0)} = \\Phi^{-1}(1- \\alpha_k(\\theta)) + \\sqrt{\\mathcal{}_k}\\theta(t_k).\\tag{9}\\] Normally, \\(b_k\\) calculated \\(\\theta(t_k)=0\\) \\(k=1,2,\\ldots,K\\) simplifies . However, \\(a_k\\) computed analogously often use non-zero \\(\\theta\\) enable -called \\(\\beta\\)-spending.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"numerical-integration","dir":"Articles","previous_headings":"","what":"Numerical integration","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"numerical integration required compute boundary probabilities derive boundaries defined section 19.3 Jennison Turnbull (1999). single change replacement non-proportional effect size assumption equation (3) replacing equivalent equation (4) used constant effect size Jennison Turnbull (1999).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_npe_integration.html","id":"demonstrating-calculations","dir":"Articles","previous_headings":"Numerical integration","what":"Demonstrating calculations","title":"Numerical Integration Non-Proportional Effect Size in Group Sequential Design","text":"walk perform basic calculations . basic scenario one interim analysis addition final analysis. target Type error \\(\\alpha=0.025\\) Type II error \\(\\beta = 0.1\\), latter corresponding target 90% power. assume power spending function \\(\\rho=2\\) bounds. , information fraction \\(t\\), cumulative spending \\(\\alpha \\times t^2\\) upper bound \\(\\beta \\times t^2\\) lower bound. Statistical information 1 first analysis 4 final analysis, leading information fraction \\(t_1= 1/4, t_2=1\\) interim final, respectively. assume \\(\\theta_1 = .5\\), \\(\\theta_3=1.5\\). Set overall study parameters Calculate interim bounds Set numerical integration grid next (final) analysis set table numerical integration continuation region can subsequently use compute boundary crossing probabilities bounds second interim analysis. begin null hypothesis. columns resulting table - z - \\(Z\\)-values grid; recall interim test statistic normally distributed variance 1 - w - weights numerical integration - h - weights w times normal density can used numerical integration; demonstrate use probability crossing bound null hypothesis computed follows: now set numerical integration grid alternate hypothesis compute continuation probability. Compute initial iteration analysis 2 bounds initial estimate second analysis bounds computed way actual first analysis bounds. Compute actual boundary crossing probabilities initial approximations get actual boundary crossing probabilities second analysis, update numerical integration grids. null hypothesis, need update interval b2_0. get first order Taylor’s series approximation update bound, need derivative probability respect Z-value cutoff. given subdensity computed grid. , grid contains numerical integration weight w weight times subdensity h. Thus, get subdensity bound, estimated derivative boundary crossing probability, compute: see Taylor’s series update gotten us substantially closer targeted boundary probability. now update lower bound analogous fashion. Confirm gs_power_npe()","code":"# Information for both null and alternative info <- c(1, 4) # information fraction timing <- info / max(info)  # Type I error alpha <- 0.025 # Type II error (1 - power) beta <- 0.1 # Cumulative alpha-spending at IA, Final alphaspend <- alpha * timing^2 # Cumulative beta-spending at IA, Final betaspend <- beta * timing^2 # Average treatment effect at analyses theta <- c(1, 3)/2 # Upper bound under null hypothesis b1 <- qnorm(alphaspend[1], lower.tail = FALSE) # Lower bound under alternate hypothesis a1 <- qnorm(betaspend[1], mean = sqrt(info[1]) * theta[1]) # Compare probability of crossing vs target for bounds: cat(\"Upper bound =\", b1, \"Target spend =\", alphaspend[1],     \"Actual spend =\", pnorm(b1, lower.tail=FALSE)) #> Upper bound = 2.955167 Target spend = 0.0015625 Actual spend = 0.0015625 # Lower bound under alternate hypothesis a1 <- qnorm(betaspend[1], mean = sqrt(info[1]) * theta[1]) # Compare probability of crossing vs target for bounds: cat(\"Lower bound =\", a1, \"Target spend =\", betaspend[1],     \"Actual spend =\", pnorm(a1, mean = sqrt(info[1]) * theta[1])) #> Lower bound = -1.997705 Target spend = 0.00625 Actual spend = 0.00625 # Set up grid over continuation region # Null hypothesis grid1_0 <- h1(theta = 0, I = info[1], a = a1, b = b1) grid1_0 %>% head() #> $z #>   [1] -1.99770547 -1.95718607 -1.91666667 -1.87500000 -1.83333333 -1.79166667 #>   [7] -1.75000000 -1.70833333 -1.66666667 -1.62500000 -1.58333333 -1.54166667 #>  [13] -1.50000000 -1.45833333 -1.41666667 -1.37500000 -1.33333333 -1.29166667 #>  [19] -1.25000000 -1.20833333 -1.16666667 -1.12500000 -1.08333333 -1.04166667 #>  [25] -1.00000000 -0.95833333 -0.91666667 -0.87500000 -0.83333333 -0.79166667 #>  [31] -0.75000000 -0.70833333 -0.66666667 -0.62500000 -0.58333333 -0.54166667 #>  [37] -0.50000000 -0.45833333 -0.41666667 -0.37500000 -0.33333333 -0.29166667 #>  [43] -0.25000000 -0.20833333 -0.16666667 -0.12500000 -0.08333333 -0.04166667 #>  [49]  0.00000000  0.04166667  0.08333333  0.12500000  0.16666667  0.20833333 #>  [55]  0.25000000  0.29166667  0.33333333  0.37500000  0.41666667  0.45833333 #>  [61]  0.50000000  0.54166667  0.58333333  0.62500000  0.66666667  0.70833333 #>  [67]  0.75000000  0.79166667  0.83333333  0.87500000  0.91666667  0.95833333 #>  [73]  1.00000000  1.04166667  1.08333333  1.12500000  1.16666667  1.20833333 #>  [79]  1.25000000  1.29166667  1.33333333  1.37500000  1.41666667  1.45833333 #>  [85]  1.50000000  1.54166667  1.58333333  1.62500000  1.66666667  1.70833333 #>  [91]  1.75000000  1.79166667  1.83333333  1.87500000  1.91666667  1.95833333 #>  [97]  2.00000000  2.04166667  2.08333333  2.12500000  2.16666667  2.20833333 #> [103]  2.25000000  2.29166667  2.33333333  2.37500000  2.41666667  2.45833333 #> [109]  2.50000000  2.54166667  2.58333333  2.62500000  2.66666667  2.70833333 #> [115]  2.75000000  2.79166667  2.83333333  2.87500000  2.91666667  2.93591676 #> [121]  2.95516685 #>  #> $w #>   [1] 0.013506468 0.054025872 0.027395357 0.055555556 0.027777778 0.055555556 #>   [7] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [13] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [19] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [25] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [31] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [37] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [43] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [49] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [55] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [61] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [67] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [73] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [79] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [85] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [91] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #>  [97] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #> [103] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #> [109] 0.027777778 0.055555556 0.027777778 0.055555556 0.027777778 0.055555556 #> [115] 0.027777778 0.055555556 0.027777778 0.055555556 0.020305586 0.025666787 #> [121] 0.006416697 #>  #> $h #>   [1] 7.325795e-04 3.174772e-03 1.741296e-03 3.821460e-03 2.064199e-03 #>   [6] 4.452253e-03 2.396592e-03 5.151272e-03 2.763254e-03 5.918793e-03 #>  [11] 3.163964e-03 6.753608e-03 3.597711e-03 7.652841e-03 4.062610e-03 #>  [16] 8.611793e-03 4.555835e-03 9.623842e-03 5.073586e-03 1.068040e-02 #>  [21] 5.611075e-03 1.177092e-02 6.162560e-03 1.288302e-02 6.721409e-03 #>  [26] 1.400261e-02 7.280204e-03 1.511417e-02 7.830885e-03 1.620106e-02 #>  [31] 8.364929e-03 1.724594e-02 8.873556e-03 1.823116e-02 9.347967e-03 #>  [36] 1.913930e-02 9.779592e-03 1.995361e-02 1.016034e-02 2.065862e-02 #>  [41] 1.048287e-02 2.124051e-02 1.074078e-02 2.168766e-02 1.092888e-02 #>  [46] 2.199098e-02 1.104332e-02 2.214423e-02 1.108173e-02 2.214423e-02 #>  [51] 1.104332e-02 2.199098e-02 1.092888e-02 2.168766e-02 1.074078e-02 #>  [56] 2.124051e-02 1.048287e-02 2.065862e-02 1.016034e-02 1.995361e-02 #>  [61] 9.779592e-03 1.913930e-02 9.347967e-03 1.823116e-02 8.873556e-03 #>  [66] 1.724594e-02 8.364929e-03 1.620106e-02 7.830885e-03 1.511417e-02 #>  [71] 7.280204e-03 1.400261e-02 6.721409e-03 1.288302e-02 6.162560e-03 #>  [76] 1.177092e-02 5.611075e-03 1.068040e-02 5.073586e-03 9.623842e-03 #>  [81] 4.555835e-03 8.611793e-03 4.062610e-03 7.652841e-03 3.597711e-03 #>  [86] 6.753608e-03 3.163964e-03 5.918793e-03 2.763254e-03 5.151272e-03 #>  [91] 2.396592e-03 4.452253e-03 2.064199e-03 3.821460e-03 1.765603e-03 #>  [96] 3.257338e-03 1.499749e-03 2.757277e-03 1.265110e-03 2.317833e-03 #> [101] 1.059795e-03 1.934941e-03 8.816570e-04 1.604123e-03 7.283858e-04 #> [106] 1.320661e-03 5.975956e-04 1.079765e-03 4.868972e-04 8.767006e-04 #> [111] 3.939593e-04 7.068990e-04 3.165552e-04 5.660405e-04 2.525990e-04 #> [116] 4.501131e-04 2.001694e-04 3.554511e-04 1.151506e-04 1.375807e-04 #> [121] 3.249917e-05 probH0continue <- sum(grid1_0$h)  cat(\"Probability of continuing trial under null hypothesis\\n\",     \" Using numerical integration:\", probH0continue,      \"\\n  Using normal cdf:\", pnorm(b1) - pnorm(a1), \"\\n\") #> Probability of continuing trial under null hypothesis #>   Using numerical integration: 0.9755632  #>   Using normal cdf: 0.9755632 grid1_1 <- h1(theta = theta[1], I = info[1], a = a1, b = b1) probH1continue <- sum(grid1_1$h)  h1mean <- sqrt(info[1]) * theta[1] cat(\"Probability of continuing trial under alternate hypothesis\\n\",     \" Using numerical integration:\", probH1continue,      \"\\n  Using normal cdf:\", pnorm(b1, mean = h1mean) - pnorm(a1, h1mean), \"\\n\") #> Probability of continuing trial under alternate hypothesis #>   Using numerical integration: 0.986709  #>   Using normal cdf: 0.986709 # Upper bound under null hypothesis # incremental spend spend0 <- alphaspend[2] - alphaspend[1] # H0 bound at 2nd analysis; 1st approximation b2_0 <- qnorm(spend0, lower.tail = FALSE) # Lower bound under alternate hypothesis spend1 <- betaspend[2] - betaspend[1] a2_0 <- qnorm(spend1, mean = sqrt(info[2]) * theta[2]) cat(\"Initial bound approximation for 2nd analysis\\n (\",     a2_0, \", \", b2_0,\")\\n\", sep=\"\") #> Initial bound approximation for 2nd analysis #>  (1.681989, 1.987428) # Upper rejection region grid under H0 grid2_0 <- hupdate(theta = 0, I = info[2], a = b2_0, b = Inf, Im1 = info[1], gm1 = grid1_0) pupper_0 <- sum(grid2_0$h)  cat(\"Upper spending at analysis 2\\n Target:\", spend0, \"\\n Using initial bound approximation:\",     pupper_0,\"\\n\") #> Upper spending at analysis 2 #>  Target: 0.0234375  #>  Using initial bound approximation: 0.02290683 # First point in grid is at bound # Compute derivative dpdb2 <- grid2_0$h[1] / grid2_0$w[1] # Compute difference between target and actual bound crossing probability pdiff <- spend0 - pupper_0 # Taylor's series update b2_1 <- b2_0 - pdiff / dpdb2 # Compute boundary crossing probability at updated bound cat(\"Original bound approximation:\", b2_0,      \"\\nUpdated bound approximation:\", b2_1     ) #> Original bound approximation: 1.987428  #> Updated bound approximation: 1.977726 grid2_0 <- hupdate(theta = 0, I = info[2], a = b2_1, b = Inf, Im1 = info[1], gm1 = grid1_0) pupper_1 <- sum(grid2_0$h) cat(\"\\nOriginal boundary crossing probability:\", pupper_0,      \"\\nUpdated boundary crossing probability:\", pupper_1,     \"\\nTarget:\", spend0, \"\\n\"     ) #>  #> Original boundary crossing probability: 0.02290683  #> Updated boundary crossing probability: 0.02344269  #> Target: 0.0234375 # Lower rejection region grid under H1 grid2_1 <- hupdate(theta = theta[2], I = info[2], a = -Inf, b = a2_0,                     thetam1 = theta[1], Im1 = info[1], gm1 = grid1_1) plower_0 <- sum(grid2_1$h) # Last point in grid is at bound # Compute derivative indx <- length(grid2_1$h) dpda2 <- grid2_1$h[indx] / grid2_1$w[indx] # Compute difference between target and actual bound crossing probability pdiff <- spend1 - plower_0 # Taylor's series update a2_1 <- a2_0 + pdiff / dpda2 # Compute boundary crossing probability at updated bound cat(\"Original bound approximation:\", a2_0,      \"\\nUpdated bound approximation:\", a2_1) #> Original bound approximation: 1.681989  #> Updated bound approximation: 1.702596  grid2_1 <- hupdate(theta = theta[2], I = info[2], a = -Inf, b = a2_1,                     thetam1 = theta[1], Im1 = info[1], gm1 = grid1_1) plower_1 <- sum(grid2_1$h)  cat(\"\\nOriginal boundary crossing probability:\", plower_0,      \"\\nUpdated boundary crossing probability:\", plower_1,     \"\\nTarget:\", spend1, \"\\n\"     ) #>  #> Original boundary crossing probability: 0.09035972  #> Updated boundary crossing probability: 0.09379707  #> Target: 0.09375 gs_power_npe(theta = theta, theta1 = theta, info = info, binding = TRUE,              upper = gs_spending_bound,              upar = list(sf = gsDesign::sfPower, total_spend = 0.025, param = 2),              lower = gs_spending_bound,              lpar = list(sf = gsDesign::sfPower, total_spend = 0.1, param = 2) ) #> # A tibble: 4 × 10 #>   Analysis Bound     Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  2.96     0.00704   0.5    0.5  0.25     1     1     1 #> 2        2 Upper  1.98     0.845     1.5    1.5  1        4     4     4 #> 3        1 Lower -2.00     0.00625   0.5    0.5  0.25     1     1     1 #> 4        2 Lower  1.70     0.100     1.5    1.5  1        4     4     4"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Power Evaluation with Spending bounds","text":"vignette covers compute power Type error design derived spending bound. write general non-constant treatment effect using gs_design_npe() derived design one parameter setting computing power another setting. use trial binary endpoint enable full illustration.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"scenario-for-consideration","dir":"Articles","previous_headings":"","what":"Scenario for Consideration","title":"Power Evaluation with Spending bounds","text":"consider scenario largely based CAPTURE study (Investigators et al. (1997)) primary endpoint composite death, acute myocardial infarction need recurrent percutaneous intervention within 30 days randomization. detailed introduction trial listed follows. consider 2-arm trial experimental arm control arm. assume \\(K=3\\) analyses \\(350\\), \\(700\\), \\(1400\\) patients observed equal randomization treatment groups. primary endpoint trial binary indicator participant failed outcome. case, consider parameter \\[ \\theta = p_1 - p _2 \\] \\(p_1\\) denotes probability trial participant control group experiences failure \\(p_2\\) represents probability trial participant experimental group. study designed approximately 80% power (Type II error \\(\\beta = 1 - 0.8 = 0.2\\)) 2.5% one-sided Type error (\\(\\alpha = 0.025\\)) detect reduction 15% event rate (\\(p_1 = 0.15\\)) control group 10% (\\(p_2 = 0.1\\)) experimental group. example, parameter interest \\(\\theta = p_1 - p_2\\). denote alternate hypothesis \\[   H_1: \\theta = \\theta_1= p_1^1 - p_2^1 = 0.15 - 0.10 = 0.05 \\] null hypothesis \\[   H_0: \\theta = \\theta_0 = 0 = p_1^0 - p_2^0 \\] \\(p^0_1 = p^0_2= (p_1^1+p_2^1)/2 = 0.125\\) laid Lachin (2009). note considered success outcome objective response oncology study, let \\(p_1\\) denote experimental group \\(p_2\\) control group response rate. Thus, always set notation \\(p_1>p_2\\) represents superiority experimental group.","code":"p0 <- 0.15     # assumed failure rate in control group p1 <- 0.10     # assumed failure rate in experimental group alpha <- 0.025 # type I error beta <- 0.2    # type II error for 80% power"},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"notations","dir":"Articles","previous_headings":"","what":"Notations","title":"Power Evaluation with Spending bounds","text":"assume \\(k\\): index analysis, .e., \\(k = 1, \\ldots, K\\); \\(\\): index arm, .e., \\(= 1\\) control group \\(= 2\\) experimental group; \\(n_{ik}\\): number subjects group \\(\\) analysis \\(k\\); \\(n_k\\): number subjects analysis \\(k\\), .e., \\(n_k = n_{1k} + n_{2k}\\); \\(X_{ij}\\): independent random variable whether \\(j\\)-th subject group \\(\\) response, .e, \\[ X_{ij} \\sim \\hbox{Bernoulli}(p_i); \\] \\(Y_{ik}\\): number subject response group \\(\\) analysis \\(k\\), .e., \\[ Y_{ik} = \\sum_{j = 1}^{n_{ik}} X_{ij}; \\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"statistical-testing","dir":"Articles","previous_headings":"","what":"Statistical Testing","title":"Power Evaluation with Spending bounds","text":"section, discuss estimation statistical information variance porprotion null hypothesis \\(H_0: p_1^0 = p_2^0 \\equiv p_0\\) alternative hypothesis \\(H_1: \\theta = \\theta_1= p_1^1 - p_2^1\\). , introduce test statistics group sequential design.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"estimation-of-statistical-information-under-h1","dir":"Articles","previous_headings":"Statistical Testing","what":"Estimation of Statistical Information under H1","title":"Power Evaluation with Spending bounds","text":"alternative hypothesis, one can estimate proportion failures group \\(\\) analysis \\(k\\) \\[    \\hat{p}_{ik} = Y_{ik}/n_{ik}. \\] note variance \\[  \\hbox{Var}(\\hat p_{ik})=\\frac{p_{}(1-p_i)}{n_{ik}}, \\] consistent estimator \\[   \\widehat{\\hbox{Var}}(\\hat p_{ik})=\\frac{\\hat p_{ik}(1-\\hat p_{ik})}{n_{ik}}, \\] \\(= 1, 2\\) \\(k = 1, 2, \\ldots, K\\). Letting \\(\\hat\\theta_k = \\hat p_{1k} - \\hat p_{2k},\\) also \\[   \\sigma^2_k   \\equiv    \\hbox{Var}(\\hat\\theta_k)   =   \\frac{p_1(1-p_1)}{n_{1k}}+\\frac{p_2(1-p_2)}{n_{2k}}, \\] consistent estimator \\[   \\hat\\sigma^2_k   =   \\frac{\\hat p_{1k}(1-\\hat p_{1k})}{n_{1k}}+\\frac{\\hat p_{2k}(1-\\hat p_{2k})}{n_{2k}}, \\] Statistical information quantities corresponding estimators denoted \\[   \\left\\{   \\begin{align}     \\mathcal{}_k = &1/\\sigma^2_k,\\\\     \\mathcal{\\hat }_k = &1/\\hat \\sigma^2_k,   \\end{align}   \\right. \\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"estimation-of-statistical-information-under-h0","dir":"Articles","previous_headings":"Statistical Testing","what":"Estimation of Statistical Information under H0","title":"Power Evaluation with Spending bounds","text":"null hypothesis, one can estimate proportion failures group \\(\\) analysis \\(k\\) estimate \\[    \\hat{p}_{0k}   =   \\frac{Y_{1k}+ Y_{2k}}{n_{1k}+ n_{2k}}   =   \\frac{n_{1k}\\hat p_{1k} + n_{2k}\\hat p_{2k}}{n_{1k} + n_{2k}}.  \\] corresponding null hypothesis estimator \\[   \\hat\\sigma^2_{0k}   \\equiv   \\widehat{\\text{Var}}(\\hat{p}_{0k})   =   \\hat p_{0k}(1-\\hat p_{0k})\\left(\\frac{1}{n_{1k}}+ \\frac{1}{n_{2k}}\\right), \\] \\(k = 1,2, \\ldots, K\\). Statistical information quantities corresponding estimators denoted \\[   \\left\\{   \\begin{align}     \\mathcal{}_{0k} =& 1/ \\sigma^2_{0k},\\\\     \\mathcal{\\hat }_{0k} =& 1/\\hat \\sigma^2_{0k},   \\end{align}   \\right. \\] \\(k = 1, 2, \\ldots, K\\).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"testing-statistics","dir":"Articles","previous_headings":"Statistical Testing","what":"Testing Statistics","title":"Power Evaluation with Spending bounds","text":"Testing, recommended Lachin (2009), done large sample test null hypothesis variance estimate without continuity correction: \\[ Z_k = \\hat\\theta_k/\\hat\\sigma_{0k}=\\frac{\\hat p_{1k} - \\hat p_{2k}}{\\sqrt{(1/n_{1k}+ 1/n_{2k})\\hat p_{0k}(1-\\hat p_{0k})} }, \\] asymptotically \\(\\text{Normal}(0,1)\\) \\(p_1 = p_2\\) \\(\\text{Normal}(0, \\sigma_{0k}^2/\\sigma_k^2)\\) generally \\(p_1, p_2\\) \\(k = 1, 2, \\ldots, K\\). assume constant proportion \\(\\xi_i\\) randomized group \\(=1,2.\\) Thus, \\[   Z_k   \\approx    \\frac{\\sqrt{n_k}(\\hat p_{1k} - \\hat p_{2k})}{\\sqrt{(1/\\xi_1+ 1/\\xi_2)p_{0}(1- p_0)} }. \\] , asymptotic distribution \\[   Z_k   \\sim   \\hbox{Normal}   \\left(     \\sqrt{n_k}\\frac{p_1 - p_2}{\\sqrt{(1/\\xi_1+ 1/\\xi_2) p_0(1- p_0)} },     \\sigma^2_{0k}/\\sigma^2_{1k}   \\right), \\] note \\[    \\sigma^2_{0k}/\\sigma^2_{1k}    =    \\frac{ p_0(1-p_0)\\left(1/\\xi_1+ 1/\\xi_2\\right)}{p_1(1-p_1)/\\xi_1+p_2(1-p_2)/\\xi_2}. \\] also note definition \\(\\sigma^2_{0k}/\\sigma^2_{1k}=\\mathcal I_k/\\mathcal I_{0k}.\\) Based input \\(p_1, p_2, n_k, \\xi_1, \\xi_2 = 1-\\xi_1\\) compute \\(\\theta, \\mathcal{}_k, \\mathcal{}_{0k}\\) \\(k = 1, 2, \\ldots, K\\). note \\(\\chi^2=Z^2_k\\) \\(\\chi^2\\) test without continuity correction recommended Gordon Watson (1996). Note finally extends straightforward way non-inferiority test Farrington Manning (1990) null hypothesis \\(\\theta = p_1 - p_2 - \\delta = 0\\) non-inferiority margin \\(\\delta > 0\\); \\(\\delta < 0\\) correspond referred super-superiority Chan (2002), requiring experimental therapy shown superior control least margin \\(-\\delta>0\\).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_power_evaluation_with_spending_bound.html","id":"power-calculations","dir":"Articles","previous_headings":"","what":"Power Calculations","title":"Power Evaluation with Spending bounds","text":"begin developing function gs_info_binomial() calculate statistical infomation discussed . CAPTURE trial, can plug gs_power_npe() intended spending functions. begin power alternate hypothesis Now examine information smaller assumed treatment difference alternative:","code":"gs_info_binomial <- function(p1, p2, xi1, n, delta = NULL){   if (is.null(delta)) delta <- p1 - p2   # Compute (constant) effect size at each analysis theta   theta <- rep(p1 - p2, length(n))   # compute null hypothesis rate, p0   p0 <- xi1 * p1 + (1 - xi1) * p2   # compute information based on p1, p2   info <-  n / (p1 * (1 - p1) / xi1 + p2 * (1 - p2) / (1 - xi1))   # compute information based on null hypothesis rate of p0   info0 <- n / (p0 * (1 - p0)*(1 / xi1 + 1 / (1 - xi1)))   # compute information based on H1 rates of p1star, p2star   p1star <- p0 + delta * xi1   p2star <- p0 - delta * (1 - xi1)   info1 <-  n / (p1star * (1 - p1star) / xi1 + p2star * (1 - p2star) / (1 - xi1))      out <- tibble(Analysis = 1:length(n),                 n = n,                 theta = theta,                 theta1 = rep(delta, length(n)),                 info = info,                 info0 = info0,                 info1 = info1)   return(out) } h1 <- gs_info_binomial(p1 = .15, p2 = .1, xi1 = .5, n = c(350, 700, 1400)) h1 %>% gt() gs_power_npe(   theta = h1$theta,    theta1 = h1$theta,    info = h1$info,   info0 = h1$info0,    info1 = h1$info1,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfHSD, param = -2, total_spend = 0.2)   ) %>%    gt() %>%    fmt_number(columns = 3:10, decimals = 4) h <- gs_info_binomial(p1 = .15, p2 = .12, xi1 = .5, delta = .05, n = c(350, 700, 1400))  gs_power_npe(   theta = h$theta, theta1 = h$theta1, info = h$info,   info0 = h$info0, info1 = h$info1,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfHSD, param = -2, total_spend = 0.2)   ) %>%    gt() %>%    fmt_number(columns = 3:10, decimals = 4)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Quick Start for NPH Sample Size and Power","text":"provide simple examples use gsdmvn package deriving fixed group sequential designs non-proportional hazards. piecewise model enrollment, failure rates, dropout rates changing hazard ratio time allow great flexibility design assumptions. Users encouraged suggest features immediate long-term interest add. Topics included : Packages required used. Specifying enrollment rates. Specifying failure dropout rates possibly changing hazard ratio time. Deriving fixed design interim analysis. Simple boundary specification group sequential design. Deriving group sequential design non-proportional hazards. Displaying design properties. Design properties alternate assumptions. Differences gsDesign. Future enhancement priorities. items discussed briefly enable quick start early adopters also suggesting ultimate possibilities software enables. Finally, final section provides current enhancement priorities, potential topic-related enhancements discussed throughout document.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"packages-used","dir":"Articles","previous_headings":"","what":"Packages Used","title":"Quick Start for NPH Sample Size and Power","text":"gsdmvn package used implement group sequential distribution theory non-proportional hazards derive wide variety boundary types group sequential designs. gsDesign package used check results proportional hazards well source deriving bounds using spending functions. gsDesign2 package provides computations compute expected event accumulation average hazard ratio time; key inputs group sequential distribution parameters. simtrial package used verify design properties using simulation. gsdmvn package likely likely incorporated eventually gsDesign2 package, resulting fully featured design package. However, features implementation gsdmvn allowed change needed agile rapid development phase.","code":"devtools::load_all() library(gsDesign) #library(gsDesign2) library(simtrial) library(knitr) library(dplyr) library(gt) library(ggplot2)"},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"enrollment-rates","dir":"Articles","previous_headings":"","what":"Enrollment Rates","title":"Quick Start for NPH Sample Size and Power","text":"Piecewise constant enrollment rates input tabular format. assume enrollment ramp-\\(25\\%\\), \\(50\\%\\), \\(75\\%\\) final enrollment rate \\(2\\) months followed steady state \\(100\\%\\) enrollment another \\(6\\) months. rates increased later power design appropriately. However, fixed enrollment rate periods remain unchanged.","code":"enrollRates <- tibble(   Stratum = \"All\",    duration = c(2, 2, 2, 6),    rate = (1:4) / 4)  enrollRates %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"failure-and-dropout-rates","dir":"Articles","previous_headings":"","what":"Failure and Dropout Rates","title":"Quick Start for NPH Sample Size and Power","text":"Constant failure dropout rates specified study period stratum; consider single stratum . hazard ratio provided treatment/control hazard rate period stratum. dropout rate period assumed treatment group; restriction eliminated future version, needed. Generally, take advantage identity exponential distribution median \\(m\\), corresponding failure rate \\(\\lambda\\) \\[\\lambda = \\log(2) / m.\\] consider control group exponential time--event \\(12\\) month median. assume hazard ratio \\(1\\) \\(4\\) months, followed hazard ratio \\(0.6\\) thereafter. Finally, assume low \\(0.001\\) exponential dropout rate per month treatment groups.","code":"medianSurv <- 12 failRates <- tibble::tibble(   Stratum = \"All\",   duration = c(4, Inf),   failRate = log(2) / medianSurv,   hr = c(1, .6),   dropoutRate = .001)  failRates %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"fixed-design","dir":"Articles","previous_headings":"","what":"Fixed Design","title":"Quick Start for NPH Sample Size and Power","text":"enrollment, failure dropout rate assumptions now derive sample size trial targeted complete 36 months interim analysis, \\(90\\%\\) power \\(2.5\\%\\) Type error. quick summary targeted sample size obtained . Note normally round N even number Events next integer. enrollment rates period increased proportionately size trial desired properties; duration enrollment rate changed.","code":"alpha <- .025 beta <- .1                   # 1 - targeted power d <- fixed_design(   x = \"AHR\",                 # method for computing sample size   enrollRates = enrollRates, # Relative enrollment rates    failRates = failRates,     # Failure rates from above   alpha = alpha,             # Type I error   power = 1 - beta,          # Type II error = 1 - power   studyDuration = 36         # Planned trial duration ) d %>% summary() %>% as_gt() d$enrollRates %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"group-sequential-design","dir":"Articles","previous_headings":"","what":"Group Sequential Design","title":"Quick Start for NPH Sample Size and Power","text":"go detail group sequential designs . brief, however, sequence tests \\(Z_1, Z_2,\\ldots, Z_K\\) follow multivariate normal distribution performed test new treatment better control (Jennison Turnbull (1999)). assume \\(Z_k > 0\\) favorable experimental treatment. Generally Type error set tests controlled null hypothesis treatment difference sequence bounds \\(b_1, b_2,\\ldots,b_K\\) chosen Type error \\(\\alpha > 0\\) \\[   \\alpha = 1 - P_0(\\cap_{k=1}^K Z_k < b_k) \\] \\(P_0()\\) refers probability null hypothesis. referred non-binding bound since assumed trial stopped early futility \\(Z_k\\) small.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"simple-efficacy-bound-definition","dir":"Articles","previous_headings":"Group Sequential Design","what":"Simple Efficacy Bound Definition","title":"Quick Start for NPH Sample Size and Power","text":"Lan DeMets (1983) developed spending function method deriving group sequential bounds. involves use non-decreasing spending function \\(f(t)\\) \\(t\\ge 0\\) \\(f(0)=0\\) \\(f(t)=\\alpha\\) \\(t \\ge 1\\). Suppose \\(K>0\\) analyses performed proportion \\(t_1< t_2 <\\ldots t_K=1\\) planned statistical information (e.g., proportion planned events time--event endpoint trial proportion observations binomial normal endpoint). Bounds first \\(k\\) analyses \\(1\\le k\\le K\\) recursively defined spending function multivariate normal distribution satisfy \\[   f(t_k) = 1 - P_0(\\cap_{j=1}^k Z_j < b_j). \\] quick start, illustrate type efficacy bound. Perhaps common spending function approach Lan DeMets (1983) approximation O’Brien-Fleming bound \\[   f(t) = 2-2\\Phi\\left(\\frac{\\Phi^{-1}(1-\\alpha/2)}{t^{1/2}}\\right). \\]  Suppose \\(K=3\\) \\(t_1=0.5\\), \\(t_2 = 0.75\\), \\(t_3 = 1\\). can use assumptions group sequential design efficacy bound using Lan-DeMets O’Brien-Fleming spending function \\(\\alpha = 0.025\\) Bounds 3 analyses follows. Note expected sample size time data cutoff analysis also N. filter upper bound lower bounds Z = -Inf shown. gsDesign replicate bounds (replicate sample size).","code":"design1s <- gs_design_ahr(   alpha = alpha,   beta = beta,   enrollRates = enrollRates,   failRates = failRates,   analysisTimes = c(16, 26, 36),                           # Calendar time of planned analyses   upper = gs_spending_bound,                               # Spending function bound for efficacy   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025), # specify spending function and total Type I error   lower = gs_b, lpar = rep(-Inf, 3),                       # No futility bound   info_scale = 2 ) design1s %>%   summary() %>%    as_gt(title = \"1-sided group sequential bound using AHR method\",         subtitle = \"Lan-DeMets spending to approximate O'Brien-Fleming bound\") x <- gsDesign(k = 3, test.type = 1, timing = design1s$analysis$IF, sfu = sfLDOF) cat(\"gsDesign\\n  Upper bound: \",x$upper$bound,     \"\\n  Cumulative boundary crossing probability (H0): \", cumsum(x$upper$prob[, 1]),     \"\\n  Timing (IF): \", x$timing,     \"\\ngs_design_ahr\\n  Upper bound: \", design1s$bounds$Z,     \"\\n  Cumulative boundary crossing probability (H0): \", design1s$bounds$Probability0,     \"\\n  Timinng (IF): \", design1s$analysis$IF,     \"\\n\") #> gsDesign #>   Upper bound:  3.013804 2.264946 2.027236  #>   Cumulative boundary crossing probability (H0):  0.00128997 0.01217731 0.025  #>   Timing (IF):  0.4850799 0.7993622 1  #> gs_design_ahr #>   Upper bound:  3.003506 -Inf 2.256138 -Inf 2.028823 -Inf  #>   Cumulative boundary crossing probability (H0):  0.001470581 0 0.01260011 0 0.02521913 0  #>   Timinng (IF):  0.4850799 0.7993622 1"},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"two-sided-testing","dir":"Articles","previous_headings":"Group Sequential Design","what":"Two-Sided Testing","title":"Quick Start for NPH Sample Size and Power","text":"consider symmetric asymmetric 2-sided designs.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"symmetric-2-sided-bounds","dir":"Articles","previous_headings":"Group Sequential Design > Two-Sided Testing","what":"Symmetric 2-sided bounds","title":"Quick Start for NPH Sample Size and Power","text":"first 2-sided design symmetric design. Design bounds confirmed : bounds can plotted easily:","code":"design2ss <- gs_design_ahr(   alpha = alpha,   beta = beta,   enrollRates = enrollRates,   failRates = failRates,   analysisTimes = c(16, 26, 36),  #  Calendar analysis times   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   h1_spending = FALSE             # This specifies futility testing with spending under NULL ) design2ss %>%    summary() %>%    as_gt(title = \"2-sided symmetric group sequential bound using AHR method\",         subtitle = \"Lan-DeMets spending to approximate O'Brien-Fleming bound\") ggplot(data = design2ss$analysis %>% left_join(design2ss$bounds, by = \"Analysis\"),         aes(x = Events, y = Z, group = Bound)) +   geom_line(aes(linetype = Bound)) +   geom_point() +   ggtitle(\"2-sided symmetric bounds with O'Brien-Fleming-like spending\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_quick_start.html","id":"asymmetric-2-sided-bounds","dir":"Articles","previous_headings":"Group Sequential Design > Two-Sided Testing","what":"Asymmetric 2-sided bounds","title":"Quick Start for NPH Sample Size and Power","text":"Asymmetric 2-sided designs common symmetric since objectives two bounds tend different. often caution analyze early efficacy use conservative bound; principles used example designs far. Stopping lack benefit experimental treatment control overt indication unfavorable trend generally might examined early bounds less stringent. add early futility analysis nominal 1-sided p-value \\(0.05\\) wrong direction (\\(Z=\\Phi^{-1}(0.05)\\) 30% \\(50\\%\\) events accrued. might considered disaster check. point time, may perceived need futility analysis. efficacy, add infinite bound first interim analysis. now slightly larger sample size account possibility early futility stop. Bounds now:","code":"design2sa <- gs_design_ahr(   alpha = alpha,   beta = beta,   enrollRates = enrollRates,   failRates = failRates,   analysisTimes = c(12, 16, 26, 36),   upper = gs_spending_bound,    upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),  # Same efficacy bound as before   test_lower = c(FALSE, TRUE, TRUE, TRUE), # Only test efficacy after IA1   lower = gs_b,    lpar = c(rep(qnorm(.05),2), -Inf, -Inf)   # Fixed lower bound at first 2 analyses ) design2sa %>%    summary() %>%   as_gt(title = \"2-sided asymmetric group sequential bound using AHR method\",         subtitle = \"Lan-DeMets spending to approximate O'Brien-Fleming bound for efficacy, futility disaster check at IA1, IA2 only\")"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Group Sequential Design for Binary Outcomes","text":"consider group sequential design examining risk difference two treatment groups binary outcome. several issues consider: measure treatment difference natural parameter; focus risk difference. Incorporation null alternate hypothesis variances. Superiority, non-inferiority super-superiority designs. Stratified populations. Fixed group sequential designs. single stratum designs, focus sample size power using method Farrington Manning (1990) trial test difference two binomial event rates. routine can used test superiority, non-inferiority super-superiority. design tests superiority, methods consistent Fleiss, Tytun, Ury (1980), without continuity correction. Methods sample size power gsDesign::nBinomial() testing risk-difference scale single stratum. also consistent Hmisc R package routines bsamsize() bpower() superiority designs. trials multiple strata, testing risk difference often done weighting stratum according inverse variance (Mantel Haenszel (1959)). Since risk differences may also assumed different different strata, also explore weighting strata sample sizes Mehrotra Railkar (2000a). focus sample sizes large enough asymptotic theory work well without continuity corrections. concepts incorporated following functions intended use fixed group sequential designs: gs_info_rd() support asymptotic variance statistical information calculation. gs_power_rd() support power calculations. gs_design_rd() support sample size calculations. Simulation used throughout check examples presented.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"notation","dir":"Articles","previous_headings":"","what":"Notation","title":"Group Sequential Design for Binary Outcomes","text":"\\(K\\): total number analyses (including final analysis) group sequential design. fixed design, \\(K= 1\\). \\(S\\): total number strata. population un-stratified population, \\(S=1\\). \\(w_{s,k}\\): underlying weight assigned \\(s\\)-th strata \\(k\\)-th analysis. SWITH ORDER s, k w? \\(\\widehat w_{s,k}\\): estimated weight assigned \\(s\\)-th strata \\(k\\)-th analysis. \\(N_{C,k,s}, N_{E,k,s}\\): planned sample size control/treatment group \\(k\\)-th analysis \\(s\\)-th strata. \\(\\widehat N_{C,k,s}, \\widehat N_{E,k,s}\\): observed sample size control/treatment group \\(k\\)-th analysis \\(s\\)-th strata. \\(r\\): planned randomization ratio, .e., \\[ r = N_{E,k,s} / N_{C,k,s} \\;\\; \\forall k = 1, \\ldots, K \\;\\; \\text{} \\;\\; s = 1, \\ldots, S. \\] \\(p_{C,s}, p_{E,s}\\): planned rate control/treatment arm, .e., independent observations control/treatment group binary outcome observed probability \\(p_{C,s}\\) \\(k\\)-th analysis \\(s\\)-th strata. \\(d\\): indicator whether outcome failure (bad outcome) response (good outcome), .e., \\[ d =  \\left\\{ \\begin{array}{lll}   -1 & \\text{} p_{C,s} < p_{E,s} & \\text{control arm better}\\\\    1 & \\text{} p_{C,s} > p_{E,s} & \\text{treatment arm better}\\\\ \\end{array} \\right. \\] assume \\(\\exists s^* \\\\{1, \\ldots, S\\}\\), s.t., \\(p_{C,s^*} < p_{E,s^*}\\), \\(p_{C,s} < p_{E,s}, \\forall s \\\\{1, \\ldots, S\\}\\), vice versa. \\(X_{C,k,s}, X_{E,k,s}\\): random variables indicating number subjects failed control/treatment arm, .e., \\(X_{C,k,s} \\sim \\hbox{Binomial}(N_{C,k,s}, p_{C,k,s})\\), \\(X_{E,k,s} \\sim \\hbox{Binomial}(N_{E,k,s}, p_{E,k,s})\\) \\(k\\)-th analysis \\(s\\)-th strata. \\(x_{C,k,s}, x_{E,k,s}\\): observed outcome \\(X_{C, k, s}, X_{E, k, s}\\) \\(k\\)-th analysis \\(s\\)-th strata, respectively. \\(\\widehat p_{C,k,s}, \\widehat p_{E,k,s}\\): observed rates control/treatment group \\(k\\)-th analysis \\(s\\)-th strata, .e., \\[ \\widehat p_{C,k,s} = x_{C,k,s} / \\widehat N_{C,k,s}.\\\\ \\widehat p_{E,k,s} = x_{E,k,s} / \\widehat N_{E,k,s}. \\] \\(\\delta_{s}^{null}\\): planned risk difference \\(H_0\\) \\(k\\)-th analysis \\(s\\)-th strata. \\(\\delta_{s}\\): planned risk difference \\(H_1\\) \\(k\\)-th analysis \\(s\\)-th strata denoted \\[ \\delta_{s} = |p_{C,s} - p_{E,s}|.  \\] \\(\\hat\\delta_{s}\\): estimation risk difference \\[ \\widehat\\theta_{k,s} = |\\widehat p_{C,k,s} - \\widehat p_{E,k,s}| \\] \\(E(\\widehat\\theta_{k,s}) = \\theta_{s}, \\;\\forall k = 1, \\ldots, K\\).","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"testing","dir":"Articles","previous_headings":"","what":"Testing","title":"Group Sequential Design for Binary Outcomes","text":"test statistics \\(k\\)-th analysis \\[   Z_{k}    =    \\frac{      \\sum_{s=1}^S \\widehat w_{s,k} \\; |\\widehat \\delta_{k,s} - \\delta_{s}^{null} |   }{     \\sqrt{\\sum_{s=1}^S \\widehat w_{s,k}^2 \\widehat\\sigma_{H_0,k,s}^2}   } \\] \\(\\widehat\\sigma^2_{k,s} = \\widehat{\\hbox{Var}}(\\widehat p_C -\\widehat p_E)\\). value \\(\\widehat\\sigma^2_{k,s}\\) depends hypothesis design, .e., whether superiority design, non-inferiority design, super-superiority design. discuss \\(\\widehat\\sigma^2_{k,s}\\) following 3 subsections.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"superiority-design","dir":"Articles","previous_headings":"Testing","what":"Superiority Design","title":"Group Sequential Design for Binary Outcomes","text":"superiority design (\\(\\delta_{s}^{null} = 0\\)) show experimental group superior control group thresholds. hypothesis \\[   H_0: \\delta_{s} = 0 \\text{ vs. } H_1: \\delta_{s} > 0, \\; \\forall k = 1, \\ldots, K, s = 1, \\ldots, S \\] Variance per strata per analysis: null hypothesis, \\[ \\begin{array}{ll} \\sigma^2_{H_0,k,s}  & =  \\text{Var}(p_C - p_E | H_0) = p_{k,s}^{pool} \\left(1 - p^{pool}_{k,s} \\right) \\left(\\frac{1}{N_{C,k,s}} + \\frac{1}{N_{E,k,s}} \\right), \\\\ \\widehat\\sigma^2_{H_0,k,s}  & =  \\widehat{\\text{Var}}(\\hat p_C - \\hat p_E | H_0) = \\widehat p_{k,s}^{pool} \\left(1 - \\widehat p^{pool}_{k,s} \\right) \\left(\\frac{1}{N_{C,k,s}} + \\frac{1}{N_{E,k,s}} \\right), \\end{array} \\] \\(p_{k,s}^{pool} = (p_{C,s} N_{C,k,s} + p_{E,s} N_{E,k,s}) / (N_{C,k,s} + N_{E,k,s})\\) \\(\\widehat p_{k,s}^{pool} = (x_{C,k,s} + x_{E,k,s}) / (\\widehat N_{C,k,s} + \\widehat N_{E,k,s}).\\) alternative hypothesis, \\[ \\begin{array}{ll} \\sigma_{H_1,k,s}^2  & =  \\text{Var}(p_C - p_E | H_1) =  \\frac{p_{C,s} (1- p_{C,s})}{N_{C,k,s}} + \\frac{p_{E,s} (1 - p_{E,s})}{N_{E,k,s}} \\\\ \\widehat\\sigma_{H_1,k,s}^2  & =  \\widehat{\\text{Var}}(\\hat p_C - \\hat p_E | H_1) =  \\frac{\\widehat p_{C,k,s} (1- \\widehat p_{C,k,s})}{N_{C,k,s}} + \\frac{\\widehat p_{E,k,s} (1 - \\widehat p_{E,k,s})}{N_{E,k,s}} \\end{array} \\] \\(\\widehat p_{C,k,s} = x_{C,k,s} / N_{C,k,s} \\text{ } \\widehat p_{E,k,s} = x_{E,k,s} / N_{E,k,s}\\). Testing one-sided level \\(\\alpha \\(0, 1)\\) null hypothesis rejected \\(Z_k\\) cross upper boundary. upper boundary can either fixed derived spending functions. Standardized treatment effect per analysis: null hypothesis, \\[ \\theta_{H_0,k} = 0 \\\\ \\widehat \\theta_{H_0,k} = 0 \\] alternative hypothesis, \\[ \\begin{array}{ll} \\theta_{H_1,k}  & = \\frac{\\sum_{s=1}^S w_{k,s} (p_{C,s} - p_{E,s})}{\\sqrt{\\sum_{s=1}^S w_{k,s}^2 \\sigma_{H_1, k,s}^2}}\\\\ \\widehat\\theta_{H_1,k}  & =  \\frac{ \\sum_{s=1}^S \\widehat w_{k,s} (\\widehat p_C - \\widehat p_E) }{ \\sqrt{\\sum_{s=1}^S \\widehat w_{k,s}^2 \\widehat\\sigma_{H_1, k,s}^2} }. \\end{array} \\] Standardized information per analysis: Lachin (2009) Lachin (1981) provide fixed sample size calculations based values \\(\\psi_0\\) null hypothesis \\(\\psi_1\\) alternate hypothesis. propose using variance calculations compute statistical information group sequential design apply formulation power sample size calculation vignette Computing Bounds Non-Constant Treatment Effect. null hypothesis, \\[ \\begin{array}{ll} \\mathcal I_{H0,k}  & =  \\left[  \\sum_{s=1}^S  w_{k,s}^2 \\frac{p_{k,s}^{pool} (1 - p_{k,s}^{pool})}{N_{C, k, s}} +  w_{k,s}^2 \\frac{p_{k,s}^{pool} (1 - p_{k,s}^{pool})}{N_{E, k, s}}  \\right]^{-1} \\\\ \\widehat{\\mathcal }_{H0,k}  & =  \\left[  \\sum_{s=1}^S  \\widehat w_{k,s}^2 \\frac{\\widehat p_{k,s}^{pool} (1 - \\widehat p_{k,s}^{pool})}{\\widehat N_{C,k,s}} + \\widehat w_{k,s}^2 \\frac{\\widehat p_{k,s}^{pool} (1 - \\widehat p_{k,s}^{pool})}{\\widehat N_{C,k,s}}  \\right]^{-1} \\end{array} \\] alternative hypothesis, \\[ \\begin{array}{ll} \\mathcal I_{H1,k} =  \\left[  \\sum_{s=1}^S w_{k,s}^2 \\frac{p_{C,k,s} (1 - p_{C,k,s})}{N_{C,k,s}} + \\sum_{s=1}^S w_{k,s}^2 \\frac{p_{E,k,s} (1 - p_{E,k,s})}{N_{E,k,s}}  \\right]^{-1}\\\\ \\widehat{\\mathcal }_{H1,k}  =  \\left[  \\sum_{s=1}^S \\widehat w_{k,s}^2 \\frac{\\widehat p_{C,k,s} (1 - \\widehat p_{C,k,s})}{\\widehat N_{C,k,s}} + \\sum_{s=1}^S \\widehat w_{k,s}^2 \\frac{\\widehat p_{E,k,s} (1 - \\widehat p_{E,k,s})}{\\widehat N_{E,k,s}}  \\right]^{-1} \\end{array} \\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"super-superiority-design","dir":"Articles","previous_headings":"Testing","what":"Super-Superiority Design","title":"Group Sequential Design for Binary Outcomes","text":"hypothesis super-superiority design \\[   H_0: \\delta_{k,s} = \\delta_{k,s}^{null}    \\;\\; vs. \\;\\;    H_1: \\delta > \\delta_{k,s}^{null} \\text{ } \\delta_{k,s}^{null} > 0. \\] \\(\\theta_{k,s_1}^{null} = \\theta_{k,s_2}^{null}\\) \\(\\theta_{k,s_1}^{null} \\neq \\theta_{k,s_2}^{null}\\) \\(s_1 \\neq s_2\\). null hypothesis \\(\\theta_{0,k,s} \\neq 0\\), estimation rates \\(\\widehat p_{C0,k,s}, \\widehat p_{E0,k,s}\\) satisfy \\[   \\left\\{   \\begin{array}{l}     \\widehat p_{C0,k,s} = \\widehat p_{E0,k,s} + d_{k,s} \\times \\delta_{k,s}^{null} \\\\     \\widehat p_{C0,k,s} + r\\widehat p_{E0,k,s} = \\widehat p_{C,k,s} + r\\widehat p_{E,k,s} .   \\end{array}   \\right. \\] Solving 2 equations 2 unknowns yields \\[   \\left\\{   \\begin{array}{l}   \\widehat p_{E0,k,s} & = (\\widehat p_{C,k,s} + r \\widehat p_{E,k,s} - d_{k,s} \\delta_{k,s}^{null}) / (r + 1)\\\\   \\widehat p_{C0,k,s} & =  \\widehat p_{E0,k,s} + d_{k,s} \\delta_{k,s}^{null}.   \\end{array}   \\right. \\] Variance per strata per analysis: \\(H_0\\), \\[   \\hat\\sigma^2_{H_0,k,s}   =    \\frac{\\widehat p_{C0,k,s}(1- \\widehat p_{C0,k,s})}{N_{C,k,s}} + \\frac{ \\widehat p_{E0,k,s} (1 - \\widehat p_{E0,k,s})}{N_{E,k,s}}. \\] \\(H_1\\), \\[   \\widehat\\sigma_{H_1,k,s}^2    =    \\frac{\\widehat p_{C,k,s} (1- \\widehat p_{C,k,s})}{N_{C,k,s}} + \\frac{\\widehat p_{E,k,s} (1 - \\widehat p_{E,k,s})}{N_{E,k,s}}. \\] Standardized treatment effect per analysis: null hypothesis, \\[   \\widehat \\theta_{H_0,k}    =    \\frac{     \\sum_{s=1}^S w_{k,s} \\delta_{s,k}^{null}   }{     \\sqrt{\\sum_{s=1}^S w_{k,s}^2 \\widehat \\sigma_{H_0,k,s}}^2   }. \\] alternative hypothesis, \\[   \\widehat \\theta_{H_1}    =    \\frac{     \\sum_{s=1}^S w_{k,s} d_{k,s} \\times (\\widehat p_{C,k,s} - \\widehat p_{E,k,s})   }{     \\sqrt{\\sum_{s=1}^S w_{k,s}^2 \\widehat \\sigma_{H_1,k,s}^2}   }. \\] Standardized information per analysis: null hypothesis, \\[   \\widehat{\\mathcal }_{H0,k}    =    \\left[    \\sum_{s=1}^S w_{k,s}^2 \\frac{\\bar p_{C0,s} (1 - \\bar p_{C0,s})}{N_{C,s}} + w_{k,s}^2\\frac{\\bar p_{E0,s} (1 - \\bar p_{E0,s})}{N_{E,s}}    \\right]^{-1}. \\] alternative hypothesis, \\[   \\widehat{\\mathcal }_{H1,k}    =    \\left[   \\sum_{s=1}^S \\left( w_{k,s}^2 \\frac{\\bar p_{C,k,s} (1 - \\bar p_{C,k,s})}{N_{C,k,s}} + w_{k,s}^2 \\frac{\\bar p_{E,k,s} (1 - \\bar p_{E,k,s})}{N_{E,k,s}} \\right)   \\right]^{-1}. \\]","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"non-inferiority-design","dir":"Articles","previous_headings":"Testing","what":"Non-inferiority Design","title":"Group Sequential Design for Binary Outcomes","text":"non-inferiority Design means , treatment group definitely better control group, unacceptably worse. hypothesis \\(H_0: \\delta_{k,s} = \\delta_{k,s}^{null} \\;\\; vs. \\;\\; H_1: \\delta_{k,s} > \\delta_{k,s}^{null}\\) \\(\\delta_{k,s}^{null} <0\\). variance, standardized treatment effect statistical information super-superiority design setting \\(\\delta_{k,s}^{null}\\) negative numbers.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"weighting-options","dir":"Articles","previous_headings":"","what":"Weighting Options","title":"Group Sequential Design for Binary Outcomes","text":"previously noted, consider weighting based either inverse-variance weights (Mantel Haenszel (1959)) strata sample size weights (Mehrotra Railkar (2000b)). Inverse-variance weights (INVAR): \\[ w_{s,k} = \\frac{1/\\sigma^2_{s,k}}{\\sum_{s=1}^S 1/\\sigma^2_{s,k}}. \\\\ \\widehat w_{s,k} = \\frac{1/\\widehat\\sigma^2_{s,k}}{\\sum_{s=1}^S 1/\\widehat\\sigma^2_{s,k}}. \\] \\(\\widehat\\sigma_{s,k}^2 \\\\{\\widehat\\sigma_{H_0, k,s}^2, \\widehat\\sigma_{H_1, k,s}^2 \\}\\) depending infomation scale info_scale = ... gs_info_rd(), gs_power_rd() gs_design_rd(). Sample-Size Weights (SS): \\[ w_{s,k}  = \\frac{   (N_{C, s, k} \\; N_{E, s, k}) / (N_{C, s, k} + N_{E, s, k}) }{   \\sum_{s=1}^S (N_{C, s, k} \\; N_{E, s, k}) / (N_{C, s, k} + N_{E, s, k}) },\\\\ \\widehat w_{s,k}  = \\frac{   (\\widehat N_{C, s, k} \\; \\widehat N_{E, s, k}) / (\\widehat N_{C, s, k} + \\widehat N_{E, s, k}) }{   \\sum_{s=1}^S (\\widehat N_{C, s, k} \\; \\widehat N_{E, s, k}) / (\\widehat N_{C, s, k} + \\widehat N_{E, s, k}) }, \\] \\(N_{C,s,k}, N_{E,s,k}\\) planned sample size \\(s\\)-th strata \\(k\\)-th analysis control group experimental group, respectively. \\(\\widehat N_{C,s,k}, \\widehat N_{E,s,k}\\) observed sample size \\(s\\)-th strata \\(k\\)-th analysis control group experimental group, respectively.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"simulations","dir":"Articles","previous_headings":"","what":"Simulations","title":"Group Sequential Design for Binary Outcomes","text":"quick 20,000 simulations compare density histogram outcomes standard normal density. Assume \\(r=1, d = 1, p_C=p_E=0.125, N=200\\). compute \\(\\sigma\\) 0.047. Even huge sample size normal density fits quite well flatness middle.","code":"# Hypothesized failure rate p <- .125 #  Other parameters set.seed(123) r <- 1 N <- 200 NC <- N / (r + 1) NE <- r * N / (r + 1) library(ggplot2) # Generate random counts of events for each treatment xC <- rbinom(n = 20000, size = NC, prob = p) xE <- rbinom(n = 20000, size = NE, prob = p) # Treatment difference estimate thetahat <- xC / NC - xE / NE # Standard error under H0 pbar <- (xC + xE) / N se0 <- sqrt(pbar * (1 - pbar)*(1 / NC + 1 / NE)) # Z to test H0 Z <- thetahat / se0 x <- seq(-4, 4, .1) se0a <- sqrt(p * (1 - p) * (1 / NC + 1 / NE)) y <- data.frame(Z = x, Density = dnorm(x = x, mean = 0, sd = 1))   ggplot() +    geom_histogram(data = data.frame(Z), aes(x = Z, y = ..density..), color = 1, fill = \"white\") +   geom_line(data = y, aes(x = Z, y = Density), linetype = 1) +   ylab(\"Density\") +   ggtitle(\"Binomial outcomes by simulation vs. asymptotic normal density\",           subtitle = \"Histogram of 20,000 simulations\")"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"unstratified-fixed-design","dir":"Articles","previous_headings":"Examples","what":"Unstratified Fixed Design","title":"Group Sequential Design for Binary Outcomes","text":"example discussed section unstratified fixed design equal sized groups detect 30% reduction mortality associated congestive heart failure, 1-year mortality control group assumed greater 0.4. \\(p_C=0.4, p_E = .28\\). null hypothesis, assume \\(p_C=p_E =0.34\\). desire 90% power two-sided test two proportions \\(\\alpha = 0.05\\). like calculate sample size achieve 90% power.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"gsdesign2","dir":"Articles","previous_headings":"Examples > Unstratified Fixed Design","what":"gsDesign2","title":"Group Sequential Design for Binary Outcomes","text":"First, set parameters. calculate variance \\(H_0\\) \\(H_1\\). mathmatical formulation shown follows. \\[   \\begin{array}{ll}   \\sigma^2_{H_0}    =   p^{pool} \\left(1 - p^{pool} \\right) \\left(\\frac{1}{N_C} + \\frac{1}{N_{E}} \\right)   =   p^{pool} \\left(1 - p^{pool} \\right) \\left(\\frac{1}{N \\xi_C} + \\frac{1}{N \\xi_E} \\right)   \\overset{r=1}{=}   p^{pool} \\left(1 - p^{pool} \\right) \\frac{4}{N} \\\\   \\sigma^2_{H_1}    =   \\frac{p_C \\left(1 - p_C \\right)}{N_C} +   \\frac{p_E \\left(1 - p_E \\right)}{N_E}   =   \\frac{p_C \\left(1 - p_C \\right)}{N \\xi_C} +   \\frac{p_E \\left(1 - p_E \\right)}{N \\xi_E}    \\overset{r=1}{=}   \\left[     p_C \\left(1 - p_C \\right) +     p_E \\left(1 - p_E \\right)   \\right] \\frac{2}{N}   \\end{array} \\] calculation results Next, calculate standarized treatment effect \\(H_0\\) \\(H_1\\), whose mathmatical formulation \\[   \\begin{array}{ll}   \\theta_{H_0} = 0; \\\\   \\theta_{H_1} = \\frac{|p_c - p_e|}{\\sigma_{H_1}}   \\end{array}. \\] calculation results logic implemented teh function gs_info_rd(). plugging theta info gs_design_npe(), one can calculate sample size achieve 90% power. logic implement gs_design_rd() calculate sample size given fixed power one-step.","code":"p_c <- .28 p_e <- .4 p_pool <- (p_c + p_e) / 2  N <- 1 ratio <- 1 N_c <- N / (1 + ratio) N_e <- N_c * ratio sigma_H0 <-  sqrt(p_pool*(1 - p_pool) * 4 / N) sigma_H1 <-  sqrt((p_c*(1 - p_c) + p_e*(1 - p_e)) * 2 / N)  info_H0 <- 1/(sigma_H0^2) info_H1 <- 1/(sigma_H1^2) theta_H0 <- 0 theta_H1 <- abs(p_c - p_e)/sigma_H1  tibble::tribble(   ~N_c, ~N_e, ~p_c,    ~p_e,   ~theta_H1,    ~theta_H0,    ~info_H1,    ~info_H0,    N_c,  N_e,  p_c,     p_e,    theta_H1,     theta_H0,     info_H1,     info_H0, ) %>% gt::gt() x <- gs_info_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .28),   p_e = tibble::tibble(Stratum = \"All\", Rate = .4),   N = tibble::tibble(Stratum = \"All\", N = 1, Analysis = 1),   rd0 = 0,    ratio = 1,   weight = \"un-stratified\")   x %>%    gt::gt() %>%    gt::fmt_number(columns = 5:8, decimals = 6) # under info_scale = 0 y_0 <- gs_design_npe(   theta = .4 - .28,    info = x$info0,    info0 = x$info0,    info_scale = 0,   alpha = .025,    beta = .1,   upper = gs_b,    lower = gs_b,   upar = list(par = -qnorm(.025)),   lpar = list(par = -Inf))  # under info_scale = 1 y_1 <- gs_design_npe(   theta = .4 - .28,    info = x$info1,    info0 = x$info0,    info_scale = 1,   alpha = .025,    beta = .1,   upper = gs_b,    lower = gs_b,   upar = list(par = -qnorm(.025)),   lpar = list(par = -Inf))  # under info_scale = 2 y_2 <- gs_design_npe(   theta = .4 - .28,    info = x$info1,    info0 = x$info0,    info_scale = 2,   alpha = .025,    beta = .1,   upper = gs_b,    lower = gs_b,   upar = list(par = -qnorm(.025)),   lpar = list(par = -Inf))  tibble(`info_scale = 0` = y_0$info0[1] / x$info0[1],        `info_scale = 1` = y_1$info1[1] / x$info1[1],        `info_scale = 2` = y_2$info[1] / x$info1[1]) %>%    gt::gt() %>%    gt::tab_header(title = \"The sample size calculated by gsDesign2 under 3 info_scale\") z_info_scale_0 <- gs_design_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .28),   p_e = tibble::tibble(Stratum = \"All\", Rate = .4),   rd0 = 0,    alpha = 0.025,      beta = 0.1,      ratio = 1,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = -qnorm(.025),   lpar = -Inf,   info_scale = 0)    z_info_scale_1 <- gs_design_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .28),   p_e = tibble::tibble(Stratum = \"All\", Rate = .4),   rd0 = 0,    alpha = 0.025,      beta = 0.1,      ratio = 1,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = -qnorm(.025),   lpar = -Inf,   info_scale = 1)  z_info_scale_2 <- gs_design_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .28),   p_e = tibble::tibble(Stratum = \"All\", Rate = .4),   rd0 = 0,    alpha = 0.025,      beta = 0.1,      ratio = 1,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = -qnorm(.025),   lpar = -Inf,   info_scale = 2)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"east","dir":"Articles","previous_headings":"Examples > Unstratified Fixed Design","what":"EAST","title":"Group Sequential Design for Binary Outcomes","text":"Sample size calculated EAST","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"summary","dir":"Articles","previous_headings":"Examples > Unstratified Fixed Design","what":"Summary","title":"Group Sequential Design for Binary Outcomes","text":"","code":"tibble::tibble(gsDesign2_info_scale_0 = z_info_scale_0$analysis$N,                gsDesign2_info_scale_1 = z_info_scale_1$analysis$N,                gsDesign2_info_scale_2 = z_info_scale_2$analysis$N,                gsDesign = x_gsDesign$n,                 EAST_unpool = 645,                 EAST_pool = 651) %>%    gt::gt() %>%    gt::tab_spanner(label = \"gsDesign2\",                   columns = c(gsDesign2_info_scale_0, gsDesign2_info_scale_1, gsDesign2_info_scale_2)) %>%    gt::tab_spanner(label = \"EAST\",                   columns = c(EAST_unpool, EAST_pool)) %>%    cols_label(gsDesign2_info_scale_0 = \"info_scale = 0\",              gsDesign2_info_scale_1 = \"info_scale = 1\",              gsDesign2_info_scale_2 = \"info_scale = 2\",              EAST_unpool = \"un-pooled\",              EAST_pool = \"pooled\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"unstratified-group-sequential-design","dir":"Articles","previous_headings":"Examples","what":"Unstratified Group Sequential Design","title":"Group Sequential Design for Binary Outcomes","text":"example discussed section unstratified group sequential design equal sized groups detect \\(p_C = 0.15, p_E = .1\\). null hypothesis, assume \\(p_C = p_E = 0.125\\). desire 90% power two-sided test two proportions \\(\\alpha = 0.05\\). like calculate sample size achieve 90% power.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"gsdesign2-1","dir":"Articles","previous_headings":"Examples > Unstratified Group Sequential Design","what":"gsDesign2","title":"Group Sequential Design for Binary Outcomes","text":"calculate sample size, one can use gs_design_rd(). logic gs_design_rd() calculate sample size fixed design first. logic implemented gs_design_rd().","code":"x_gs <- gs_info_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .15),   p_e = tibble::tibble(Stratum = \"All\", Rate = .1),   N = tibble::tibble(Stratum = \"All\", N = 1:3/3, Analysis = 1:3),   rd0 = 0,    ratio = 1,   weight = \"un-stratified\" )  x_gs %>%    gt::gt() %>%   gt::tab_header(title = \"The statistical information of the group sequential design\") # info_scale = 0 y_gs0 <- gs_design_npe(   theta = .05,    info = x_gs$info0,    info0 = x_gs$info0,    info_scale = 0,   alpha = .025, beta = .1, binding = FALSE,   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE)  # info_scale = 1 y_gs1 <- gs_design_npe(   theta = .05,    info = x_gs$info1,    info0 = x_gs$info1,    info_scale = 2,   alpha = .025, beta = .1, binding = FALSE,   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE)  # info_scale = 2 y_gs2 <- gs_design_npe(   theta = .05,    info = x_gs$info1,    info0 = x_gs$info0,    info_scale = 2,   alpha = .025, beta = .1, binding = FALSE,   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE)  tibble(`info_scale = 0` = y_gs0$info0 / x_gs$info0[3],        `info_scale = 1` = y_gs1$info1 / x_gs$info1[3],        `info_scale = 2` = y_gs2$info / x_gs$info1[3]) %>%    gt::gt() %>%    gt::tab_header(title = \"The sample size calculated by `gsDesign2` under 3 info_scale\", subtitle = \"under group sequential design\") x_gsDesign2_info_scale_0 <- gs_design_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .15),   p_e = tibble::tibble(Stratum = \"All\", Rate = .1),   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .1,                   ratio = 1,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE,   info_scale = 0 )  x_gsDesign2_info_scale_1 <- gs_design_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .15),   p_e = tibble::tibble(Stratum = \"All\", Rate = .1),   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .1,                   ratio = 1,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE,   info_scale = 1 )  x_gsDesign2_info_scale_2 <- gs_design_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = .15),   p_e = tibble::tibble(Stratum = \"All\", Rate = .1),   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .1,                   ratio = 1,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE,   info_scale = 2 )"},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"gsdesign-1","dir":"Articles","previous_headings":"Examples > Unstratified Group Sequential Design","what":"gsDesign","title":"Group Sequential Design for Binary Outcomes","text":"","code":"n_fix <- nBinomial(   # Control event rate   p1 = .15,    # Experimental event rate   p2 = .1,    # Null hypothesis event rate difference (control - experimental)   delta0 = 0,    # 1-sided Type I error   alpha = .025,    # Type II error (1 - Power)   beta = .1,    # Experimental/Control randomization ratio   ratio = 1)   cat(\"The sample size of fixed-design calculated by `gsDesign` is \", n_fix, \".\\n\") #> The sample size of fixed-design calculated by `gsDesign` is  1834.641 .  x_gsDesign <- gsDesign(   k = 3,   test.type = 1,   # 1-sided Type I error   alpha = .025,    # Type II error (1 - Power)   beta = .1,       # If test.type = 5 or 6, this sets maximum spending for futility   # under the null hypothesis. Otherwise, this is ignored.   astar = 0,   timing = 1:3/3,   sfu = sfLDOF,   sfupar = NULL,   sfl = sfLDOF,   sflpar = NULL,   # Difference in event rates under alternate hypothesis   delta = 0,   # Difference in rates under H1   delta1 = .05,   # Difference in rates under H0   delta0 = 0,   endpoint = \"Binomial\",   # Fixed design sample size from nBinomial above   n.fix = n_fix)  cat(\"The sample size calcuated by `gsDesign` is \", x_gsDesign$n.I, \".\\n\") #> The sample size calcuated by `gsDesign` is  618.7954 1237.591 1856.386 .  gsBoundSummary(x_gsDesign, digits = 4, ddigits = 2, tdigits = 1) #>   Analysis                  Value Efficacy #>  IA 1: 33%                      Z   3.7103 #>     N: 619            p (1-sided)   0.0001 #>                   ~delta at bound   0.0985 #>               P(Cross) if delta=0   0.0001 #>            P(Cross) if delta=0.05   0.0338 #>  IA 2: 67%                      Z   2.5114 #>    N: 1238            p (1-sided)   0.0060 #>                   ~delta at bound   0.0472 #>               P(Cross) if delta=0   0.0060 #>            P(Cross) if delta=0.05   0.5603 #>      Final                      Z   1.9930 #>    N: 1857            p (1-sided)   0.0231 #>                   ~delta at bound   0.0306 #>               P(Cross) if delta=0   0.0250 #>            P(Cross) if delta=0.05   0.9000"},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"east-1","dir":"Articles","previous_headings":"Examples > Unstratified Group Sequential Design","what":"EAST","title":"Group Sequential Design for Binary Outcomes","text":"Sample size calculated EAST Sample size calculated EAST Sample size calculated EAST","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"summary-1","dir":"Articles","previous_headings":"Examples > Unstratified Group Sequential Design","what":"Summary","title":"Group Sequential Design for Binary Outcomes","text":"","code":"tibble::tibble(gsDesign2_info_scale_0 = x_gsDesign2_info_scale_0$analysis$N,                gsDesign2_info_scale_1 = x_gsDesign2_info_scale_1$analysis$N,                gsDesign2_info_scale_2 = x_gsDesign2_info_scale_2$analysis$N,                gsDesign = x_gsDesign$n.I,                EAST_unpool = c(617, 1233, 1850),                EAST_pool = c(619, 1238, 1857)) %>%    gt::gt() %>%    gt::tab_spanner(label = \"gsDesign2\",                   columns = c(gsDesign2_info_scale_0, gsDesign2_info_scale_1, gsDesign2_info_scale_2)) %>%    gt::tab_spanner(label = \"EAST\",                   columns = c(EAST_unpool, EAST_pool)) %>%    cols_label(gsDesign2_info_scale_0 = \"info_scale = 0\",              gsDesign2_info_scale_1 = \"info_scale = 1\",              gsDesign2_info_scale_2 = \"info_scale = 2\",              EAST_unpool = \"un-pooled\",              EAST_pool = \"pooled\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"stratified-group-sequential-design","dir":"Articles","previous_headings":"Examples","what":"Stratified Group Sequential Design","title":"Group Sequential Design for Binary Outcomes","text":"example, consider 3 strata group sequential design 3 analyses.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"gsdesign2-2","dir":"Articles","previous_headings":"Examples > Stratified Group Sequential Design","what":"gsDesign2","title":"Group Sequential Design for Binary Outcomes","text":"First, calculate variance \\[   \\left\\{   \\begin{array}{ll}   \\sigma^2_{H_0,k,s}    & =   p_{k,s}^{pool} \\left(1 - p^{pool}_{k,s} \\right)    \\left(\\frac{1}{N_{C,k,s}} + \\frac{1}{N_{E,k,s}} \\right)    =   p_{k,s}^{pool} \\left(1 - p^{pool}_{k,s} \\right)    \\left(\\frac{1}{ \\frac{\\xi_s}{1+r} N_{k}} + \\frac{1}{ \\frac{r \\xi_s}{1+r} N_{k}} \\right) \\\\   \\sigma_{H_1,k,s}^2    & =    \\frac{p_{C,s} (1- p_{C,s})}{N_{C,k,s}} + \\frac{p_{E,s} (1 - p_{E,s})}{N_{E,k,s}}    =    \\frac{p_{C,s} (1- p_{C,s})}{\\frac{\\xi_s}{1+r} N_{k}} + \\frac{p_{E,s} (1 - p_{E,s})}{\\frac{r \\xi_s}{1+r} N_{k}}    \\end{array}   \\right. \\] Second, calculate weight using inverse variance \\[   w_{s,k} = \\frac{1/\\sigma^2_{s,k}}{\\sum_{s=1}^S 1/\\sigma^2_{s,k}}.  \\] Third, calculate weighted risk difference weighted statistical information. \\[   \\left\\{   \\begin{array}{ll}     \\delta_{H_0,k}      & = 0\\\\     \\delta_{H_1,k}      & = \\sum_{s=1}^S w_{k,s} |p_{C,s} - p_{E,s}|   \\end{array}   \\right. \\\\   \\left\\{   \\begin{array}{ll}     \\mathcal I_{H_0,k}      & =      \\left[        \\sum_{s=1}^S        w_{k,s}^2 \\frac{p_{k,s}^{pool} (1 - p_{k,s}^{pool})}{N_{C, k, s}} +        w_{k,s}^2 \\frac{p_{k,s}^{pool} (1 - p_{k,s}^{pool})}{N_{E, k, s}}      \\right]^{-1}\\\\     \\mathcal I_{H_1,k}       & =      \\left[        \\sum_{s=1}^S w_{k,s}^2 \\frac{p_{C,k,s} (1 - p_{C,k,s})}{N_{C,k,s}}       +       \\sum_{s=1}^S w_{k,s}^2 \\frac{p_{E,k,s} (1 - p_{E,k,s})}{N_{E,k,s}}      \\right]^{-1}   \\end{array}   \\right. \\\\ \\] logic implemented gs_design_rd().","code":"ratio <- 1 prevalence_ratio <- c(4, 5, 6)  p_c_by_stratum <- c(.3, .37, .6) p_e_by_stratum <- c(.25, .3, .5)    p_c <- tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), Rate = p_c_by_stratum) p_e <- tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), Rate = p_e_by_stratum) ratio_strata_c <- tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), ratio = prevalence_ratio) ratio_strata_e <- ratio_strata_c  N <- 1 IF <- 1:3/3 N_c <- N / (1 + ratio)  N_e <- ratio * N_c   x <- p_c %>%    rename(p_c = Rate) %>%    left_join(p_e) %>%    rename(p_e = Rate) %>%    mutate(p_pool = (p_c + p_e) / 2) %>%    mutate(xi_c = (ratio_strata_c %>% mutate(prop = ratio / sum(ratio)))$prop) %>%    mutate(xi_e = (ratio_strata_e %>% mutate(prop = ratio / sum(ratio)))$prop) %>%    mutate(N_c = N_c * xi_c, N_e = N_e * xi_e)  x %>%    gt::gt() %>%    gt::fmt_number(columns = 4:8, decimals = 4) %>%    gt::tab_footnote(footnote = \"p_pool = (p_c * N_c + p_e * N_e) / (N_c * N_e).\",                    locations = gt::cells_column_labels(columns = p_pool)) %>%    gt::tab_footnote(footnote = \"xi_c = sample size of a strata / sample size of the control arm.\",                    locations = gt::cells_column_labels(columns = xi_c)) %>%    gt::tab_footnote(footnote = \"xi_e = sample size of a strata / sample size of the experimental arm.\",                    locations = gt::cells_column_labels(columns = xi_e)) %>%    gt::tab_footnote(footnote = \"N_c = total sample size of the control arm.\",                    locations = gt::cells_column_labels(columns = N_c)) %>%    gt::tab_footnote(footnote = \"N_e = total size of the experimental arm.\",                    locations = gt::cells_column_labels(columns = N_e)) %>%    gt::tab_header(title = \"Stratified Example\") x <- x %>%    union_all(x) %>%    union_all(x) %>%    mutate(Analysis = rep(1:3, each = 3)) %>%    left_join(tibble(Analysis = 1:3, IF = IF)) %>%    mutate(N_c = N_c * IF, N_e = N_e * IF) %>%    select(Analysis, Stratum, p_c, p_pool, p_e, N_c, N_e, xi_c, xi_e) %>%    mutate(sigma_H0 = sqrt(p_pool * (1 - p_pool) * (1 / N_c + 1 / N_e)),          sigma_H1 = sqrt(p_c * (1 - p_c) / N_c + p_e * (1 - p_e) / N_e))  x %>%    gt() %>%    gt::fmt_number(6:11, decimals = 4) %>%    gt::tab_footnote(footnote = \"sigma_H0 = the H0 sd per stratum per analysis.\",                    locations = gt::cells_column_labels(columns = sigma_H0)) %>%    gt::tab_footnote(footnote = \"sigma_H1 = the H0 sd per stratum per analysis.\",                    locations = gt::cells_column_labels(columns = sigma_H1)) temp <- x %>%    group_by(Analysis) %>%    summarise(sum_invar_H0 = sum(1/sigma_H0^2),             sum_invar_H1 = sum(1/sigma_H1^2),             sum_ss = sum((N_c * N_e) / (N_c + N_e)))  x <- x %>%    left_join(temp) %>%    mutate(weight_invar_H0 = 1/sigma_H0^2 / sum_invar_H0,          weight_invar_H1 = 1/sigma_H1^2 / sum_invar_H1,          weight_ss = (N_c * N_e) / (N_c + N_e) / sum_ss) %>%    select(-c(sum_invar_H0, sum_invar_H1, sum_ss))  x %>%    gt() %>%    fmt_number(6:14, decimals = 4) %>%    gt::tab_footnote(footnote = \"weight_invar_H0 = the weight per stratum per analysis calculated by INVAR by using variance under H0.\",                    locations = gt::cells_column_labels(columns = weight_invar_H0)) %>%    gt::tab_footnote(footnote = \"weight_invar_H1 = the weight per stratum per analysis calculated by INVAR by using variance under H1.\",                    locations = gt::cells_column_labels(columns = weight_invar_H1)) %>%    gt::tab_footnote(footnote = \"weight_ss = the weight per stratum per analysis calculated by SS.\",                    locations = gt::cells_column_labels(columns = weight_ss)) x <- x %>%    group_by(Analysis) %>%    summarise(rd_invar_H0 = sum(weight_invar_H0 * abs(p_c - p_e)),             rd_invar_H1 = sum(weight_invar_H1 * abs(p_c - p_e)),             rd_ss = sum(weight_ss * abs(p_c - p_e)),             rd0 = 0,             info_invar_H0 = 1 / sum(weight_invar_H0^2*p_c*(1-p_c)/N_c + weight_invar_H0^2*p_e*(1-p_e)/N_e),             info_invar_H1 = 1 / sum(weight_invar_H1^2*p_c*(1-p_c)/N_c + weight_invar_H1^2*p_e*(1-p_e)/N_e),             info_ss = 1 / sum(weight_ss^2*p_c*(1-p_c)/N_c + weight_ss^2*p_e*(1-p_e)/N_e),             info0_invar_H0 = 1 / sum(weight_invar_H0^2*p_pool*(1-p_pool)/N_c + weight_invar_H0^2*p_pool*(1-p_pool)/N_e),             info0_invar_H1 = 1 / sum(weight_invar_H1^2*p_pool*(1-p_pool)/N_c + weight_invar_H1^2*p_pool*(1-p_pool)/N_e),             info0_ss = 1 / sum(weight_ss^2*p_pool*(1-p_pool)/N_c + weight_ss^2*p_pool*(1-p_pool)/N_e)             ) x %>%    gt::gt() %>%    fmt_number(c(2:4, 6:11), decimals = 6) %>%    gt::tab_footnote(footnote = \"info_invar_H0 = the statistical information under H1 per stratum per analysis calculated by INVAR by using variance under H0.\",                    locations = gt::cells_column_labels(columns = info_invar_H0)) %>%    gt::tab_footnote(footnote = \"info_invar_H1 = the statistical information under H1 per stratum per analysis calculated by INVAR by using variance under H0.\",                    locations = gt::cells_column_labels(columns = info_invar_H1)) %>%    gt::tab_footnote(footnote = \"info_ss = the statistical information under H1 per stratum per analysis calculated by SS.\",                    locations = gt::cells_column_labels(columns = info_ss)) %>%    gt::tab_footnote(footnote = \"info0_invar_H0 = the statistical information under H0 per stratum per analysis calculated by INVAR by using variance under H0.\",                    locations = gt::cells_column_labels(columns = info0_invar_H0)) %>%    gt::tab_footnote(footnote = \"info0_invar_H1 = the statistical information under H0 per stratum per analysis calculated by INVAR by using variance under H0.\",                    locations = gt::cells_column_labels(columns = info0_invar_H1)) %>%    gt::tab_footnote(footnote = \"info0_ss = the statistical information under H0 per stratum per analysis calculated by SS.\",                    locations = gt::cells_column_labels(columns = info0_ss)) # ----------------------------------- #  #     sample size under H0            # # ----------------------------------- #  y_invar_H0 <- gs_design_npe(   theta = x$rd_invar_H0,   info = x$info0_invar_H0,    info0 = x$info0_invar_H0,    info_scale = 2,   alpha = 0.025,                     beta = 0.2,                   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE, )  y_invar_H1 <- gs_design_npe(   theta = x$rd_invar_H1,   info = x$info0_invar_H1,    info0 = x$info0_invar_H1,    info_scale = 2,   alpha = 0.025,                     beta = 0.2,                   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE, )  y_ss <- gs_design_npe(   theta = x$rd_ss,   info = x$info0_ss,    info0 = x$info0_ss,    info_scale = 2,   alpha = 0.025,                     beta = 0.2,                   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE, )  # ----------------------------------- #  #     sample size under H1            # # ----------------------------------- #  yy_invar_H0 <- gs_design_npe(   theta = x$rd_invar_H0,   info = x$info_invar_H0,    info0 = x$info0_invar_H0,    info_scale = 2,   alpha = 0.025,                     beta = 0.2,                   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE, )  yy_invar_H1 <- gs_design_npe(   theta = x$rd_invar_H1,   info = x$info_invar_H1,    info0 = x$info0_invar_H1,    info_scale = 2,   alpha = 0.025,                     beta = 0.2,                   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE, )  yy_ss <- gs_design_npe(   theta = x$rd_ss,   info = x$info_ss,    info0 = x$info0_ss,    info_scale = 2,   alpha = 0.025,                     beta = 0.2,                   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = rep(-Inf, 3),   test_lower = FALSE, )  ans_math <- tibble::tibble(`Weighting method` = rep(c(\"INVAR-H0\", \"INVAR-H1\", \"Sample Size\"), 2),                            `Calculated under` = c(rep(\"H0\", 3), rep(\"H1\", 3)),                            `Sample size` = c(y_invar_H0$info[3] / x$info0_invar_H0[3],                                               y_invar_H1$info[3] / x$info0_invar_H1[3],                                               y_ss$info[3] / x$info0_ss[3],                                              yy_invar_H0$info[3] / x$info_invar_H0[3],                                               yy_invar_H1$info[3] / x$info_invar_H1[3],                                               yy_ss$info[3] / x$info_ss[3]))   ans_math %>%    gt::gt() %>%    gt::tab_header(title = \"Sample size calculated by INVAR and SS\") ## sample size weighting + information scale = 0 x_ss0 <- gs_design_rd(   p_c = p_c,   p_e = p_e,   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .2,                       ratio = 1,   stratum_prev = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), prevalence = 4:6),   weight = \"ss\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)),   info_scale = 0,   binding = FALSE) ## sample size weighting + information scale = 1 x_ss1 <- gs_design_rd(   p_c = p_c,   p_e = p_e,   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .2,                       ratio = 1,   stratum_prev = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), prevalence = 4:6),   weight = \"ss\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)),   info_scale = 1,   binding = FALSE) ## sample size weighting + information scale = 2 x_ss2 <- gs_design_rd(   p_c = p_c,   p_e = p_e,   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .2,                       ratio = 1,   stratum_prev = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), prevalence = 4:6),   weight = \"ss\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)),   info_scale = 2,   binding = FALSE) ## inverse variance weighting + information scale = 0 x_invar0 <- gs_design_rd(   p_c = p_c,   p_e = p_e,   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .2,                       ratio = 1,   stratum_prev = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), prevalence = 1:3),   weight = \"invar\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)),   info_scale = 0,   binding = FALSE) ## inverse variance weighting + information scale = 1 x_invar1 <- gs_design_rd(   p_c = p_c,   p_e = p_e,   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .2,                       ratio = 1,   stratum_prev = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), prevalence = 1:3),   weight = \"invar\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)),   info_scale = 1,   binding = FALSE) ## inverse variance weighting + information scale = 2 x_invar2 <- gs_design_rd(   p_c = p_c,   p_e = p_e,   IF = 1:3/3,   rd0 = 0,    alpha = .025,                     beta = .2,                       ratio = 1,   stratum_prev = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), prevalence = 1:3),   weight = \"invar\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)),   info_scale = 2,   binding = FALSE) ans <- tibble::tibble(INVAR0 = x_invar0$analysis$N[1:3],                INVAR1 = x_invar1$analysis$N[1:3],                INVAR2 = x_invar2$analysis$N[1:3],                SS0 = x_ss0$analysis$N[1:3],                SS1 = x_ss1$analysis$N[1:3],                SS2 = x_ss2$analysis$N[1:3])  ans %>%    gt::gt() %>%    gt::tab_header(title = \"Sample size calculated by INVAR and SS\") %>%    gt::tab_spanner(label = \"Inverse variance weighting\",                   columns = c(INVAR0, INVAR1, INVAR2)) %>%    gt::tab_spanner(label = \"Sample size wighting\",                   columns = c(SS0, SS1, SS2)) %>%    cols_label(INVAR0 = \"info_scale = 0\",              INVAR1 = \"info_scale = 1\",              INVAR2 = \"info_scale = 2\",              SS0 = \"info_scale = 0\",              SS1 = \"info_scale = 1\",              SS2 = \"info_scale = 2\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"simulations-1","dir":"Articles","previous_headings":"Examples > Stratified Group Sequential Design","what":"Simulations","title":"Group Sequential Design for Binary Outcomes","text":"","code":"run_simulation <- function(N, weight_method, n_sim, prevalence_ratio, IF, under_H0 = TRUE, integration = \"gs_power_npe\"){      ans <- NULL      N_S1 <- ceiling(N * prevalence_ratio[1] / sum(prevalence_ratio)) * IF   N_S2 <- ceiling(N * prevalence_ratio[2] / sum(prevalence_ratio)) * IF    N_S3 <- ceiling(N * prevalence_ratio[3] / sum(prevalence_ratio)) * IF       # begin the simulations   for (simu in 1:n_sim) {          # set the random seed     set.seed(simu)        # observations of 3 strata in FA     x_e_S1 <- lapply(diff(c(0, ceiling(N_S1/2))), function(x){rbinom(n = x, size = 1, prob = p_e$Rate[1])})     x_e_S2 <- lapply(diff(c(0, ceiling(N_S2/2))), function(x){rbinom(n = x, size = 1, prob = p_e$Rate[2])})     x_e_S3 <- lapply(diff(c(0, ceiling(N_S3/2))), function(x){rbinom(n = x, size = 1, prob = p_e$Rate[3])})     x_c_S1 <- lapply(diff(c(0, ceiling(N_S1/2))), function(x){rbinom(n = x, size = 1, prob = p_c$Rate[1])})     x_c_S2 <- lapply(diff(c(0, ceiling(N_S2/2))), function(x){rbinom(n = x, size = 1, prob = p_c$Rate[2])})     x_c_S3 <- lapply(diff(c(0, ceiling(N_S3/2))), function(x){rbinom(n = x, size = 1, prob = p_c$Rate[3])})      # calculate the number of events at FA     n_e_S1 <- cumsum(do.call(c, lapply(x_e_S1, sum)))     n_e_S2 <- cumsum(do.call(c, lapply(x_e_S2, sum)))     n_e_S3 <- cumsum(do.call(c, lapply(x_e_S3, sum)))     n_c_S1 <- cumsum(do.call(c, lapply(x_c_S1, sum)))     n_c_S2 <- cumsum(do.call(c, lapply(x_c_S2, sum)))     n_c_S3 <- cumsum(do.call(c, lapply(x_c_S3, sum)))      # calculate the events rates     p_e_S1 <- n_e_S1 / (N_S1/2)     p_e_S2 <- n_e_S2 / (N_S2/2)     p_e_S3 <- n_e_S3 / (N_S3/2)     p_c_S1 <- n_c_S1 / (N_S1/2)     p_c_S2 <- n_c_S2 / (N_S2/2)     p_c_S3 <- n_c_S3 / (N_S3/2)        # calculate the variance per stratum per analysis     x <- tibble::tibble(analysis = rep(1:3, 3),                         statum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),                         IF = rep(IF, 3),                         N_e = c(N_S1/2, N_S2/2, N_S3/2),                         N_c = N_e,                         n_e = c(n_e_S1, n_e_S2, n_e_S3),                         n_c = c(n_c_S1, n_c_S2, n_c_S3),                         p_e = c(p_e_S1, p_e_S2, p_e_S3),                         p_c = c(p_c_S1, p_c_S2, p_c_S3)                         )%>%        mutate(p_pool = (n_c + n_e) / (N_c + N_e),              sigma_H0 = sqrt(p_pool * (1 - p_pool) * (1 / N_c + 1 / N_e)),              sigma_H1 = sqrt(p_c * (1 - p_c) / N_c + p_e * (1 - p_e) / N_e))     # calculate the sum of weights     sum_weight <- x %>%        group_by(analysis) %>%        summarize(sum_invar_H0 = sum(1/sigma_H0^2),                 sum_invar_H1 = sum(1/sigma_H1^2),                 sum_ss = sum((N_c * N_e) / (N_c + N_e))) %>%        ungroup()     # calculate the weight per stratum     suppressMessages(     x <- x %>%        left_join(sum_weight) %>%        mutate(weight_invar_H0 = 1/sigma_H0^2 / sum_invar_H0,             weight_invar_H1 = 1/sigma_H1^2 / sum_invar_H1,             weight_ss = (N_c * N_e) / (N_c + N_e) / sum_ss) %>%        select(-c(sum_invar_H0, sum_invar_H1, sum_ss)) %>%        # calculated the weighted rd and info       group_by(analysis) %>%        summarise(# weighted risk difference                 rd_invar_H0 = sum(weight_invar_H0 * abs(p_c - p_e)),                 rd_invar_H1 = sum(weight_invar_H1 * abs(p_c - p_e)),                 rd_ss = sum(weight_ss * abs(p_c - p_e)),                 rd0 = 0,                 # weighted statistical information under H1                 info_invar_H0 = 1 / sum(weight_invar_H0^2*p_c*(1-p_c)/N_c + weight_invar_H0^2*p_e*(1-p_e)/N_e),                 info_invar_H1 = 1 / sum(weight_invar_H1^2*p_c*(1-p_c)/N_c + weight_invar_H1^2*p_e*(1-p_e)/N_e),                 info_ss       = 1 / sum(weight_ss^2      *p_c*(1-p_c)/N_c + weight_ss^2      *p_e*(1-p_e)/N_e),                 # weighted statistical information under H0                 info0_invar_H0 = 1 / sum(weight_invar_H0^2*p_pool*(1-p_pool) * (1/N_c + 1/N_e)),                 info0_invar_H1 = 1 / sum(weight_invar_H1^2*p_pool*(1-p_pool) * (1/N_c + 1/N_e)),                 info0_ss       = 1 / sum(weight_ss^2      *p_pool*(1-p_pool) * (1/N_c + 1/N_e))) %>%        ungroup()     )               # calculate the power     if(integration == \"gs_power_npe\"){       res <- switch (weight_method,       \"invar_H0\" = {         gs_power_npe(theta = x$rd_invar_H0,                       info = x$info_invar_H0,                       info_scale = 2,                      binding = FALSE,                      upper = gs_b,                       lower = gs_b,                       upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,                      lpar = c(qnorm(.1), rep(-Inf, 2)),                      test_upper = TRUE,                      test_lower = TRUE,                      r = 18,                      tol = 1e-6                     )       },       \"invar_H1\" = {         gs_power_npe(theta = x$rd_invar_H1,                       info = x$info_invar_H1,                       info_scale = 2,                      binding = FALSE,                      upper = gs_b,                       lower = gs_b,                       upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,                      lpar = c(qnorm(.1), rep(-Inf, 2)),                      test_upper = TRUE,                      test_lower = TRUE,                      r = 18,                      tol = 1e-6                    )        },       \"ss\" = {         gs_power_npe(theta = x$rd_ss,                       info = x$info_ss,                       info_scale = 2,                      binding = FALSE,                      upper = gs_b,                       lower = gs_b,                       upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,                      lpar = c(qnorm(.1), rep(-Inf, 2)),                      test_upper = TRUE,                      test_lower = TRUE,                      r = 18,                      tol = 1e-6                      )       }       )              ans_new <- tibble::tibble(simu_ID = simu, method = weight_method,                                 power = res %>% filter(Bound == \"Upper\", Analysis == 3) %>% select(Probability) %>% unlist() %>% as.numeric())     }          if(integration == \"pmvtnorm\"){              if(weight_method == \"invar_H0\"){         if(under_H0){           IF_sim <- x$info0_invar_H0 / x$info0_invar_H0[3]           mean_sim <- x$rd_invar_H0 * sqrt(x$info0_invar_H0)           }else{             IF_sim <- x$info_invar_H1 / x$info_invar_H1[3]             mean_sim <- x$rd_invar_H1 * sqrt(x$info_invar_H1)           }       }              if(weight_method == \"invar_H1\"){         if(under_H0){           IF_sim <- x$info0_invar_H1 / x$info0_invar_H1[3]           mean_sim <- x$rd_invar_H1 * sqrt(x$info0_invar_H1)           }else{             IF_sim <- x$info_invar_H1 / x$info_invar_H1[3]             mean_sim <- x$rd_invar_H1 * sqrt(x$info_invar_H1)           }       }              if(weight_method == \"ss\"){                  if(under_H0){           IF_sim <- x$info0_ss / x$info0_ss[3]           mean_sim <- x$rd_ss * sqrt(x$info0_ss)           }else{             IF_sim <- x$info_ss / x$info_ss[3]             mean_sim <- x$rd_ss * sqrt(x$info_ss)           }       }              p <- pmvnorm(lower = c(rep(-Inf, 3)),                    upper = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,                    mean = mean_sim,                    corr = matrix(c(1,                         sqrt(IF_sim[1]/IF_sim[2]), sqrt(IF_sim[1]/IF_sim[3]),                                  sqrt(IF_sim[1]/IF_sim[2]), 1,                         sqrt(IF_sim[2]/IF_sim[3]),                                  sqrt(IF_sim[1]/IF_sim[3]), sqrt(IF_sim[2]/IF_sim[3]), 1),                                 nrow = 3, byrow = TRUE),                     sigma = NULL,                    algorithm = GenzBretz(maxpts = 1e5, abseps = 1e-5), keepAttr = FALSE)              # summarize this simulation       ans_new <- tibble::tibble(simu_ID = simu, method = weight_method, power = 1- p)     }          ans <- rbind(ans, ans_new)     print(simu)   }      return(ans) } n_sim <- 1e3 run simulations ans_H0 <- do.call(cbind,                   lapply(list(list(\"ss_H0\", ans$SS0),                               list(\"invar_H0\", ans$INVAR0)),                          function(x){return(run_simulation(N = x[[2]],                                                            weight_method = x[[1]],                                                            n_sim = n_sim, prevalence_ratio = prevalence_ratio,                                                            IF = IF, under_H0 = TRUE, integration = \"gs_power_npe\"))}))  ans_H1 <- do.call(cbind,                   lapply(list(list(\"ss_H1\", ans$SS1),                               list(\"invar_H1\", ans$INVAR1)),                          function(x){return(run_simulation(N = x[[2]],                                                            weight_method = x[[1]],                                                            n_sim = n_sim, prevalence_ratio = prevalence_ratio,                                                            IF = IF, under_H0 = FALSE, integration = \"gs_power_npe\"))}))  ans <- tibble::tibble(simu_ID = rep(ans_H0$simu_ID, 2),                       ss = c(ans_H0[, 3], ans_H1[, 3]),                        invar = c(ans_H0[, 6], ans_H1[, 6]),                       `calculated under` = c(rep(\"H0\", n_sim), rep(\"H1\", n_sim)))   save(ans, file = \"./fixtures/rd_simu_power_gspowernpe_2_weight.Rdata\") load(\"./fixtures/rd_simu_power_gspowernpe_2_weight.Rdata\") ans %>%    group_by(`calculated under`) %>%    summarize(`simulated power - ss` = mean(ss),              `simulated power - invar` = mean(invar)) %>%    gt::gt() %>%    gt::tab_header(title = \"Simulated power under different weightin methods\",                  subtitle = \"by gs_power_npe\")"},{"path":"https://merck.github.io/gsDesign2/articles/story_risk_difference.html","id":"summary-2","dir":"Articles","previous_headings":"","what":"Summary","title":"Group Sequential Design for Binary Outcomes","text":"\\(\\delta_{k,s}^{null}\\) risk difference \\(H_0\\). 0, positive, negative superiority, super-superiority non-inferiority design, respectively. superiority design, \\(\\widehat \\sigma^2_{H_0,k,s} = \\widehat p _{k,s}^{pool} \\left(1 - \\widehat p ^{pool}_{k,s} \\right) \\left( \\frac{1}{N_{C,k,s}} + \\frac{1}{N_{E,k,s}} \\right)\\) super-superiority design non-inferiority design, \\(\\hat \\sigma^2 _{H_0,k,s} = \\frac {\\widehat p _{C0,k,s}(1- \\widehat p_{C0,k,s})}{N_ {C,k,s}} + \\frac{ \\widehat p_{E0,k,s} (1 - \\widehat p_{E0,k,s})}{N_{E,k,s}}\\)","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Spending Time Examples","text":"multiple scenarios event-based spending group sequential designs limitations terms ensuring adequate follow-ensuring adequate spending preserved final analysis. Example contexts often arises trials may delayed treatment effect, control failure rates different expected, multiple hypotheses tested. general, situations found ensuring adequate follow-duration adequate number events important fully evaluate potential effectiveness new treatment. testing multiple hypotheses, carefully thinking possible spending issues can critical. addition, group sequential trials, preserving adequate \\(\\alpha\\)-spending final evaluation hypothesis important difficult using traditional event-based spending. document, outline three examples demonstrate issues: importance adequate events adequate follow-duration ensure power fixed design, importance guaranteeing reasonable amount \\(\\alpha\\)-spending final analysis group sequential design. trial examining outcome biomarker positive overall populations, show importance considering design reacts incorrect design assumptions biomarker prevalence. group sequential design options, demonstrate concept spending time effective way adapt. Traditionally Lan DeMets (1983), spending done according targeting specific number events outcome end trial. However, delayed treatment effect scenarios substantial literature (e.g., Lin et al. (2020), Roychoudhury et al. (2021)) documenting importance adequate follow-duration addition requiring adequate number events traditional proportional hazards assumption. approaches taken, found spending time approach generalizes well addressing variety scenarios. fact spending need correspond information fraction perhaps first raised Lan DeMets (1989) calendar-time spending discussed. However, note Proschan, Lan, Wittes (2006) raised scenarios spending alternatives considered. Two specific spending approaches suggested : Spending according minimum planned observed event counts. suggested delayed effect examples. Spending common spending time across multiple hypotheses; e.g., multiple population example, spending overall population rate biomarker positive subgroup regardless event counts time overall population. consistent Follmann, Proschan, Geller (1994) applied multiple experimental treatments compared common control. Spending time case corresponds approach Fleming, Harrington, O’Brien (1984) fixed incremental spending set potentially variable number interim analyses. document fairly long demonstrates number scenarios relevant spending time concept. layout intended make easy possibly focus individual examples interested full review. Code available unhide interested implementation. Rather bog conceptual discussion implementation details, tried provide sufficient comments code guide implementation interested .","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"delayed-effect-scenario","dir":"Articles","previous_headings":"","what":"Delayed Effect Scenario","title":"Spending Time Examples","text":"consider example single stratum possibility delayed treatment effect. next two sections consider 1) fixed design interim analysis, 2) design interim analysis. Following common assumptions: control group time--event exponentially distributed median 12 months. 2.5% one-sided Type error. 90% power. constant enrollment rate expected enrollment duration 12 months. targeted trial duration 30 months. delayed effect experimental group compared control, hazard ratio 1 first 4 months hazard ratio 0.6 thereafter. restrictions constant control failure rate, two hazard ratio time intervals constant enrollment required, simplify example. approach taken uses average-hazard ratio approach approximating treatment effect Mukhopadhyay et al. (2020) asymptotic group sequential theory Tsiatis (1982).","code":"# control median m <- 12            # enrollment rate  enrollRates <- tibble(   Stratum = \"All\",       # single stratum   duration = 12,         # expected enrollment duration of 12 months   rate = 1               # here the rate is a ratio, which will be updated to achieve the desired sample size   ) # failure rate failRates <- tibble(   Stratum = \"All\",    duration = c(4, 100),  # hazard ratio of 1 for the first 4 months and a hazard ratio of 0.6 thereafter   hr = c(1, .6),    failRate = log(2) / m, # exponential distribution   dropoutRate = .001   )"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"fixed-design-delayed-effect","dir":"Articles","previous_headings":"","what":"Fixed Design, Delayed Effect","title":"Spending Time Examples","text":"sample size events design shown . see average hazard ratio (AHR) assumptions 0.7026, part way early HR 1 later HR 0.6 assumed experimental versus control therapy.","code":"# bounds for fixed design are just a fixed bound for nominal p = 0.025, 1-sided Z_025 <- qnorm(.975)  # fixed design, single stratum # find sample size for 30 month trial under given  # enrollment and sample size assumptions xx <- gs_design_ahr(enrollRates,                      failRates,                      analysisTimes = 30,                     upar = Z_025,                      lpar = Z_025)  # get the summary table of the fixed design summary(xx,         analysis_vars = c(\"Time\", \"N\", \"Events\", \"AHR\",\"IF\"),         analysis_decimals = c(0, 0, 0, 4, 4)) %>% as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"scenario-1-less-experimental-benefit","dir":"Articles","previous_headings":"Fixed Design, Delayed Effect > Power When Assumptions Design are Wrong","what":"Scenario 1: Less Experimental Benefit","title":"Spending Time Examples","text":"assume instead effect delay 6 months instead 4 control median 10 months instead 12, substantial impact power. , assumed targeted events required final analysis resulting expected final analysis time 25 months instead planned 30 average hazard ratio 0.78 expected time analysis rather targeted average hazard ratio 0.70 original assumptions. Now also require 30 months trial duration addition targeted events. improves power 63% 76% increase 25 30 months duration 340 377 expected events, important gain. driven average hazard ratio 0.78 compared 0.76 increased expected number events. also ensures adequate follow-better describe longer-term differences survival; may particularly important early follow-suggests delayed effect crossing survival curves. Thus, adaptation event-based design based also require adequate follow-can help ensure power large clinical trial investment clinically relevant underlying survival benefit.","code":"# update the median of control arm am <- 10                           # alternate control median (the original is 12)  # update the failure rate table  failRates$duration[1] <- 6         # the original is 4 failRates$failRate <- log(2) / am  # the original is log(2)/12  # get the targeted number of events target_events <- xx$analysis$Events  # update the design and calculate the power under the targeted events yy <- gs_power_ahr(   enrollRates = xx$enrollRates,   failRates = failRates,   # here we want to achieve the target events    # and set analysisTimes as NULL   # so the analysisTime will be calculated according to the target events   events = target_events,   analysisTimes = NULL,   upar = Z_025,   lpar = Z_025)  yy %>%    summary() %>%    as_gt() yy <- gs_power_ahr(   enrollRates = xx$enrollRates,   failRates = failRates,   # here we want to achieve the targeted events,    # but also keep the 30 month as the analysisTime   events = target_events,   analysisTimes = 30,   upar = Z_025,   lpar = Z_025)  # get the summary table of updated design yy %>%    summary() %>%    as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"scenario-2-low-control-event-rates","dir":"Articles","previous_headings":"Fixed Design, Delayed Effect","what":"Scenario 2: Low Control Event Rates","title":"Spending Time Examples","text":"Now assume longer planned control median, 16 months demonstrate value retaining event count requirement. analyze 30 months, power trial 87% 288 events expected. also require adequate events, restore power 94.5, originally targeted level 90%. cost expected trial duration becomes 38.5 months rather 30; however, since control median now larger, additional follow-useful characterize tail behavior. Note scenario likely particularly interested retaining power treatment effect actually stronger original alternate hypothesis. Thus, example, time cutoff alone ensured sufficient follow-power trial.","code":"# alternate control median am <- 16                          # the original is 12  # update the failure rate failRates$failRate <- log(2) / am failRates$duration[1] <- 4  # calculate the power when trial duration is 30 month yy <- gs_power_ahr(   enrollRates = xx$enrollRates,   failRates = failRates,   # here we set analysisTime as 30    # and calculate the corresponding number of events   events = NULL,   analysisTimes = 30,   upper = gs_b, upar = Z_025,   lower = gs_b, lpar = Z_025)  yy %>%    summary() %>%    as_gt() # calculate the power when trial duration is 30 month and the events is the targeted events yy <- gs_power_ahr(   enrollRates = xx$enrollRates,   failRates = failRates,   # here we set trial duration as 30 month    # and keep the events as the target events   events = target_events,   analysisTimes = 30,   upar = Z_025,   lpar = Z_025)   yy %>%    summary() %>%    as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"conclusions-for-fixed-design","dir":"Articles","previous_headings":"Fixed Design, Delayed Effect","what":"Conclusions for Fixed Design","title":"Spending Time Examples","text":"summary, demonstrated value requiring adequate events adequate follow-duration approach analysis done one requirements. Requiring retain power important treatment benefit characterization time potential delayed onset positive beneficial treatment effect.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"alternative-spending-strategies","dir":"Articles","previous_headings":"Group Sequential Design","what":"Alternative Spending Strategies","title":"Spending Time Examples","text":"extend design detect delayed effect group sequential design single interim analysis 80% final planned events accrued. assume final analysis require targeted trial duration events based fixed design based evaluations . assume efficacy bound uses Lan DeMets (1983) spending function approximating O’Brien-Fleming bound. futility bound planned, exception demonstration one scenario. interim analysis far enough trial substantial probability stopping early design assumptions. Coding different strategies must done carefully. Spending approach 1: time design, specify spending function specifying use information fraction design. Spending approach 2: wished use 22 30 months calendar analysis times use calendar fraction spending, need specify spending time design. Spending approach 3: Next show set information-based spending power calculation timing analysis based information fraction; e.g., propose requiring achieving planned event counts, also planned study duration analysis performed. critical set maximum planned information update information fraction calculation case. Spending approach 4: final case replace information fraction design specific spending time plugged spending function compute incremental \\(\\alpha\\)-spending analysis. case, use planned information fraction design, 0.8 interim analysis 1 final analysis. used regardless scenario using compute power, recall information fraction still used computing correlations asymptotic distribution approximation design tests.","code":"# Spending for design with planned information fraction (IF) upar_design_IF <- list(   # total_spend represents one-sided Type I error   total_spend = 0.025,   # Spending function and associated    # parameter (NULL, in this case)   sf = sfLDOF,    param = NULL,   # Do NOT specify spending time here as it will be set   # by information fraction specified in call to gs_design_ahr()   timing = NULL,   # Do NOT specify maximum information here as it will be   # set as the design maximum information   max_info = NULL) # CF is for calendar fraction upar_design_CF <- upar_design_IF # Now switch spending time to calendar fraction upar_design_CF$timing <- c(22, 30)/30 # We now need to change max_info from spending as specified for design upar_actual_IF <- upar_design_IF # Note that we still have timing = NULL, unchanged from information-based design upar_actual_IF <- NULL # Replace NULL maximum information with planned maximum null hypothesis # information from design # This max will be updated for each planned design later upar_actual_IF$max_info <- 100 # Copy original upper planned spending upar_planned_IF <- upar_design_IF # Interim and final spending time will always be the same, regardless of  # expected events or calendar timing of analysis upar_planned_IF$timing <- c(0.8, 1) # We will reset planned maximum information later"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"planned-design","dir":"Articles","previous_headings":"Group Sequential Design","what":"Planned design","title":"Spending Time Examples","text":"extend design studied group sequential design single interim analysis 80% final planned events accrued. assume final analysis require targeted trial duration events based fixed design evaluations made . assume efficacy bound uses Lan-DeMets spending function approximating O’Brien-Fleming bound. futility bound planned. interim analysis far enough trial substantial probability stopping early design assumptions.","code":"# Control median m <- 12   # Planned information fraction at interim(s) and final planned_IF <- c(.8, 1)  # No futility bound lpar <- rep(-Inf, 2)   # enrollment rate enrollRates <- tibble(   Stratum = \"All\",    duration = 12,    rate = 1)  # failure rate failRates <- tibble(   Stratum = \"All\",    duration = c(4, 100),    hr = c(1, .6),    failRate = log(2) / m,    dropoutRate = .001)  # get the group sequential design model  xx <- gs_design_ahr(   enrollRates,    failRates,    # final analysis time set to targeted study duration;    # analysis times before are 'small' to ensure use of information fraction for timing   analysisTimes = c(1, 30),    # timing here matches what went into planned_IF above   IF = planned_IF,   # upper bound : spending approach 1   upper = gs_spending_bound,    upar = upar_design_IF,    # lower bound: no futility bound   lower = gs_b,    lpar = lpar)  # get the summary table xx %>%    summary() %>%    as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"two-alternate-approaches","dir":"Articles","previous_headings":"Group Sequential Design","what":"Two Alternate Approaches","title":"Spending Time Examples","text":"consider two alternate approaches demonstrate spending time concept may helpful practice. However, skipping following two subsections can done interest. first demonstrates calendar spending Lan DeMets (1989). second basically method Fleming, Harrington, O’Brien (1984) fixed incremental spend used potentially variable number interim analyses, final bound computed based unspent one-sided Type error assigned hypothesis.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"calendar-spending","dir":"Articles","previous_headings":"Group Sequential Design > Two Alternate Approaches","what":"Calendar Spending","title":"Spending Time Examples","text":"use sample size , change efficacy bound spending calendar-based. reason spending different information-based spending mainly due fact expected information linear time. case, calendar fraction interim less information fraction, exactly opposite true earlier trial. just note calendar-based spending chosen, may worth comparing design bounds bounds using spending function, information-based spending see important differences trial team possibly scientific regulatory community. note also risk enough events achieve targeted power final analysis calendar-based spending strategy. examine calendar-based spending document.","code":"yy <- gs_power_ahr(   enrollRates = xx$enrollRates,    failRates = xx$failRates,    # Planned time will drive timing since information accrues faster   events = 1:2,    # Interim time rounded   analysisTimes = c(22, 30),    # upper bound: use calendar fraction   upper = gs_spending_bound,    upar = upar_design_CF,    # lower bound: no futility bound   lower = gs_b,   lpar = lpar   )   yy %>%    summary() %>%    as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"fixed-incremental-spend-with-a-variable-number-of-aanalyses","dir":"Articles","previous_headings":"Group Sequential Design > Two Alternate Approaches","what":"Fixed Incremental Spend with a Variable Number of Aanalyses","title":"Spending Time Examples","text":"noted, method proposed Fleming, Harrington, O’Brien (1984). general strategy demonstrated interim analyses every 6 months final targeted follow-time cumulative number events achieved. efficacy analyses start, fixed incremental spend 0.001 used interim. criteria final analysis met, remaining \\(\\alpha\\) spent. Cumulative spending months 18 24 0.001 0.002, respectively, full cumulative \\(\\alpha\\)-spending 0.025 final analysis. done setting spending time 18 24 months 1/25, 2/25 1; .e., 1/25 incremental \\(\\alpha\\)-spending incorporated interim analysis remaining \\(\\alpha\\) spent final analysis. enables strategy analyzing every 6 months minimum targeted follow-minimum number events observed, time final analysis performed. skip efficacy analyses first two interim analyses months 6 12. futility, simply use nominal 1-sided p-value 0.05 favoring control interim. note raises flag futility bound crossed Data Monitoring Committee (DMC) can choose continue trial even futility bound crossed. However, bound may effective providing DMC guidance stop futility prematurely. comparison designs, leave enrollment rates, failure rates, dropout rates final analysis time . see following table summarizing efficacy bounds power little impact total power futility analyses specified. cumulative \\(\\alpha\\)-spending 0.001 0.002 efficacy interim analyses, see nominal p-value bound second interim 0.0015, 0.001 incremental \\(\\alpha\\)-spend. also note nominal p-values testing, approximate hazard ratio required cross bounds presumably help justify consideration completing trial based definitive interim efficacy finding. Also, small interim spend, final nominal p-value reduced much overall \\(\\alpha=0.025\\) Type error set group sequential design. also examine futility bound. nominal p-value 0.05 analysis one-sided p-value favor control experimental treatment. can see probability stopping early alternate hypothesis (\\(\\beta\\)-spending) substantial even given early delayed effect. Also, substantial approximate observed hazard ratios cross futility bound seem reasonable given timing number events observed; exception small number events first interim, larger number observed time early excess risk. may useful plan additional analyses futility bound crossed support stopping . example, looking subgroups evaluating smoothed hazard rates time treatment group may useful. clinical trial study team complete discussion futility bound considerations time design.","code":"# Cumulative spending at IA3 and IA4 will be 0.001 and 0.002, respectively. # Power spending function sfPower with param = 1 is linear in timing # which makes setting the above cumulative spending targets simple by # setting timing variable the the cumulative proportion of spending at each analysis. # There will be no efficacy testing at IA1 or IA2. # Thus, incremental spend, which will be unused, is set very small for these analyses. upar_FHO <- list(   total_spend = 0.025,   sf = sfPower,   param = 1,   timing = c((1:2)/250, (1:2)/25, 1))  FHO <- gs_power_ahr(   enrollRates = xx$enrollRates,   failRates = xx$failRates,   events = NULL,   analysisTimes = seq(6, 30, 6),   upper = gs_spending_bound,   upar = upar_FHO,   # No efficacy testing at IA1 or IA2   # Thus, the small alpha the spending function would have   # allocated will not be used   test_upper = c(FALSE, FALSE, TRUE, TRUE, TRUE),   lower = gs_b,   lpar = c(rep(qnorm(.05), 4), -Inf))  FHO %>%    summary() %>%    as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"scenario-with-less-treatment-effect","dir":"Articles","previous_headings":"Group Sequential Design","what":"Scenario with Less Treatment Effect","title":"Spending Time Examples","text":", compute power assumption changing median control group time--event 10 months rather assumed 12 delay effect onset 6 months rather 4. otherwise change enrollment, dropout hazard ratio assumptions. following examples, require targeted number events targeted trial duration group sequential design interim final analyses. first example, uses interim spending based event count observed originally planned final event count information fraction 323 / 355 = 0.91. gives event-based spending 0.0191, substantially targeted information fraction 284 / 355 = 0.8 targeted interim spending 0.0122. reduces power overall 76% 73% lowers nominal p-value bound final analysis 0.0218 0.0165; see following two tables. Noting average hazard ratio 0.8 interim 0.76 final analysis emphasizes value preserving \\(\\alpha\\)-spending final analysis. Thus, example valuable limit spending interim analysis minimum planned spending opposed using event-based spending. Just important, general design principle making interim analysis criteria stringent final ensured alternate scenario. multiple trials delayed effects observed difference final nominal p-value bound made difference ensure statistically significant finding.","code":"# Alternate control median am <- 10   # Update the failure rate failRates$failRate <- log(2) / am failRates$duration[1] <- 6  # Set planned maximum information from planned design max_info0 <- max(xx$analysis$info) upar_actual_IF <- upar_design_IF upar_actual_IF$max_info <- max_info0  # compute power if actual information fraction relative to original # planned total is used yy <- gs_power_ahr(   enrollRates = xx$enrollRates,    failRates = failRates,    # Planned time will drive timing since information accrues faster   events = 1:2,    analysisTimes = xx$analysis$Time,   upper = gs_spending_bound,    upar = upar_actual_IF,    lower = gs_b,   lpar = lpar   )   yy %>%    summary() %>%    filter(Bound == \"Efficacy\") %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4) yz <- gs_power_ahr(   enrollRates = xx$enrollRates,    failRates = failRates,    events = xx$analysis$Events,   analysisTimes = xx$analysis$Time,   upper = gs_spending_bound,    upar = upar_planned_IF,    lpar = lpar)   yz %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"scenario-with-longer-control-median","dir":"Articles","previous_headings":"Group Sequential Design","what":"Scenario with Longer Control Median","title":"Spending Time Examples","text":"Now return example control median longer expected confirm spending according planned level alone without considering actual number events also result power reduction. power gain great (94.2% vs 95.0%) interim final p-value bounds aligned intent emphasizing final analysis smaller average hazard ratio expected (0.680 vs 0.723 interim). First, show result using planned spending. Since number events less expected, used actual number events interim bound stringent obtain slightly greater power.","code":"# Alternate control median am <- 16   # Update the failure rate failRates$failRate <- log(2) / am # Return to 4 month delay with HR=1 before HR = 0.6 failRates$duration[1] <- 4  # Start with spending based on planned information # which is greater than actual information yy <- gs_power_ahr(   enrollRates = xx$enrollRates,    failRates = failRates,    events = c(1, max(xx$analysis$Events)),   analysisTimes = xx$analysis$Time,   upper = gs_spending_bound,    upar = upar_planned_IF,    lower = gs_b,   lpar = lpar)   yy %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4) yz <- gs_power_ahr(   enrollRates = xx$enrollRates,    failRates = failRates,    events = c(1, max(xx$analysis$Events)),   analysisTimes = xx$analysis$Time,   upper = gs_spending_bound,    upar = upar_actual_IF,    lower = gs_b,   lpar = lpar)   yz %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"summary-for-spending-time-motivation-assuming-delayed-benefit","dir":"Articles","previous_headings":"Group Sequential Design","what":"Summary for Spending Time Motivation Assuming Delayed Benefit","title":"Spending Time Examples","text":"summary, using minimum planned actual spending adapt design based event-based spending adapts interim bound stringent final bound different scenarios ensures better power event-based interim analysis spending.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"assumptions","dir":"Articles","previous_headings":"Testing Multiple hypotheses","what":"Assumptions","title":"Spending Time Examples","text":"consider simple case use method Maurer Bretz (2013) test overall population biomarker subgroup endpoint. assume exponential failure rate median 12 control group regardless population. hazard ratio biomarker positive subgroup assumed 0.6, negative population 0.8. assume biomarker positive group represents half population, meaning enrollment rates assumed negative positive patients. difference failure rates two strata hazard ratio. case, assume proportional hazards within negative (HR = 0.8) positive (HR = 0.6) patients. illustrative purposes, choosing strategy based possible feeling much less certainty study start whether underlying benefit biomarker negative population. wish ensure power biomarker positive group, allow good chance positive overall population finding lesser benefit biomarker negative population. alternative trial strategy planned, alternate approach following considered. case, design first biomarker positive population one-sided Type error controlled \\(\\alpha = 0.0125\\):","code":"# we assume an exponential failure rate with a median of 12  # for the control group regardless of population.  m <- 12  # the enrollment rate of both subgroup and population is the same enrollRates <- tibble(   Stratum = c(\"Positive\", \"Negative\"),    duration = 12,    rate = 20)  # the hazard ratio in the biomarker positive subgroup will be assumed to be 0.6,  # and in the negative population 0.8. failRates <- tibble(   Stratum = c(\"Positive\", \"Negative\"),    hr = c(0.6, 0.8),   duration = 100,   failRate = log(2) / m,   dropoutRate = 0.001)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"planned-design-for-biomarker-positive-population","dir":"Articles","previous_headings":"Testing Multiple hypotheses","what":"Planned Design for Biomarker Positive Population","title":"Spending Time Examples","text":"","code":"# Since execution will be event-based for biomarker population, # there will be no need to change spending plan for different scenarios.  # upper bound: spending based on information fraction upar_design_spend <- list(   sf = gsDesign::sfLDOF, # spending function   total_spend = 0.0125,  # total alpha spend is now 0.0125    timing = NULL,         # to select maximum planned information for information fraction   param = NULL             )  # lower bound: no futility bound lpar <- rep(-Inf, 2)     # Z = -infinity for lower bound  # we will base the combined hypothesis design to ensure power in the biomarker subgroup positive <- gs_design_ahr(   # enroll/failure rates   enrollRates = enrollRates %>% filter(Stratum == \"Positive\"),   failRates = failRates %>% filter(Stratum == \"Positive\"),   # Following drives information fraction for interim   IF = c(.8, 1),    # Total study duration driven by final analysisTimes value, i.e., 30   # Enter small increasing values before that    # so information fraction in planned_IF drives timing of interims   analysisTimes = c(1, 30),   # upper bound   upper = gs_spending_bound,    upar = upar_design_spend,   # lower lower    lower = gs_b,    lpar = lpar)  positive %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"planned-design-for-overall-population","dir":"Articles","previous_headings":"Testing Multiple hypotheses","what":"Planned Design for Overall Population","title":"Spending Time Examples","text":"adjust overall study enrollment rate match design requirement biomarker positive population. Now can examine power overall population based hazard ratio assumptions biomarker negative biomarker positive subgroups just calculated enrollment assumption. use analysis times biomarker positive population design. see interim information fraction overall population slightly greater biomarker positive population . compensate enable flexibility biomarker positive prevalence changes, use spending time biomarker positive subgroup regardless true fraction final planned events analysis. Thus, interim nominal p-value bound biomarker positive overall populations. make much difference , see natural way adapt design observed biomarker positive prevalence different assumed design.","code":"# Get enrollment rate inflation factor compared to originally input rate inflation_factor <- positive$enrollRates$rate[1] / enrollRates$rate[1]  # Using this inflation factor, set planned enrollment rates planned_enrollRates <- enrollRates %>% mutate(rate = rate * inflation_factor) planned_enrollRates %>% gt() # Store overall enrollment rates for future use overall_enrollRates <- planned_enrollRates %>%    summarize(     Stratum = \"All\",      duration = first(duration),      rate = sum(rate))  overall_enrollRates %>% gt() # Set total spend for overall population, O'Brien-Fleming spending function, and  # same spending time as biomarker subgroup upar_overall_planned_IF <- list(   sf = gsDesign::sfLDOF,  # O'Brien-Fleming spending function   param = NULL,   total_spend = 0.0125,   # alpha   timing = c(.8, 1),      # same spending time as biomarker subgroup   max_info = NULL         # we will use actual final information as planned initially   )  overall_planned_bounds <- gs_power_ahr(   # enroll/failure rates   enrollRates = planned_enrollRates,   failRates = failRates,   # analysis time: the planed analysis time for biomarker positive population    analysisTimes = positive$analysis$Time,   # events will be determined by expected events at planned analysis times   events = NULL,    # upper bound: planned spending times are specified the same as before   upper = gs_spending_bound,   upar = upar_overall_planned_IF,   # lower bound: no futility    lower = gs_b,   lpar = lpar)   overall_planned_bounds %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"alternate-scenarios-overview","dir":"Articles","previous_headings":"Testing Multiple hypotheses","what":"Alternate Scenarios Overview","title":"Spending Time Examples","text":"divide evaluations three subsections: one higher prevalence biomarker positive patients expected; one lower biomarker prevalence; differing event rate hazard ratio assumptions. case, assume total enrollment rate 48.8 per month planned . also assume enroll targeted biomarker positive subgroup enrollment 293 achieved, regardless overall enrollment. specify interim analysis timing require 80% planned final analysis events biomarker positive population least 10 months minimum follow-; thus, biomarker population never vary events spending . spending time used overall population, compare event-based spending. choices arbitrary. think reasonable, design planner think carefully variations suit clinical trial team needs.","code":"## Setting spending alternatives  # Using information (event)-based spending time relative to overall population plan # Set total spend for overall population, O'Brien-Fleming spending function.  # For design information-spending, we set timing =  NULL and max_info to plan from above upar_overall_planned_IF <- list(   sf = gsDesign::sfLDOF,                        # O'Brien-Fleming spending function   total_spend = 0.0125,                         # alpha   max_info = max(overall_planned_bounds$info0), # we will use planned final information for                                                  # overall population from design to                                                  # compute information fraction relative to plan   param = NULL,   timing = planned_IF)  # Using planned information fraction will demonstrate problems below. # Set total spend for overall population, O'Brien-Fleming spending function, and  # same spending time as biomarker subgroup upar_overall_actual_IF <- list(   sf = gsDesign::sfLDOF,                        # O'Brien-Fleming spending function   total_spend = 0.0125,                         # alpha   max_info = max(overall_planned_bounds$info0), # we will use planned final information                                                  # for overall population from design   param = NULL,   timing = NULL)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"biomarker-subgroup-power","dir":"Articles","previous_headings":"Testing Multiple hypotheses > Alternate Scenarios Overview > Biomarker Subgroup Prevalence Higher than Planned","what":"Biomarker Subgroup Power","title":"Spending Time Examples","text":"suppose biomarker prevalence 60%, higher 50% prevalence design anticipated. enrollment rates positive versus negative patients expected enrollment duration now: Now can compute power biomarker positive group targeted events. Since simple proportional hazards model, thing changing original design takes slightly less time.","code":"# update the enrollment rate due to 60% prevalence positive_60_enrollRates <- rbind(   overall_enrollRates %>% mutate(Stratum = \"Positive\", rate = 0.6 * rate),   overall_enrollRates %>% mutate(Stratum = \"Negative\", rate = 0.4 * rate) )  # update the enrollment duration positive_60_enrollRates$duration <- max(positive$analysis$N) /                                     overall_enrollRates$rate /                                      0.6  # display the updated enrollment rate table positive_60_enrollRates %>%    gt() %>%    fmt_number(columns = \"rate\", decimals = 1) positive_60_power <- gs_power_ahr(   # enrollment/failure rate   enrollRates = positive_60_enrollRates %>% filter(Stratum == \"Positive\"),   failRates = failRates %>% filter(Stratum == \"Positive\"),   # number of events   events = positive$analysis$Events, # positive$bounds$Events[1:K],   # analysis time will be calcuated to achieve the targeted events   analysisTimes = NULL,   # upper bound   upper = gs_spending_bound,   upar = upar_design_spend,   # lower bound   lower = gs_b,   lpar = lpar)   positive_60_power %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"overall-population-power","dir":"Articles","previous_headings":"Testing Multiple hypotheses > Alternate Scenarios Overview > Biomarker Subgroup Prevalence Higher than Planned","what":"Overall Population Power","title":"Spending Time Examples","text":"Now use spending overall population, resulting full \\(\\alpha\\)-spending end trial even though originally targeted events expected achieved. note information fraction computed based originally planned events overall population. Given larger proportion patients biomarker positive, average hazard ratio stronger originally planned power overall population still 90%. used information-based (.e., event-based) spending, reached full spending final analysis thus lower power.","code":"gs_power_ahr(   # set the enrollment/failure rate   enrollRates = positive_60_enrollRates,   failRates = failRates,   # set evnets and analysis time   events = NULL,   analysisTimes = positive_60_power$analysis$Time,   # set upper bound: use planned spending in spite of lower overall information   upper = gs_spending_bound,   upar = upar_overall_planned_IF,   # set lower bound: no futility   lower = gs_b,    lpar = rep(-Inf, 2)   ) %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4) gs_power_ahr(   # set the enrollment/failure rate   enrollRates = positive_60_enrollRates,   failRates = failRates,   # set evnets and analysis time   events = NULL,   analysisTimes = positive_60_power$analysis$Time,   # upper bound: use actual spending which uses less than complete alpha   upper = gs_spending_bound,   upar = upar_overall_actual_IF,   # lower bound: no futility    lower = gs_b,    lpar = lpar   ) %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"biomarker-subgroup-prevalence-lower-than-planned","dir":"Articles","previous_headings":"Testing Multiple hypotheses > Alternate Scenarios Overview","what":"Biomarker Subgroup Prevalence Lower Than Planned","title":"Spending Time Examples","text":"suppose biomarker prevalence 40%, lower 50% prevalence design anticipated. enrollment rates positive versus negative patients expected enrollment duration now :","code":"# set the enrollment rate under 40% prevalence positive_40_enrollRates <- rbind(   overall_enrollRates %>% mutate(Stratum = \"Positive\", rate = 0.4 * rate),   overall_enrollRates %>% mutate(Stratum = \"Negative\", rate = 0.6 * rate) )  # update the duration of enrollment table positive_40_enrollRates$duration <- max(positive$analysis$N) /                                      positive_40_enrollRates$rate[1]  # display the enrollment table positive_40_enrollRates %>%    gt() %>%    fmt_number(columns = \"rate\", decimals = 1)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"biomarker-positive-subgroup-power","dir":"Articles","previous_headings":"Testing Multiple hypotheses > Alternate Scenarios Overview > Biomarker Subgroup Prevalence Lower Than Planned","what":"Biomarker Positive Subgroup Power","title":"Spending Time Examples","text":"Now can compute power biomarker positive group targeted events.","code":"upar_actual_IF$total_spend <- 0.0125 upar_actual_IF$max_info <- max(positive$analysis$info)  positive_40_power <- gs_power_ahr(   # set enrollment/failure rate   enrollRates = positive_40_enrollRates %>% filter(Stratum == \"Positive\"),   failRates = failRates %>% filter(Stratum == \"Positive\"),   # set events/analysis time   events = positive$analysis$Events,   analysisTimes = NULL,   # set upper bound   upper = gs_spending_bound,   upar = upar_actual_IF,    # set lower bound   lower = gs_b,   lpar = rep(-Inf, 2))  positive_40_power %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"overall-population-power-1","dir":"Articles","previous_headings":"Testing Multiple hypotheses > Alternate Scenarios Overview > Biomarker Subgroup Prevalence Lower Than Planned","what":"Overall Population Power","title":"Spending Time Examples","text":"see adapting overall sample size spending according biomarker subgroup, retain 90% power. spite lower overall effect size, larger adapted sample size ensures power retention.","code":"gs_power_ahr(   enrollRates = positive_40_enrollRates,   failRates = failRates,   events = 1:2,   analysisTimes = positive_40_power$analysis$Time,   upper = gs_spending_bound,   upar = upar_overall_planned_IF,   lower = gs_b,   lpar = rep(-Inf,2)) %>%    summary() %>%    gt() %>%    fmt_number(columns = 3:6, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_spending_time_example.html","id":"summary-of-findings","dir":"Articles","previous_headings":"Testing Multiple hypotheses","what":"Summary of Findings","title":"Spending Time Examples","text":"suggested two overall findings planning executing trial potentially delayed treatment effect: Require targeted event count minimum follow-completing analysis trial helps ensure powering trial appropriately better description tail behavior may essential long-term results key establishing potentially positive risk-benefit. Use fixed, small incremental \\(\\alpha\\)-spend interim proposed Fleming, Harrington, O’Brien (1984) variable number interim analyses ensure adequate follow-. Use minimum planned actual spending interim analyses. implementing Fleming, Harrington, O’Brien (1984) approach, also suggested simple approach futility may quite useful practically scenario potentially delayed onset treatment effect. basically looks evidence favorable control group effect relative experimental setting nominal p-value cutoff 1-sided 0.05 level early interim futility analyses. crossing survival curves inferior survival curves may exist, may useful way ensure continuing trial ethical; approach perhaps useful experimental treatment replacing components control treatment case add-treatment may toxic potentially detrimental effects. addition delayed effect example, considered example testing biomarker positive subgroup overall population. Using common spending time hypotheses common interim analysis strategy advocated Follmann, Proschan, Geller (1994) can helpful implement spending hypotheses adequate \\(\\alpha\\) spend final analysis also ensure full utilization \\(\\alpha\\)-spending. suggested using minimum planned actual spending interim analysis. Spending can based key hypothesis (e.g., biomarker positive population) minimum spending time among hypotheses tested. Taking advantage know correlations ensure full \\(\\alpha\\) utilitization multiple hypothesis testing also simply implemented strategy Anderson et al. (2021). summary, illustrated motivation illustration spending time approach examples commonly encountered. Approaches suggested included implementation Fleming, Harrington, O’Brien (1984) fixed incremental \\(\\alpha\\)-spend interim analysis well use minimum planned actual spending interim analyses.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"vignette introduces publication quality table production group sequential designs gsDesign2 package. also demonstrates designs example scenario using multiple design approaches. divide document 3 parts: Design specification derivation Printing design summary tables Details output design functions Details table output options reader can decide sections interest . function used generate bounds tables gsDesign2::summary(). Users can use gsDesign2::as_gt() format table using gt package. vignette, introduce general approach bound summaries examples using different design approaches time--event outcome: average hazard ratio (AHR) method extended Mukhopadhyay et al. (2020) using gsDesign2::gs_design_ahr(); weighted logrank (WLR) method Yung Liu (2019) using gsDesign2::gs_design_wlr();","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"design-parameters","dir":"Articles","previous_headings":"Design Specification and Derivation","what":"Design Parameters","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"design parameters use across different designs derived :","code":"# enrollment/failure rates enrollRates <- tibble::tibble(    Stratum = \"All\",     duration = 12,     rate = 30) failRates <- tibble::tibble(    Stratum = \"All\",     duration = c(4, 100),     failRate = log(2) / 12,    hr = c(1, .6),     dropoutRate = .001)  # Information fraction IF <- (1:3)/3  # Analysis times in months; first 2 will be ignored as IF will not be achieved analysisTimes <- c(.01, .02, 36)    # Experimental / Control randomization ratio ratio <- 1   # 1-sided Type I error alpha <- 0.025  # Type II error (1 - power) beta <- 0.1   # Upper bound upper <- gsDesign2::gs_spending_bound     # alpha-spending bound upar <- list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)             # Lower bound lower <- gsDesign2::gs_spending_bound    # beta-spending bound lpar <- list(sf = gsDesign::sfHSD, total_spend = 0.1, param = 0, timing = NULL)  # Fleming-Harrington (FH) weight functions for weighted logrank (WLR) wgt00 <- function(x, arm0, arm1){    # Equal weighting for logrank    gsDesign2::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)} wgt05 <- function(x, arm0, arm1){    # Early downweighting with FH(0,.5)     gsDesign2::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = .5)}  # Both of above tests for MaxCombo: logrank and FH(0,.5) fh_test <- rbind(    # Include logrank for all 3 analyses    data.frame(rho = 0, gamma = 0, tau = -1, test = 1, Analysis = 1:3, analysisTimes = c(12, 24, 36)),     # Only include FH(0,.5) for analyses 2 and 3    data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1, test = 2:3, Analysis = 3, analysisTimes = 36))"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"ahr-design-derivation","dir":"Articles","previous_headings":"Design Specification and Derivation > Deriving Designs","what":"AHR design derivation","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"Using design parameters , AHR design derived follows: using design parameters , one can generate AHR model gs_design_ahr ","code":"x_design_ahr <- gs_design_ahr(    enrollRates = enrollRates,    failRates = failRates,    IF = IF,     analysisTimes = analysisTimes,     ratio = ratio,     alpha = alpha,     beta = beta,     upper = upper,    upar = upar,    lower = lower,    lpar = lpar )  x_power_ahr <- gs_power_ahr(    enrollRates = x_design_ahr$enrollRates,    failRates = x_design_ahr$failRates,    events = c(100, 200, 300),    analysisTimes = NULL,    upper = upper,    upar = upar,    lower = lower,    lpar = lpar )"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"wlr-design-derivation","dir":"Articles","previous_headings":"Design Specification and Derivation > Deriving Designs","what":"WLR design derivation","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"","code":"x_design_wlr <- gs_design_wlr(    enrollRates = enrollRates,    failRates = failRates,    weight = wgt05,     IF = NULL,     analysisTimes = sort(unique(x_design_ahr$analysis$Time)),     ratio = ratio,     alpha = alpha,     beta = beta,       upper = upper,    upar = upar,    lower = lower,    lpar = lpar )  x_power_wlr <- gs_power_wlr(    enrollRates = x_design_wlr$enrollRates,    failRates = x_design_wlr$failRates,    weight = wgt05,     events = c(50, 100, 150),    analysisTimes = NULL,     upper = upper,    upar = upar,    lower = lower,    lpar = lpar )"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"default-summary-table-production","dir":"Articles","previous_headings":"","what":"Default Summary Table Production","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"Instead outputting 4 detailed tables (table enrollment rates, table failure rates, table analysis summary, table bounds summary), users can get com pensive summary table calling summary(x), x object returned either gs_design_ahr gs_design_wlr. summary() function produces overall summary table bounds publication protocol. example, default output summary() AHR method Please note summary() can also applied objected returned gs_power_ahr(). example, default output summary() WLR method Note summary() can also applied summarize object returned gs_power_wlr().","code":"x_design_ahr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4) x_power_ahr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4) x_design_wlr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4) x_power_wlr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"detailed-summary-table-formatting","dir":"Articles","previous_headings":"","what":"Detailed Summary Table Formatting","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"demonstrate options formatting analysis rows, bound rows well table parameters titles, labels footnotes.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"custom-the-variables-to-be-summaried-for-each-analysis","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom the Variables to be Summaried for Each Analysis","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"default table summary table generated summary(x), variables used summarize analysis includes Analysis, Time, N(sample size), Events, AHR, (information fraction). users can customize variables chosen using analysis_vars = ... corresponding decimals displayed using argument analysis_decimals = .... example Please note need input \"Analysis\" analysis_vars = ... always appear.","code":"summary(    x_design_ahr,    analysis_vars = c(\"N\", \"Events\"),    analysis_decimals = c(1, 1)    ) %>%     gt::gt() %>%     gt::fmt_number(columns = c(3:6), decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"custom-the-bound-names","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom the Bound Names","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"Users can also customize bound names. default output generated summary(x), bound name c(\"Efficacy\", \"Futility\"), can changed c(\"better\", \"B better\") 2-sided design using argument bound_names = .... example,","code":"summary(    x_design_ahr,    bound_names = c(\"A is better\", \"B is better\")    ) %>%     mutate_if(is.numeric, round, digits = 4) %>%     gt::gt() %>%     gt::fmt_number(columns = c(3:6), decimals = 4) #> `mutate_if()` ignored the following grouping variables: #> • Column `Analysis`"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"custom-into-a-gt-table-and-add-titlesubtitlefootnotesspanners","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom into a gt Table and Add Title/SubTitle/Footnotes/Spanners","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"Users can also use as_gt() get R table gt table. Furthermore, can edit title/subtitle/spanner/footnotes gt table using arguments summary. objective can also realized using functions R package gt custom design table layout. note as_gt() always produces gt object , thus, can customized gt package formatting functions. future, support rich text format using function as_rtf() fashion similar as_gt().","code":"summary(x_design_ahr) %>%     as_gt(title = \"Summary of the Crossing Probability\",          subtitle = \"by Using gs_design_ahr\",          colname_spanner = \"Cumulative boundary crossing probability\",          colname_spannersub = c(\"Alternate hypothesis\", \"Null hypothesis\"),          footnote = list(content = c(\"approximate hazard ratio to cross bound.\",                                       \"gs_design_ahr is a function in gsDesign2.\",                                      \"AHR is average hazard ratio; IF is information fraction.\"),                          location = c(\"~HR at bound\", NA, NA),                          attr = c(\"colname\", \"subtitle\", \"analysis\")))"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"custom-the-variables-to-display","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom the Variables to Display","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"Users can select variables displayed summary table using argument display_colunm = ....","code":"summary(x_design_ahr) %>%     as_gt(display_columns = c(\"Analysis\", \"Bound\", \"Z\", \"Probability\"))"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"custom-whether-to-show-infinity-bound-or-not","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom Whether to Show Infinity Bound or Not","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"Users options either show infinity bounds taking advantage display_inf_bound = ....","code":"summary(x_design_ahr) %>%     as_gt(display_inf_bound = FALSE)"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"details-of-output-from-designpower-functions","dir":"Articles","previous_headings":"","what":"Details of Output from Design/Power Functions","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"four components objects returned either gs_design_ahr()/gs_design_wlr() gs_power_ahr()/gs_power_wlr(): 1. failure rates: table summarizing failure rate dropout rate. 1. enrollment rates: table summarizing enrollment rate. 1. bounds: table summarize bound analysis. 1. analysis: table summarize analysis, one row one analysis one hypothsis.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"failure-rates","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Failure Rates","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"failure rates different gsDesign object can obtained using x$failRates, x object returned either gs_design_ahr gs_design_wlr. example, failure rates AHR design derivation can returned calling Please note x_design_ahr x_wlr returns failure rates, inputted failRates. verify, let’s take look failure rate WLR design derivation, shown .","code":"x_design_ahr$failRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3:5, decimals = 4) x_design_wlr$failRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3:5, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"enrollment","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Enrollment","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"enrollment rate gs design derivation can collected using x$failRates, x object returned either gs_design_ahr gs_design_wlr. example, enrollment rates AHR/WLR design derivation can seen , although design derivation different, enrollment rate table share table structure, enrollment period durations rate. Yet, enrollment rates differ designs multiplicative constant.","code":"x_design_ahr$enrollRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3, decimals = 4) x_design_wlr$enrollRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"analysis","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Analysis","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"analysis summary table structure one row per analysis per hypothesis. columns can vary different defaults design option. type tables useful understanding commonalities designs summarized different models. get analysis summary table, users can call x$analysis, x object returned either gs_design_ahr gs_design_wlr. example, analysis summary AHR/WLR design derivation ","code":"x_design_ahr$analysis %>%     gt::gt() %>%     gt::fmt_number(columns = 2:8, decimals = 4) x_design_wlr$analysis %>%     gt::gt() %>%     gt::fmt_number(columns = 2:8, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/story_summarize_designs.html","id":"bounds","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Bounds","title":"Summarize Group Sequential Designs in Nice gt Tables","text":"analysis summary table structure One row per analysis per bound per hypothesis. Columns can vary different defaults design option. get bouns summary table, users can call x$analysis, x object returned either gs_design_ahr gs_design_wlr. example, bounds summary AHR/WLR design derivation ","code":"x_design_ahr$bounds %>%     gt::gt() %>%     gt::fmt_number(columns = c(3, 5:7), decimals = 4) x_design_wlr$bounds %>%     gt::gt() %>%     gt::fmt_number(columns = c(3, 5:7), decimals = 4)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"goals","dir":"Articles","previous_headings":"","what":"Goals","title":"Style guide","text":"overall goal style guide: User experience: ensure consistent API syntax minimal surprises using software. Developer experience: minimize time cost make consistent interface design decisions developing software. Ultimately, style guide help us Support healthy coexistence user-facing, functional API, low-level, object-oriented API. Create balanced alignment style best practices presented high-quality research software. Build universe software clinical trial design scale.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"package-names","dir":"Articles","previous_headings":"","what":"Package names","title":"Style guide","text":"General principles deciding name package: Prefer lower case Use dot (.) indicate collection extension packages. Examples include “gamlss” packages “future” packages. Can easily searched found using search engines. Follow existing conventions, even don’t agree rules . Examples include gsDesign gsDesign2. Note package name product name can stylized differently. Example: tensorflow vs. TensorFlow.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"functional-api","dir":"Articles","previous_headings":"","what":"Functional API","title":"Style guide","text":"user-facing interactions functional API.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"functions","dir":"Articles","previous_headings":"Functional API","what":"Functions","title":"Style guide","text":"Function names, argument names, variable names use snake_case.","code":"# Good gs_design_ahr <- function(enroll_rates = ...) {}  # Bad gsDesignAHR <- function(enrollRates = ...) {}"},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"methods","dir":"Articles","previous_headings":"Functional API","what":"Methods","title":"Style guide","text":"rule also applies S3 R7 method names argument names, inherently, functions. One still follow S3 convention use dot (.) connect method name class name.","code":"# Good as_gt.gsDesign <- function(...) {}  # Bad as.gt.gsDesign <- function(...) {}"},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"object-oriented-api","dir":"Articles","previous_headings":"","what":"Object-oriented API","title":"Style guide","text":"Object-oriented API selectively used low-level abstractions limited cases user-facing interactions appropriate.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"classes","dir":"Articles","previous_headings":"Object-oriented API","what":"Classes","title":"Style guide","text":"Class names defined OOP system, example, S3 R7, use UpperCamelCase. rule intends indicate “function” class constructor, instead (regular) exported internal function follows conventions R6. input argument names variable names still use snake_case.","code":"# Good RangedDoubleOrNULL <- new_class(   \"RangedDoubleOrNULL\",   properties = list(     value = class_any,     min = class_double,     max = class_double,     min_closed = class_logical,     max_closed = class_logical   ),   ... )  # Bad ranged_double_or_null <- new_class(   \"ranged_double_or_null\",   properties = list(     value = class_any,     min = class_double,     max = class_double,     min_closed = class_logical,     max_closed = class_logical   ),   ... )"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"argument-order","dir":"Articles","previous_headings":"Arguments","what":"Argument order","title":"Style guide","text":"Arguments arranged order data, descriptors, details. style makes natural consistently create chainable operations form workflow either functional API object-oriented API, minimal surprises. suggests “data” argument requires multiple inputs, create another function bundle single object pass function interest.","code":"# Functional API design <- create_design(enroll_rates, fail_rates, ...) design |>   do_compute_1(detail_1 = ...) |>   do_compute_2(detail_2 = ...) # Object-oriented API design <- Design(enroll_rates, fail_rates, ...) design$do_compute_1(detail_1 = ...)$do_compute_2(detail_2 = ...)"},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"required-and-optional-arguments","dir":"Articles","previous_headings":"Arguments","what":"Required and optional arguments","title":"Style guide","text":"Required arguments default value. contrast, optional arguments default value.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"enumerated-type-arguments","dir":"Articles","previous_headings":"Arguments","what":"Enumerated type arguments","title":"Style guide","text":"Use lower case abbreviations snake_case enumerated type arguments. reasoning behind : strings used together function names argument names, using snake_case create visual consistency. Whenever possible, set default value enumerated type input argument definition. See enumerate possible options.","code":"# Bad f <- function(method = c(\"AHR\", \"WLR\", ...)) {}  # Good f <- function(method = c(\"ahr\", \"wlr\", ...)) {} # Bad f <- function(approx = c(\"event driven\", \"asymptotic\", \"generalized schoenfeld\", ...)) {}  # Good f <- function(approx = c(\"event_driven\", \"asymptotic\", \"generalized_schoenfeld\", ...)) {}"},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"code-formatting","dir":"Articles","previous_headings":"","what":"Code formatting","title":"Style guide","text":"R code formatted using styler default tidyverse style. C/C++ code formatted using clang-format. doable via Visual Studio Code C++ extension. code formatting can automatically checked CI/CD workflows.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"code-linting","dir":"Articles","previous_headings":"","what":"Code linting","title":"Style guide","text":"rules enforced via CI/CD workflow code linting. Example GitHub Actions workflow Customize code linting rules","code":""},{"path":"https://merck.github.io/gsDesign2/articles/style.html","id":"useful-links","dir":"Articles","previous_headings":"","what":"Useful links","title":"Style guide","text":"tidyverse style guide tidyverse design guide R6 - Advanced R TensorFlow Probability API Style guides rules - Software Engineering Google","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_AHR.html","id":"introduction-of-ahr","dir":"Articles","previous_headings":"","what":"Introduction of AHR()","title":"AHR: computes AHR under NPH assumptions and (stratified) populations","text":"AHR() provides geometric average hazard ratio various non-proportional hazards assumptions either single multiple strata studies. piecewise exponential distribution allows simple method specify distribution enrollment pattern enrollment, failure dropout rates changes time.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_AHR.html","id":"example-1-un-stratified-population","dir":"Articles","previous_headings":"Usage of AHR()","what":"Example 1: Un-stratified population","title":"AHR: computes AHR under NPH assumptions and (stratified) populations","text":"","code":"enrollRates <- tibble(Stratum = \"All\",                       duration = c(2, 10, 4, 4, 8),                       rate = c(5, 10, 0, 3, 6)) failRates <- tibble(Stratum = \"All\",                     duration = 1,                     failRate = c(.1, .2, .3, .4),                     hr = c(.9, .75, .8, .6),                     dropoutRate = .001) AHR(enrollRates = enrollRates, failRates = failRates, totalDuration = c(15, 30)) ## # A tibble: 2 × 5 ##    Time   AHR Events  info info0 ##   <dbl> <dbl>  <dbl> <dbl> <dbl> ## 1    15 0.694   91.0  22.6  22.7 ## 2    30 0.685  154.   37.9  38.6"},{"path":"https://merck.github.io/gsDesign2/articles/usage_AHR.html","id":"example-2-stratified-population","dir":"Articles","previous_headings":"Usage of AHR()","what":"Example 2: Stratified population","title":"AHR: computes AHR under NPH assumptions and (stratified) populations","text":"","code":"enrollRates <- tibble(Stratum = c(rep(\"Low\", 2), rep(\"High\", 3)),                       duration = c(2, 10, 4, 4, 8),                       rate = c(5, 10, 0, 3, 6)) failRates <- tibble(Stratum = c(rep(\"Low\", 2), rep(\"High\", 2)),                     duration = 1,                     failRate = c(.1, .2, .3, .4),                     hr = c(.9, .75, .8, .6),                     dropoutRate = .001) AHR(enrollRates = enrollRates, failRates = failRates, totalDuration = c(15, 30)) ## # A tibble: 2 × 5 ##    Time   AHR Events  info info0 ##   <dbl> <dbl>  <dbl> <dbl> <dbl> ## 1    15 0.733   113.  28.1  28.3 ## 2    30 0.718   166.  41.3  41.5"},{"path":"https://merck.github.io/gsDesign2/articles/usage_AHR.html","id":"inner-logic-of-ahr","dir":"Articles","previous_headings":"","what":"Inner Logic of AHR()","title":"AHR: computes AHR under NPH assumptions and (stratified) populations","text":"Let’s take un-stratified population example, enrollment rate, failure rates dropout rates Step 1: compute proportion group compute expected events different treatment group, stratum time period, iterate totalDuration Strata. Since example, one analysis time (totalDuration = 30) one stratum (Stratum = \"\"), iterate . one multiple analysis time strata, one can use loop bind results row. Step 2: subset enrollment rates failure rates stratum. Step 3: calculate enrollment rates experimental arm control arm, respectively. Step 4: update failure rate control experimental arm. Step 5: calculate expected number events control experimental eEvents_df(). t column start period, failRate column failure rate period, Events column expected events period. Step 6: combine results together output . Please note , output, info column based following input. alternative hypothesis \\(H_1\\) \\[   \\text{hr}   =   \\left\\{   \\begin{array}{ll}     0.9  & \\text{first 1 month} \\\\     0.75 & \\text{afterwards},   \\end{array}   \\right. \\] info = info1, info1 statistical information \\(H_1\\). notice enrollRates failRates always \\(H_1\\), call info, rather info1.","code":"enrollRates <- tibble(Stratum = \"All\",                       duration = c(2, 10, 4),                       rate = c(5, 10, 0)) failRates <- tibble(Stratum = \"All\",                     duration = 1,                     failRate = c(.1, .2),                     hr = c(.9, .75),                     dropoutRate = .001)  ratio <- 2  totalDuration <- 30 Qe <- ratio / (1 + ratio) Qc <- 1 - Qe ## The proportion of the experimental arm is  0.6666667 ## The proportion of the control arm is  0.3333333 td <- totalDuration s <- \"All\" enroll <- enrollRates %>% filter(Stratum == s) fail <- failRates %>% filter(Stratum == s) enroll_c <- enroll %>% mutate(rate = rate * Qc) enroll_e <- enroll %>% mutate(rate = rate * Qe) fail_c <- fail fail_e <- fail %>% mutate(failRate = failRate * hr) events_c <- eEvents_df(enrollRates = enroll_c, failRates = fail_c, totalDuration = td, simple = FALSE) events_e <- eEvents_df(enrollRates = enroll_e, failRates = fail_e, totalDuration = td, simple = FALSE) ## The expected number of events in the control arm is ## # A tibble: 3 × 3 ##       t failRate Events ##   <dbl>    <dbl>  <dbl> ## 1     0      0.1   3.49 ## 2     1      0.2  30.6  ## 3     2      0.2   1.98 ## The expected number of events in the experimental arm is ## # A tibble: 3 × 3 ##       t failRate Events ##   <dbl>    <dbl>  <dbl> ## 1     0     0.09   6.31 ## 2     1     0.15  57.2  ## 3     2     0.15   6.86 # combine control and experimental events <- rbind(events_c %>% mutate(Treatment = \"Control\"),                 events_e %>% mutate(Treatment = \"Experimental\")) %>%           arrange(t, Treatment) %>%            ungroup() %>%            # recompute HR, events, info by period           group_by(t) %>%           summarize(Stratum = s,                      info = (sum(1 / Events))^(-1),                     Events = sum(Events),                      HR = last(failRate) / first(failRate)) %>%            # compute info0           mutate(Time = td,                   lnhr = log(HR),                   info0 = Events * Qc * Qe) %>%           ungroup() %>%                       group_by(Time, Stratum, HR) %>%           summarize(t = min(t),                      Events = sum(Events),                      info0 = sum(info0),                      info = sum(info)) %>%           # pool time period together           group_by(Time) %>%           summarize(AHR = exp(sum(log(HR) * Events) / sum(Events)),                     Events = sum(Events),                     info = sum(info),                     info0 = sum(info0)) ## The overall expected number of events over the time is ## # A tibble: 1 × 5 ##    Time   AHR Events  info info0 ##   <dbl> <dbl>  <dbl> <dbl> <dbl> ## 1    30 0.763   106.  23.7  23.6 enrollRates <- tibble(Stratum = \"All\",                       duration = c(2, 10, 4),                       rate = c(5, 10, 0)) failRates <- tibble(Stratum = \"All\",                     duration = 1,                     failRate = c(.1, .2),                     hr = c(.9, .75),                     dropoutRate = .001)"},{"path":[]},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_eAccural.html","id":"example-1","dir":"Articles","previous_headings":"Use cases of eAccrual()","what":"Example 1","title":"eAccrual: computes the expected cumulative enrollment (accrual) given a set of piecewise constant enrollment rates and times.","text":"enrollment first 3 months, exactly \\(3 \\times 5 = 15\\).","code":"eAccrual(x = 3,          enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20))) ## [1] 15"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eAccural.html","id":"example-2","dir":"Articles","previous_headings":"Use cases of eAccrual()","what":"Example 2","title":"eAccrual: computes the expected cumulative enrollment (accrual) given a set of piecewise constant enrollment rates and times.","text":"enrollment first 6 months, exactly \\(3 \\times 5 + 3 \\times 10 = 45\\).","code":"eAccrual(x = 6,           enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20))) ## [1] 45"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eAccural.html","id":"example-3","dir":"Articles","previous_headings":"Use cases of eAccrual()","what":"Example 3","title":"eAccrual: computes the expected cumulative enrollment (accrual) given a set of piecewise constant enrollment rates and times.","text":"enrollment first 24 months, exactly \\(3 \\times 5 + 3 \\times 10 + 18 * 20 = 405\\).","code":"eAccrual(x = 24,           enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20))) ## [1] 405"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eAccural.html","id":"example-4","dir":"Articles","previous_headings":"Use cases of eAccrual()","what":"Example 4","title":"eAccrual: computes the expected cumulative enrollment (accrual) given a set of piecewise constant enrollment rates and times.","text":"enrollment 24 months, 24 months, since enrollment stopped.","code":"eAccrual(x = 25,           enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20))) ## [1] 405"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eAccural.html","id":"example-5","dir":"Articles","previous_headings":"Use cases of eAccrual()","what":"Example 5","title":"eAccrual: computes the expected cumulative enrollment (accrual) given a set of piecewise constant enrollment rates and times.","text":"Instead compute enrolled subjects one time point one time point, can also compute .","code":"eAccrual(x = c(3, 6, 24, 25),           enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20))) ## [1]  15  45 405 405"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eAccural.html","id":"inner-logic-of-eaccrual","dir":"Articles","previous_headings":"","what":"Inner Logic of eAccrual()","title":"eAccrual: computes the expected cumulative enrollment (accrual) given a set of piecewise constant enrollment rates and times.","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_eEvents_df.html","id":"introduction-of-eevents_df","dir":"Articles","previous_headings":"","what":"Introduction of eEvents_df","title":"eEvents_df: compute expected number of events at 1 time point","text":"eEvents_df() computes expected number events given analysis time strata assumption piecewise model: piecewise constant enrollment rates piecewise exponential failure rates piecewise censoring rates. piecewise exponential distribution allows simple method specify distribution enrollment pattern enrollment, failure dropout rates changes time. df eEvents_df() short data frame, since output data frame.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_eEvents_df.html","id":"example-1-single-enroll-single-fail-period","dir":"Articles","previous_headings":"Use Cases","what":"Example 1: Single Enroll + Single Fail Period","title":"eEvents_df: compute expected number of events at 1 time point","text":"","code":"enrollRates <- tibble(duration = 10, rate = 10) failRates <- tibble(duration = 100, failRate = log(2) / 6, dropoutRate = .01) totalDuration <- 22  eEvents_df(enrollRates = enrollRates, failRates = failRates, totalDuration = totalDuration, simple = FALSE) ## # A tibble: 1 × 3 ##       t failRate Events ##   <dbl>    <dbl>  <dbl> ## 1     0    0.116   80.4"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eEvents_df.html","id":"example-2-multiple-enroll-single-fail-period","dir":"Articles","previous_headings":"Use Cases","what":"Example 2: Multiple Enroll + Single Fail Period","title":"eEvents_df: compute expected number of events at 1 time point","text":"","code":"enrollRates <- tibble(duration = c(5, 5), rate = c(10, 20)) failRates <- tibble(duration = 100, failRate = log(2)/6, dropoutRate = .01) totalDuration <- 22  eEvents_df(enrollRates = enrollRates, failRates = failRates, totalDuration = totalDuration, simple = FALSE) ## # A tibble: 1 × 3 ##       t failRate Events ##   <dbl>    <dbl>  <dbl> ## 1     0    0.116   119."},{"path":"https://merck.github.io/gsDesign2/articles/usage_eEvents_df.html","id":"example-3-signle-enroll-multiple-fail-period","dir":"Articles","previous_headings":"Use Cases","what":"Example 3: Signle Enroll + Multiple Fail Period","title":"eEvents_df: compute expected number of events at 1 time point","text":"","code":"enrollRates <- tibble(duration = 10, rate = 10) failRates <- tibble(duration = c(20, 80), failRate = c(log(2)/6, log(2)/4), dropoutRate = .01) totalDuration <- 22  eEvents_df(enrollRates = enrollRates, failRates = failRates, totalDuration = totalDuration, simple = FALSE) ## # A tibble: 2 × 3 ##       t failRate Events ##   <dbl>    <dbl>  <dbl> ## 1     0    0.116 80.2   ## 2    20    0.173  0.250"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eEvents_df.html","id":"example-4-multiple-duration","dir":"Articles","previous_headings":"Use Cases","what":"Example 4: Multiple Duration","title":"eEvents_df: compute expected number of events at 1 time point","text":"","code":"enrollRates <- tibble(duration = 10, rate = 10) failRates <- tibble(duration = 100, failRate = log(2) / 6, dropoutRate = .01) totalDuration <- c(2, 22)  try(eEvents_df(enrollRates = enrollRates, failRates = failRates, totalDuration = totalDuration, simple = FALSE)) ## Error in eEvents_df(enrollRates = enrollRates, failRates = failRates,  :  ##   gsDesign2: totalDuration in `events_df()` must be a numeric number!"},{"path":"https://merck.github.io/gsDesign2/articles/usage_eEvents_df.html","id":"inner-logic-of-eevents_df","dir":"Articles","previous_headings":"","what":"Inner Logic of eEvents_df()","title":"eEvents_df: compute expected number of events at 1 time point","text":"Step 1: set analysis time. Step 2: set enrollment rates.  Step 3: set failure rates dropout rates.   Given piecewise enrollment rates, failure rates, dropout rates, time line divided several parts: \\((0, 5]\\) (5 change point enrollment rates); \\((5, 10]\\) (10 another change point enrollment rates); \\((10, 20]\\) (20 change point failure rates); \\((20, 50]\\) (50 analysis time); \\((50, \\infty]\\) (analysis time).  Given sub-intervals, objective calculate expected number events sub-intervals. Step 4: divide time line enrollments Step 5: divide time line failure & dropout rates df_2, one needs discriminate analysis time (totalDuration = 50) beyond total failure rate duration. Step 6: divide time line considering change points enrollment, failure, dropout rates. find lots NA, can imputed piecewise model. Step 7: compute expected number events sub-intervals following technical details vignette ``computing expected events interval risk’’ Step 8: output results","code":"totalDuration <- 50 enrollRates <- tibble(duration = c(5, 5), rate = c(10, 20))  # create a step function (sf) to define enrollment rates over time sf.enrollRate <- stepfun(c(0, cumsum(enrollRates$duration)),                          c(0, enrollRates$rate, 0),                          right = FALSE)  plot(sf.enrollRate,       xlab = \"duration\", ylab = \"enrollment rates\",       main = \"Piecewise enrollment rate over time\", xlim = c(-0.01, 21)) failRates <- tibble(duration = c(20, 80), failRate = c(0.1, 0.2), dropoutRate = .01)  # get the time points where the failure rates change startFail <- c(0, cumsum(failRates$duration))  # plot the piecewise failure rates sf.failRate <- stepfun(startFail,                        c(0, failRates$failRate, last(failRates$failRate)),                        right = FALSE) plot(sf.failRate,       xlab = \"duration\", ylab = \"failure rates\",       main = \"Piecewise failure rate over time\", xlim = c(-0.01, 101)) # plot the piecewise dropout rate sf.dropoutRate <- stepfun(startFail,                           c(0, failRates$dropoutRate, last(failRates$dropoutRate)),                           right = FALSE) plot(sf.dropoutRate,       xlab = \"duration\", ylab = \"dropout rates\",       main = \"Piecewise dropout rate over time\", xlim = c(-0.01, 101)) df_1 <- tibble(startEnroll = c(0, cumsum(enrollRates$duration)),                endFail = totalDuration - startEnroll,                rate = c(enrollRates$rate, 0)) df_2 <- tibble(endFail = cumsum(failRates$duration),                startEnroll = totalDuration - endFail,                failRate = failRates$failRate,                dropoutRate = failRates$dropoutRate) # if the analysis time is after the total failure rate duration if(sum(failRates$duration) < totalDuration){   df_2 <- df_2[-nrow(df_2), ] }else{   df_2 <- df_2 %>% filter(startEnroll > 0) } df <- full_join(df_1, df_2, by = c(\"startEnroll\", \"endFail\")) %>% arrange(endFail) df <- df %>% mutate(endEnroll = lag(startEnroll, default = as.numeric(totalDuration)),                     startFail = lag(endFail, default = 0),                     duration = endEnroll - startEnroll,                     failRate = sf.failRate(startFail),                     dropoutRate = sf.dropoutRate(startFail),                     enrollRate = sf.enrollRate(startEnroll)) %>%               select(-rate) # create 2 auxiliary variable for failure & dropout rate              # q: number of expected events in a sub-interval              # Q: cumulative product of q (pool all sub-intervals) df <- df %>% mutate(q = exp(-duration * (failRate + dropoutRate)),                     Q = lag(cumprod(q), default = 1)) %>%              arrange(desc(startFail)) %>%              # create another 2 auxiliary variable for enroll rate              # g: number of expected subjects in a sub-interval              # G: cumulative sum of g (pool all sub-intervals)              mutate(g = enrollRate * duration,                     G = lag(cumsum(g), default = 0)) %>%              arrange(startFail) %>%              # compute expected events as nbar in a sub-interval              mutate(d = ifelse(failRate == 0, 0, Q * (1 - q) * failRate / (failRate + dropoutRate)),                     nbar = ifelse(failRate == 0, 0, G * d + (failRate * Q * enrollRate) / (failRate + dropoutRate) * (duration - (1 - q) / (failRate + dropoutRate)))) sf.startFail <- stepfun(startFail, c(0, startFail), right = FALSE) df <- df %>%    transmute(t = endFail, failRate = failRate, Events = nbar, startFail = sf.startFail(startFail)) %>%    group_by(startFail) %>%   summarize(failRate = first(failRate), Events = sum(Events)) %>%   mutate(t = startFail) %>%    select(\"t\", \"failRate\", \"Events\")  df %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"parameters","dir":"Articles","previous_headings":"","what":"Parameters","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"# Enrollment rate enrollRates <- tibble::tibble(    Stratum = \"All\",     duration = 18,     rate = 20)  # Failure rates failRates <- tibble::tibble(    Stratum = \"All\",     duration = c(4, 100),     failRate = log(2) / 12,    hr = c(1, .6),     dropoutRate = .001)  # Study duration in months studyDuration <- 36  # Experimental / Control randomization ratio ratio <- 1   # 1-sided Type I error alpha <- 0.025  # Type II error (1 - power) beta <- 0.1"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power","dir":"Articles","previous_headings":"AHR","what":"under fixed power","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x <- fixed_design(x = \"AHR\",               alpha = alpha, power = 1 - beta,               enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio)   x %>% summary() ## # A tibble: 1 × 7 ##   Design                   N Events  Time Bound alpha Power ##   <chr>                <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 Average hazard ratio  463.   325.    36  1.96 0.025   0.9 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size","dir":"Articles","previous_headings":"AHR","what":"under fixed sample size","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"AHR\",               alpha = alpha,                enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio) %>%    summary() %>%    as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-default-rhogamma","dir":"Articles","previous_headings":"FH","what":"under fixed power (default rho/gamma)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"# fixed design with a given power with default rho/gamma x <- fixed_design(x = \"FH\",               alpha = alpha, power = 1 - beta,               enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio)  x %>% summary() ## # A tibble: 1 × 7 ##   Design                            N Events  Time Bound alpha Power ##   <chr>                         <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 Fleming-Harrington FH(0, 0.5)  356.   249.    36  1.96 0.025   0.9 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-custom-rhogamma","dir":"Articles","previous_headings":"FH","what":"under fixed power (custom rho/gamma)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"# fixed design with a given power with input rho/gamma fixed_design(x = \"FH\",               alpha = alpha, power = 1 - beta,               enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio,              rho = 0.5, gamma = 0.5) %>%    summary() %>%     as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-default-rhogamma","dir":"Articles","previous_headings":"FH","what":"under fixed sample size (default rho/gamma)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"# fixed design with power calculated fixed_design(x = \"FH\",               alpha = alpha,                enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio) %>%    summary() %>%     as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-custom-rhogamma","dir":"Articles","previous_headings":"FH","what":"under fixed sample size (custom rho/gamma)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"# fixed design with power calculated fixed_design(x = \"FH\",               alpha = alpha,                enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio,              rho = 0.5, gamma = 0.5) %>%    summary() %>%     as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-default-tau","dir":"Articles","previous_headings":"MB","what":"under fixed power (default tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x <- fixed_design(x = \"MB\",               ratio = ratio,               alpha = alpha, power = 1 - beta,              enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration)  x %>% summary() ## # A tibble: 1 × 7 ##   Design                            N Events  Time Bound alpha Power ##   <chr>                         <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 Modestly weighted LR: tau = 6  412.   289.    36  1.96 0.025   0.9 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-custom-tau","dir":"Articles","previous_headings":"MB","what":"under fixed power (custom tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"MB\",               ratio = ratio,               alpha = alpha, power = 1 - beta,              enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration,              tau = 4) %>%    summary() %>%     as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-default-tau","dir":"Articles","previous_headings":"MB","what":"under fixed sample size (default tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"MB\",              ratio = ratio,              alpha = alpha,              enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration) %>%    summary() %>%     as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-custom-tau","dir":"Articles","previous_headings":"MB","what":"under fixed sample size (custom tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"MB\",              ratio = ratio,              alpha = alpha,              enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration,              tau = 4) %>%    summary() %>%     as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-1","dir":"Articles","previous_headings":"LF","what":"under fixed power","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"LF\", alpha = alpha, power = 1 - beta,               ratio = ratio,              enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration) %>%    summary() %>%     as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-sample-size","dir":"Articles","previous_headings":"LF","what":"under sample size","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"LF\", alpha = alpha,                ratio = ratio,               enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration) %>%    summary() %>%     as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-default-rhogammatau","dir":"Articles","previous_headings":"MaxCombo","what":"under fixed power (default rho/gamma/tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x <- fixed_design(x = \"MaxCombo\", alpha = alpha, power = 1 - beta,              ratio = ratio,               enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration) ## The AHR reported in the `analysis` table is under the log-rank test. x %>% summary() ## # A tibble: 1 × 7 ##   Design                            N Events  Time Bound alpha Power ##   <chr>                         <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 MaxCombo: logrank, FH(0, 0.5)  359.   252.    36  1.96 0.025 0.900 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-custom-rhogammatau","dir":"Articles","previous_headings":"MaxCombo","what":"under fixed power (custom rho/gamma/tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"MaxCombo\", alpha = alpha, power = 1 - beta,              ratio = ratio,               enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration,              rho = c(0, 0.5, 0.5),              gamma = c(0, 0, 0.5),              tau = c(-1, 4, 6)) %>%    summary() %>%    as_gt() ## The AHR reported in the `analysis` table is under the log-rank test."},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-sample-size-default-rhogammatau","dir":"Articles","previous_headings":"MaxCombo","what":"under sample size (default rho/gamma/tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"MaxCombo\", alpha = alpha,               ratio = ratio,               enrollRates = enrollRates,              failRates = failRates,              studyDuration = studyDuration) %>%    summary() %>%    as_gt() ## The AHR reported in the `analysis` table is under the log-rank test."},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-sample-size-custom-rhogammatau","dir":"Articles","previous_headings":"MaxCombo","what":"under sample size (custom rho/gamma/tau)","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"MaxCombo\", alpha = alpha,               ratio = ratio,               enrollRates = enrollRates,              failRates = failRates,               studyDuration = studyDuration,              rho = c(0, 0.5, 0.5),              gamma = c(0, 0, 0.5),              tau = c(-1, 4, 6)) %>%    summary() %>%    as_gt() ## The AHR reported in the `analysis` table is under the log-rank test."},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-2","dir":"Articles","previous_headings":"RMST","what":"under fixed power","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x <- fixed_design(x = \"RMST\",                    alpha = alpha, power = 1 - beta,                    enrollRates = enrollRates, failRates = failRates,                    studyDuration = studyDuration, ratio = ratio,                   tau = 18)   x %>% summary() ## # A tibble: 1 × 7 ##   Design             N Events  Time Bound alpha Power ##   <chr>          <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 RMST: tau = 18 1298.   910.    36  1.96 0.025   0.9 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-1","dir":"Articles","previous_headings":"RMST","what":"under fixed sample size","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"RMST\",               alpha = alpha,                enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio,              tau = 18) %>%    summary() %>%    as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-3","dir":"Articles","previous_headings":"Milestone","what":"under fixed power","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x <- fixed_design(x = \"Milestone\",                    alpha = alpha, power = 1 - beta,                    enrollRates = enrollRates, failRates = failRates,                    studyDuration = studyDuration, ratio = ratio,                   tau = 18)   x %>% summary() ## # A tibble: 1 × 7 ##   Design                  N Events  Time Bound alpha Power ##   <chr>               <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1 Milestone: tau = 18  557.   390.    36  1.96 0.025   0.9 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-2","dir":"Articles","previous_headings":"Milestone","what":"under fixed sample size","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"Milestone\",               alpha = alpha,                enrollRates = enrollRates, failRates = failRates,               studyDuration = studyDuration, ratio = ratio,              tau = 18) %>%    summary() %>%    as_gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-power-4","dir":"Articles","previous_headings":"RD","what":"under fixed power","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x <- fixed_design(x = \"RD\",                    alpha = alpha, power = 1 - beta,                    p_c = .15, p_e = .1, rd0 = 0,                   ratio = ratio)   x %>% summary() ## # A tibble: 1 × 5 ##   Design              N Bound alpha Power ##   <chr>           <dbl> <dbl> <dbl> <dbl> ## 1 Risk difference 1835.  1.96 0.025   0.9 x %>% summary() %>% as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"under-fixed-sample-size-3","dir":"Articles","previous_headings":"RD","what":"under fixed sample size","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"fixed_design(x = \"RD\",               alpha = alpha, power = NULL,               p_c = .15, p_e = .1, rd0 = 0,              N = 2000, ratio = ratio) %>%    summary() %>%    as_gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_fixed_design.html","id":"multiple-designs","dir":"Articles","previous_headings":"","what":"Multiple Designs","title":"fixed_design: compute sample size/power of a fixed design","text":"","code":"x_AHR <- fixed_design(x = \"AHR\", alpha = alpha, ratio = ratio,                       enrollRates = enrollRates, failRates = failRates,                        studyDuration = studyDuration)  x_FH <- fixed_design(x = \"FH\", alpha = alpha, ratio = ratio,                       enrollRates = enrollRates, failRates = failRates, studyDuration = studyDuration,                      rho = 0.5, gamma = 0.5)   x_MB <- fixed_design(x = \"MB\", alpha = alpha, ratio = ratio,                       enrollRates = enrollRates,failRates = failRates, studyDuration = studyDuration,                       tau = 4)  x_LF <- fixed_design(x = \"LF\", alpha = alpha, ratio = ratio,                       enrollRates = enrollRates, failRates = failRates, studyDuration = studyDuration)  x_MaxCombo <- fixed_design(x = \"MaxCombo\", alpha = alpha, ratio = ratio,                             enrollRates = enrollRates, failRates = failRates, studyDuration = studyDuration,                            rho = c(0, 0.5, 0.5), gamma = c(0, 0, 0.5), tau = c(-1, 4, 6))  x_RMST <- fixed_design(x = \"RMST\", alpha = alpha, ratio = ratio,                         enrollRates = enrollRates, failRates = failRates, studyDuration = studyDuration,                        tau = 30)  x_Milestone <- fixed_design(x = \"Milestone\", alpha = alpha, ratio = ratio,                         enrollRates = enrollRates, failRates = failRates, studyDuration = studyDuration,                        tau = 30)  rbind(summary(x_AHR), summary(x_FH), summary(x_MB), summary(x_LF), summary(x_MaxCombo), summary(x_RMST), summary(x_Milestone)) %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_b.html","id":"introduction-of-gs_b","dir":"Articles","previous_headings":"","what":"Introduction of gs_b()","title":"gs_b: specify fixed boundaries in group sequential designs","text":"gs_b() can used derive fixed boundary fixed/group sequential design. usually used upper = ... lower = ... arguments + gs_power_npe() + gs_design_npe() + gs_power_ahr() + gs_design_ahr() + gs_power_wlr() + gs_design_wlr() + gs_power_combo() + gs_design_combo()","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_b.html","id":"example-1","dir":"Articles","previous_headings":"Usage of gs_b()","what":"Example 1","title":"gs_b: specify fixed boundaries in group sequential designs","text":"Assume group sequential design 3 analysis, one can input upper bound vector c(4, 3, 2) using gs_b() follows.","code":"gs_b(par = 4:2) ## [1] 4 3 2"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_b.html","id":"example-2","dir":"Articles","previous_headings":"Usage of gs_b()","what":"Example 2","title":"gs_b: specify fixed boundaries in group sequential designs","text":"example, one can assign upper bound second analysis ","code":"gs_b(par = 4:2, k = 2) ## [1] 3"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_b.html","id":"example-3","dir":"Articles","previous_headings":"Usage of gs_b()","what":"Example 3","title":"gs_b: specify fixed boundaries in group sequential designs","text":"Generate efficacy bound using spending function. Use Lan-DeMets spending approximation O’Brien-Fleming bound 50%, 75% 100% final spending","code":"# information fraction IF <- c(.5, .75, 1) # Lan-DeMets spending approximation of O'Brien-Fleming par <- gsDesign::gsDesign(alpha = .025, k = length(IF),                            test.type = 1, sfu = gsDesign::sfLDOF,                            timing = IF)$upper$bound gs_b(par = par) ## [1] 2.962588 2.359018 2.014084"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_b.html","id":"inner-logic-of-gs_b","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_b()","title":"gs_b: specify fixed boundaries in group sequential designs","text":"gs_b short function 2 key arguments: par = ... k = ...","code":"if(is.null(k)){   return(par) }else{    return(par[k]) }"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_ahr.html","id":"introduction-of-gs_design_ahr","dir":"Articles","previous_headings":"","what":"Introduction of gs_design_ahr()","title":"gs_design_ahr: compute sample size by the AHR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_ahr.html","id":"usage-of-gs_design_ahr","dir":"Articles","previous_headings":"","what":"Usage of gs_design_ahr()","title":"gs_design_ahr: compute sample size by the AHR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_ahr.html","id":"inner-logic-of-gs_design_ahr","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_design_ahr()","title":"gs_design_ahr: compute sample size by the AHR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_combo.html","id":"introduction-of-gs_design_combo","dir":"Articles","previous_headings":"","what":"Introduction of gs_design_combo()","title":"gs_design_combo: compute sample size by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_combo.html","id":"usage-of-gs_design_combo","dir":"Articles","previous_headings":"","what":"Usage of gs_design_combo()","title":"gs_design_combo: compute sample size by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_combo.html","id":"inner-logic-of-gs_design_combo","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_design_combo()","title":"gs_design_combo: compute sample size by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_wlr.html","id":"introduction-of-gs_design_wlr","dir":"Articles","previous_headings":"","what":"Introduction of gs_design_wlr()","title":"gs_design_wlr: compute sample size by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_wlr.html","id":"usage-of-gs_design_wlr","dir":"Articles","previous_headings":"","what":"Usage of gs_design_wlr()","title":"gs_design_wlr: compute sample size by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_design_wlr.html","id":"inner-logic-of-gs_design_wlr","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_design_wlr()","title":"gs_design_wlr: compute sample size by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"introduction-of-gs_info_ahr","dir":"Articles","previous_headings":"","what":"Introduction of gs_info_ahr()","title":"gs_info_ahr: compute statistical information by the AHR method","text":"tEvents() calculate analysis time (Time output), number events (Events output), average hazard ratio (AHR outputs), effect size (theta output), statistical information (info info0 output) using average hazard ratio model. aforementioned calculation based piecewise model: + piecewise constant enrollment rates + piecewise exponential failure rates + piecewise censoring rates.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"example-1","dir":"Articles","previous_headings":"Use Cases","what":"Example 1","title":"gs_info_ahr: compute statistical information by the AHR method","text":"example, input target number events events = ..., derive time events arrived.","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1  gs_info_ahr(enrollRates = enrollRates, failRates = failRates,             ratio = ratio, events = c(50, 80, 100)) ## # A tibble: 3 × 7 ##   Analysis  Time Events   AHR theta  info info0 ##      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1        1  8.29   50.0 0.850 0.163  12.4  12.5 ## 2        2 10.5    80.0 0.825 0.193  19.7  20.0 ## 3        3 11.9   100.  0.812 0.208  24.6  25.0"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"example-2","dir":"Articles","previous_headings":"Use Cases","what":"Example 2","title":"gs_info_ahr: compute statistical information by the AHR method","text":"example, input analysis time analysisTimes = ..., derive number events analysis time.","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1  gs_info_ahr(enrollRates = enrollRates, failRates = failRates,             ratio = ratio, analysisTimes = c(10, 15, 20)) ## # A tibble: 3 × 7 ##   Analysis  Time Events   AHR theta  info info0 ##      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1        1    10   72.4 0.831 0.186  17.9  18.1 ## 2        2    15  151.  0.786 0.241  37.2  37.8 ## 3        3    20  208.  0.738 0.304  51.0  52.1"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"example-3","dir":"Articles","previous_headings":"Use Cases","what":"Example 3","title":"gs_info_ahr: compute statistical information by the AHR method","text":"example, input analysisTimes = ... events = .... case, one see + derived analysis time (Time column) \\(\\geq\\) input analysisTimes + derived number event (Events column) \\(\\geq\\) input events","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1  gs_info_ahr(enrollRates = enrollRates, failRates = failRates,             ratio = ratio, analysisTimes = c(10, 15, 20), events = c(80,  # > events in example 2                                                                       140, # < > events in example 2                                                                       220  # > events in example 2                                                                       )) ## # A tibble: 3 × 7 ##   Analysis  Time Events   AHR theta  info info0 ##      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1        1  10.5   80.0 0.825 0.193  19.7  20.0 ## 2        2  15    151.  0.786 0.241  37.2  37.8 ## 3        3  21.2  220.  0.730 0.315  53.8  55.0"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"inner-logic-of-gs_info_ahr","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_info_ahr()","title":"gs_info_ahr: compute statistical information by the AHR method","text":"explain inner logic gs_info_ahr(), discuss 3 scenario. input analysisTimes input events input analysisTimes events","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"scenario-1-only-input-analysistimes","dir":"Articles","previous_headings":"Inner Logic of gs_info_ahr()","what":"Scenario 1: only input analysisTimes","title":"gs_info_ahr: compute statistical information by the AHR method","text":"analysisTimes = ... input, essentially, gs_info_ahr() uses AHR() calculate number events analysisTimes. exactly output gs_info_ahr():","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1 analysisTimes <- c(10, 15, 20)  AHR(enrollRates = enrollRates, failRates = failRates,      ratio = ratio, totalDuration = analysisTimes) %>%    mutate(theta = -log(AHR), Analysis = 1 : length(analysisTimes)) %>%    select(Analysis, Time, Events, AHR, theta, info, info0) %>%    gt() gs_info_ahr(enrollRates = enrollRates, failRates = failRates,              ratio = ratio, analysisTimes = analysisTimes) %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"scenario-2-only-input-events","dir":"Articles","previous_headings":"Inner Logic of gs_info_ahr()","what":"Scenario 2: only input events","title":"gs_info_ahr: compute statistical information by the AHR method","text":"events = ... input, essentially, gs_info_ahr() uses tEvents() calculate time events arrived. exactly output gs_info_ahr():","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1 events <- c(70, 150, 200)  ans <- NULL for(i in seq_along(events)){   ans_new <- gsDesign2::tEvents(enrollRates = enrollRates, failRates = failRates,                                  ratio = ratio, targetEvents = events[i])   ans <- rbind(ans, ans_new) }  ans %>%    mutate(theta = -log(AHR), Analysis = 1 : length(analysisTimes)) %>%    select(Analysis, Time, Events, AHR, theta, info, info0) %>%    gt() gs_info_ahr(enrollRates = enrollRates, failRates = failRates,              ratio = ratio, events = events) %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_ahr.html","id":"scenario-3-both-input-analysistimes-and-events","dir":"Articles","previous_headings":"Inner Logic of gs_info_ahr()","what":"Scenario 3: both input analysisTimes and events","title":"gs_info_ahr: compute statistical information by the AHR method","text":"analysisTimes = ... events = ... input, gs_info_ahr() uses AHR() tEvents(). way, guaranteed + derived number event (Events column) \\(\\geq\\) input events + derived analysis time (Time column) \\(\\geq\\) input analysisTimes exactly output gs_info_ahr():","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1 analysisTimes <- c(10, 15, 20) events <- c(70, 150, 200)  ans <- NULL  # first, use `AHR()` to calculate the number of events at the input `analysisTimes` ans <- AHR(enrollRates = enrollRates, failRates = failRates,             ratio = ratio, totalDuration = analysisTimes)  # second, compare if the events derived above meet the targeted number of events input in `events` for(i in seq_along(events)){   if (ans$Events[i] < events[i]){     ans[i,] <- tEvents(enrollRates = enrollRates, failRates = failRates,                         ratio = ratio, targetEvents = events[i])   } }  ans %>%    mutate(theta = -log(AHR), Analysis = 1 : length(analysisTimes)) %>%    select(Analysis, Time, Events, AHR, theta, info, info0) %>%    gt() gs_info_ahr(enrollRates = enrollRates, failRates = failRates,              ratio = ratio, events = events, analysisTimes = analysisTimes) %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_combo.html","id":"introduction-of-gs_info_combo","dir":"Articles","previous_headings":"","what":"Introduction of gs_info_combo()","title":"gs_info_combo: compute statistical information by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_combo.html","id":"usage-of-gs_info_combo","dir":"Articles","previous_headings":"","what":"Usage of gs_info_combo()","title":"gs_info_combo: compute statistical information by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_combo.html","id":"inner-logic-of-gs_info_combo","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_info_combo()","title":"gs_info_combo: compute statistical information by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_wlr.html","id":"introduction-of-gs_info_wlr","dir":"Articles","previous_headings":"","what":"Introduction of gs_info_wlr()","title":"gs_info_wlr: compute statistical information by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_wlr.html","id":"usage-of-gs_info_wlr","dir":"Articles","previous_headings":"","what":"Usage of gs_info_wlr()","title":"gs_info_wlr: compute statistical information by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_info_wlr.html","id":"inner-logic-of-gs_info_wlr","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_info_wlr()","title":"gs_info_wlr: compute statistical information by the WLR method","text":"TODO","code":""},{"path":[]},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_ahr.html","id":"example-1","dir":"Articles","previous_headings":"Use cases of gs_power_ahr()","what":"Example 1","title":"gs_power_ahr: computes power using average hazard ratio under non-proportional hazards","text":"","code":"x <- gs_power_ahr(enrollRates = tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)),                   failRates = tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18),                                       hr = c(.9, .6), dropoutRate = rep(.001, 2)),                   analysisTimes = c(12, 24, 36), events = NULL,                   binding = TRUE,                   upper = gs_spending_bound,                   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),                   lower = gs_spending_bound,                   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)) x ## $enrollRates ## # A tibble: 3 × 3 ##   Stratum duration  rate ##   <chr>      <dbl> <dbl> ## 1 All            2     3 ## 2 All            2     6 ## 3 All           10     9 ##  ## $failRates ## # A tibble: 2 × 5 ##   Stratum duration failRate    hr dropoutRate ##   <chr>      <dbl>    <dbl> <dbl>       <dbl> ## 1 All            3   0.0770   0.9       0.001 ## 2 All          100   0.0385   0.6       0.001 ##  ## $bounds ## # A tibble: 6 × 7 ##   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` ##      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> ## 1        1 Upper   0.000370     0.0000538  3.87           0.178   0.0000538 ## 2        1 Lower   0.0000612    0.0000538 -3.40           4.55    1.00      ## 3        2 Upper   0.116        0.00921    2.36           0.506   0.00919   ## 4        2 Lower   0.00907      0.00921   -1.20           1.42    0.885     ## 5        3 Upper   0.324        0.0250     2.01           0.608   0.0222    ## 6        3 Lower   0.0250       0.0250    -0.473          1.12    0.682     ##  ## $analysis ## # A tibble: 3 × 10 ##   Analysis  Time     N Events   AHR theta  info info0    IF   IF0 ##      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> ## 1        1    12    90   20.4 0.811 0.210  5.03  5.10 0.309 0.308 ## 2        2    24   108   49.1 0.715 0.335 12.0  12.3  0.738 0.741 ## 3        3    36   108   66.2 0.683 0.381 16.3  16.6  1     1     ##  ## attr(,\"class\") ## [1] \"ahr\"       \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_ahr.html","id":"inner-logic-of-gs_power_ahr","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_power_ahr()","title":"gs_power_ahr: computes power using average hazard ratio under non-proportional hazards","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_combo.html","id":"introduction-of-gs_power_combo","dir":"Articles","previous_headings":"","what":"Introduction of gs_power_combo()","title":"gs_power_combo: compute power by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_combo.html","id":"usage-of-gs_power_combo","dir":"Articles","previous_headings":"","what":"Usage of gs_power_combo()","title":"gs_power_combo: compute power by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_combo.html","id":"inner-logic-of-gs_power_combo","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_power_combo()","title":"gs_power_combo: compute power by the max combo method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"introduction-of-gs_power_npe","dir":"Articles","previous_headings":"","what":"Introduction of gs_power_npe()","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"gs_power_npe() derives group sequential bounds boundary crossing probabilities design. allows non-constant treatment effect time, also can applied usual homogeneous effect size designs. requires + treatment effect (theta, theta1) + statistical information analysis (info, info0, info1) + method deriving bounds, fixed bounds spending (upper, upar, lower, lpar). routine enables two things available gsDesign package: non-constant effect, flexibility boundary selection.","code":""},{"path":[]},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"no-futility-bound","dir":"Articles","previous_headings":"Usage of gs_power_npe() > Example 1: Fixed bound","what":"no futility bound","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"","code":"# Same fixed efficacy bounds,  (i.e., non-binding bound), null hypothesis gs_power_npe(   theta = rep(0, 3),   info = (1:3) * 40,   upar = gsDesign::gsDesign(k = 3,sfu = gsDesign::sfLDOF)$upper$bound,   lpar = rep(-Inf, 3)) %>%   filter(Bound == \"Upper\") %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"with-futility-bound","dir":"Articles","previous_headings":"Usage of gs_power_npe() > Example 1: Fixed bound","what":"with futility bound","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"","code":"# Fixed bound gs_power_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   upper = gs_b,   upar = gsDesign::gsDesign(k = 3,sfu = gsDesign::sfLDOF)$upper$bound,   lower = gs_b,   lpar = c(-1, 0, 0)) %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"futility-only-at-analysis-1","dir":"Articles","previous_headings":"Usage of gs_power_npe() > Example 1: Fixed bound","what":"futility only at analysis 1","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"","code":"gs_power_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   upper = gs_b,   upar = c(Inf, 3, 2),   lower = gs_b,   lpar = c(qnorm(.1), -Inf, -Inf)) %>% gt()"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"lower-spending-based-on-non-zero-effect","dir":"Articles","previous_headings":"Usage of gs_power_npe() > Example 2: spending bounds","what":"lower spending based on non-zero effect","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"","code":"gs_power_npe(   theta = c(.1, .2, .3), # non-zero effect   info = (1:3) * 40,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfHSD, total_spend = 0.1, param = -1, timing = NULL)) ## # A tibble: 6 × 10 ##   Analysis Bound       Z Probability theta theta1    IF  info info0 info1 ##      <int> <chr>   <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> ## 1        1 Upper  3.71       0.00104   0.1    0.1 0.333    40    40    40 ## 2        2 Upper  2.51       0.235     0.2    0.2 0.667    80    80    80 ## 3        3 Upper  1.99       0.883     0.3    0.3 1       120   120   120 ## 4        1 Lower -1.36       0.0230    0.1    0.1 0.333    40    40    40 ## 5        2 Lower  0.0726     0.0552    0.2    0.2 0.667    80    80    80 ## 6        3 Lower  1.86       0.100     0.3    0.3 1       120   120   120"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"sided-symmetric-spend","dir":"Articles","previous_headings":"Usage of gs_power_npe() > Example 2: spending bounds","what":"2-sided symmetric spend","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"","code":"x <- gs_power_npe(   theta = rep(0, 3),   info = (1:3) * 40,   # typically, 2-sided bounds are binding   binding = TRUE,   upper = gs_spending_bound,   # O'Brien-Fleming spending   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL))  x %>% gt() # Re-use these bounds under alternate hypothesis # Always use binding = TRUE for power calculations gs_power_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   binding = TRUE,   upar = (x %>% filter(Bound == \"Upper\"))$Z,   lpar = -(x %>% filter(Bound == \"Upper\"))$Z) %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_npe.html","id":"inner-logic-of-gs_spending_bound","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_spending_bound()","title":"gs_power_npe: derives bounds and crossing probabilities for group sequential designs under NPH assumptions","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_wlr.html","id":"introduction-of-gs_power_wlr","dir":"Articles","previous_headings":"","what":"Introduction of gs_power_wlr()","title":"gs_power_wlr: compute power by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_wlr.html","id":"usage-of-gs_power_wlr","dir":"Articles","previous_headings":"","what":"Usage of gs_power_wlr()","title":"gs_power_wlr: compute power by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_power_wlr.html","id":"inner-logic-of-gs_power_wlr","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_power_wlr()","title":"gs_power_wlr: compute power by the WLR method","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_spending_bound.html","id":"introduction-of-gs_spending_bound","dir":"Articles","previous_headings":"","what":"Introduction of gs_spending_bound()","title":"gs_spending_bound: compute spending boundary in group sequential design","text":"gs_spending_bound() can used derive spending boundary group sequential design. usually used upper = ... lower = ... arguments + gs_power_npe() + gs_design_npe() + gs_power_ahr() + gs_design_ahr() + gs_power_wlr() + gs_design_wlr() + gs_power_combo() + gs_design_combo()","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_spending_bound.html","id":"example-1","dir":"Articles","previous_headings":"Usage of gs_spending_bound()","what":"Example 1","title":"gs_spending_bound: compute spending boundary in group sequential design","text":"","code":"info <- (1:3) * 10 IF <- info / max(info) k <- length(IF)  # 1st analysis a1 <- gs_spending_bound(k = 1, efficacy = FALSE, theta = 0,                         par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, timing = IF, param = NULL),                          hgm1 = NULL)  b1 <- gs_spending_bound(k = 1, efficacy = TRUE, theta = 0,                         par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, timing = IF, param = NULL),                          hgm1 = NULL) cat(\"The (lower, upper) boundary at the 1st analysis is (\", a1, \", \", b1, \").\\n\") ## The (lower, upper) boundary at the 1st analysis is ( -3.710303 ,  3.710303 ). # 2st analysis a2 <- gs_spending_bound(k = 2, efficacy = FALSE, theta = 0,                         par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, timing = IF, param = NULL),                          hgm1 = h1(r = 18, theta = 0,  I = info[1],  a = a1, b = b1))  b2 <- gs_spending_bound(k = 2, efficacy = TRUE, theta = 0,                         par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, timing = IF, param = NULL),                          hgm1 = h1(r = 18, theta = 0,  I = info[1],  a = a1, b = b1)) cat(\"The upper boundary at the 2nd analysis is (\", a2, \", \", b2, \").\\n\") ## The upper boundary at the 2nd analysis is ( -2.511434 ,  2.511434 ). # 3nd analysis # a3 <- gs_spending_bound(k = 2, efficacy = FALSE, theta = 0, #                         par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, timing = IF, param = NULL),  #                         hgm1 = hupdate(r = 18, theta = 0,  I = info[2],  a = a2, b = b2,  #                                        thetam1 = 0,  Im1 = info[2],   #                                        gm1 = h1(r = 18, theta = 1,  I = info[1],  a = a1, b = b1))) #  # b3 <- gs_spending_bound(k = 2, efficacy = TRUE, theta = 0, #                         par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, timing = IF, param = NULL),  #                         hgm1 = hupdate(r = 18, theta = 0,  I = info[2],  a = a2, b = b2,  #                                        thetam1 = 0,  Im1 = info[2],   #                                        gm1 = h1(r = 18, theta = 0,  I = info[1],  a = a1, b = b1))) # cat(\"The upper boundary at the 2nd analysis is (\", a3, \", \", b3, \").\\n\")"},{"path":"https://merck.github.io/gsDesign2/articles/usage_gs_spending_bound.html","id":"inner-logic-of-gs_spending_bound","dir":"Articles","previous_headings":"","what":"Inner Logic of gs_spending_bound()","title":"gs_spending_bound: compute spending boundary in group sequential design","text":"TODO","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"summary & as_gt: summarize group sequential design","text":"vignette introduces publication quality table production group sequential designs gsDesign2 package. also demonstrates designs example scenario using multiple design approaches. divide document 3 parts: Design specification derivation Printing design summary tables Details output design functions Details table output options reader can decide sections interest . function used generate bounds tables gsDesign2::summary(). Users can use gsDesign2::as_gt() format table using gt package. vignette, introduce general approach bound summaries examples using different design approaches time--event outcome: average hazard ratio (AHR) method extended Mukhopadhyay et al. (2020) using gsDesign2::gs_design_ahr(); weighted logrank (WLR) method Yung (2019) using gsDesign2::gs_design_wlr();","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"design-parameters","dir":"Articles","previous_headings":"Design Specification and Derivation","what":"Design Parameters","title":"summary & as_gt: summarize group sequential design","text":"design parameters use across different designs derived :","code":"# enrollment/failure rates enrollRates <- tibble::tibble(    Stratum = \"All\",     duration = 12,     rate = 1) failRates <- tibble::tibble(    Stratum = \"All\",     duration = c(4, 100),     failRate = log(2) / 12,    hr = c(1, .6),     dropoutRate = .001)  # Information fraction IF <- (1:3)/3  # Analysis times in months; first 2 will be ignored as IF will not be achieved analysisTimes <- c(.01, .02, 36)    # Experimental / Control randomization ratio ratio <- 1   # 1-sided Type I error alpha <- 0.025  # Type II error (1 - power) beta <- 0.1   # Upper bound upper <- gsDesign2::gs_spending_bound     # alpha-spending bound upar <- list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)             # Lower bound lower <- gsDesign2::gs_spending_bound    # beta-spending bound lpar <- list(sf = gsDesign::sfHSD, total_spend = 0.1, param = 0, timing = NULL)  # Fleming-Harrington (FH) weight functions for weighted logrank (WLR) wgt00 <- function(x, arm0, arm1){    # Equal weighting for logrank    gsDesign2:::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)} wgt05 <- function(x, arm0, arm1){    # Early downweighting with FH(0,.5)     gsDesign2:::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = .5)}  # Both of above tests for MaxCombo: logrank and FH(0,.5) fh_test <- rbind(    # Include logrank for all 3 analyses    data.frame(rho = 0, gamma = 0, tau = -1, test = 1, Analysis = 1:3, analysisTimes = c(12, 24, 36)),     # Only include FH(0,.5) for analyses 2 and 3    data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1, test = 2:3, Analysis = 3, analysisTimes = 36))"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"ahr-design-derivation","dir":"Articles","previous_headings":"Design Specification and Derivation > Deriving Designs","what":"AHR Design Derivation","title":"summary & as_gt: summarize group sequential design","text":"Using design parameters , AHR design derived follows: using design parameters , one can generate AHR model gs_design_ahr ","code":"x_design_ahr <- gs_design_ahr(    enrollRates = enrollRates,    failRates = failRates,    IF = IF,     analysisTimes = analysisTimes,     ratio = ratio,     alpha = alpha,     beta = beta,     upper = upper,    upar = upar,    lower = lower,    lpar = lpar )  x_power_ahr <- gs_power_ahr(    enrollRates = x_design_ahr$enrollRates,    failRates = x_design_ahr$failRates,    events = c(100, 200, 400),    analysisTimes = NULL,    upper = upper,    upar = upar,    lower = lower,    lpar = lpar )"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"wlr-design-derivation","dir":"Articles","previous_headings":"Design Specification and Derivation > Deriving Designs","what":"WLR Design Derivation","title":"summary & as_gt: summarize group sequential design","text":"","code":"x_design_wlr <- gs_design_wlr(    enrollRates = enrollRates,    failRates = failRates,    weight = wgt05,     IF = NULL,     analysisTimes = sort(unique(x_design_ahr$analysis$Time)),     ratio = ratio,     alpha = alpha,     beta = beta,       upper = upper,    upar = upar,    lower = lower,    lpar = lpar )  # x_power_wlr <- gs_power_wlr( #    enrollRates = x_design_wlr$enrollRates, #    failRates = x_design_wlr$failRates, #    weight = wgt05,  #    events = c(100, 150, 250), #    analysisTimes = NULL,  #    upper = upper, #    upar = upar, #    lower = lower, #    lpar = lpar # )"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"default-summary-table-production","dir":"Articles","previous_headings":"","what":"Default Summary Table Production","title":"summary & as_gt: summarize group sequential design","text":"Instead outputting 4 detailed tables (table enrollment rates, table failure rates, table analysis summary, table bounds summary), users can get com pensive summary table calling summary(x), x object returned either gs_design_ahr gs_design_wlr. summary() function produces overall summary table bounds publication protocol. example, default output summary() AHR method Please note summary() can also applied objected returned gs_power_ahr(). example, default output summary() WLR method Note summary() can also applied summarize object returned gs_power_wlr().","code":"x_design_ahr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4) x_power_ahr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4) x_design_wlr %>%    summary() %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4) summary(x_power_wlr) %>%     gt::gt() %>%     gt::fmt_number(columns = c(3:6), decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"detailed-summary-table-formatting","dir":"Articles","previous_headings":"","what":"Detailed Summary Table Formatting","title":"summary & as_gt: summarize group sequential design","text":"demonstrate options formatting analysis rows, bound rows well table parameters titles, labels footnotes.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"custom-the-variables-to-be-summaried-for-each-analysis","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom the Variables to be Summaried for Each Analysis","title":"summary & as_gt: summarize group sequential design","text":"default table summary table generated summary(x), variables used summarize analysis includes Analysis, Time, N(sample size), Events, AHR, (information fraction). users can customize variables chosen using analysis_vars = ... corresponding decimals displayed using argument analysis_decimals = .... example Please note need input \"Analysis\" analysis_vars = ... always appear.","code":"x_design_ahr %>%    summary(analysis_vars = c(\"N\", \"Events\"),           analysis_decimals = c(1, 1)) %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"custom-the-bound-names","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom the Bound Names","title":"summary & as_gt: summarize group sequential design","text":"Users can also customize bound names. default output generated summary(x), bound name c(\"Efficacy\", \"Futility\"), can changed c(\"better\", \"B better\") 2-sided design using argument bound_names = .... example,","code":"x_design_ahr %>%    summary(bound_names = c(\"A is better\", \"B is better\")) %>%    mutate_if(is.numeric, round, digits = 4) %>%    gt::gt() %>%    gt::fmt_number(columns = c(3:6), decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"custom-into-a-gt-table-and-add-titlesubtitlefootnotesspanners","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom into a gt Table and Add Title/SubTitle/Footnotes/Spanners","title":"summary & as_gt: summarize group sequential design","text":"Users can also use as_gt() get R table gt table. Furthermore, can edit title/subtitle/spanner/footnotes gt table using arguments summary. objective can also realized using functions R package gt custom design table layout. note as_gt() always produces gt object , thus, can customized gt package formatting functions. future, support rich text format using function as_rtf() fashion similar as_gt().","code":"summary(x_design_ahr) %>%     as_gt(title = \"Summary of the Crossing Probability\",          subtitle = \"by Using gs_design_ahr\",          colname_spanner = \"Cumulative boundary crossing probability\",          colname_spannersub = c(\"Alternate hypothesis\", \"Null hypothesis\"),          footnote = list(content = c(\"approximate hazard ratio to cross bound.\",                                       \"gs_design_ahr is a function in gsDesign2.\",                                      \"AHR is average hazard ratio; IF is information fraction.\"),                          location = c(\"~HR at bound\", NA, NA),                          attr = c(\"colname\", \"subtitle\", \"analysis\")))"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"custom-the-variables-to-display","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom the Variables to Display","title":"summary & as_gt: summarize group sequential design","text":"Users can select variables displayed summary table using argument display_colunm = ....","code":"x_design_ahr %>%    summary() %>%    as_gt(display_columns = c(\"Analysis\", \"Bound\", \"Z\", \"Probability\"))"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"custom-whether-to-show-infinity-bound-or-not","dir":"Articles","previous_headings":"Detailed Summary Table Formatting","what":"Custom Whether to Show Infinity Bound or Not","title":"summary & as_gt: summarize group sequential design","text":"Users options either show infinity bounds taking advantage display_inf_bound = ....","code":"x_design_ahr %>%    summary() %>%    as_gt(display_inf_bound = FALSE)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"details-of-output-from-designpower-functions","dir":"Articles","previous_headings":"","what":"Details of Output from Design/Power Functions","title":"summary & as_gt: summarize group sequential design","text":"four components objects returned either gs_design_ahr()/gs_design_wlr() gs_power_ahr()/gs_power_wlr(): 1. failure rates: table summarizing failure rate dropout rate. 1. enrollment rates: table summarizing enrollment rate. 1. bounds: table summarize bound analysis. 1. analysis: table summarize analysis, one row one analysis one hypothsis.","code":""},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"failure-rates","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Failure Rates","title":"summary & as_gt: summarize group sequential design","text":"failure rates different gsDesign object can obtained using x$failRates, x object returned either gs_design_ahr gs_design_wlr. example, failure rates AHR design derivation can returned calling Please note x_design_ahr x_wlr returns failure rates, inputted failRates. verify, let’s take look failure rate WLR design derivation, shown .","code":"x_design_ahr$failRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3:5, decimals = 4) x_design_wlr$failRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3:5, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"enrollment","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Enrollment","title":"summary & as_gt: summarize group sequential design","text":"enrollment rate gs design derivation can collected using x$failRates, x object returned either gs_design_ahr gs_design_wlr. example, enrollment rates AHR/WLR design derivation can seen , although design derivation different, enrollment rate table share table structure, enrollment period durations rate. Yet, enrollment rates differ designs multiplicative constant.","code":"x_design_ahr$enrollRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3, decimals = 4) x_design_wlr$enrollRates %>%     gt::gt() %>%     gt::fmt_number(columns = 3, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"analysis","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Analysis","title":"summary & as_gt: summarize group sequential design","text":"analysis summary table structure one row per analysis per hypothesis. columns can vary different defaults design option. type tables useful understanding commonalities designs summarized different models. get analysis summary table, users can call x$analysis, x object returned either gs_design_ahr gs_design_wlr. example, analysis summary AHR/WLR design derivation ","code":"x_design_ahr$analysis %>%     gt::gt() %>%     gt::fmt_number(columns = 2:8, decimals = 4) x_design_wlr$analysis %>%     gt::gt() %>%     gt::fmt_number(columns = 2:8, decimals = 4)"},{"path":"https://merck.github.io/gsDesign2/articles/usage_summary_as_gt.html","id":"bounds","dir":"Articles","previous_headings":"Details of Output from Design/Power Functions","what":"Bounds","title":"summary & as_gt: summarize group sequential design","text":"analysis summary table structure One row per analysis per bound per hypothesis. Columns can vary different defaults design option. get bouns summary table, users can call x$analysis, x object returned either gs_design_ahr gs_design_wlr. example, bounds summary AHR/WLR design derivation ","code":"x_design_ahr$bounds %>%     gt::gt() %>%     gt::fmt_number(columns = c(3, 5:7), decimals = 4) x_design_wlr$bounds %>%     gt::gt() %>%     gt::fmt_number(columns = c(3, 5:7), decimals = 4)"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_tEvents.html","id":"introduction-of-tevents","dir":"Articles","previous_headings":"","what":"Introduction of tEvents","title":"tEvents: compute time when a targeted number of events is made","text":"tEvents() predicts time targeted events made. designed twins AHR(): matches input/output format AHR().","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/articles/usage_tEvents.html","id":"example-1","dir":"Articles","previous_headings":"Use Cases","what":"Example 1:","title":"tEvents: compute time when a targeted number of events is made","text":"","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1  x <- tEvents(enrollRates = enrollRates, failRates = failRates,              ratio = ratio, targetEvents = 200)  x %>% gt()"},{"path":"https://merck.github.io/gsDesign2/articles/usage_tEvents.html","id":"example-2","dir":"Articles","previous_headings":"Use Cases","what":"Example 2:","title":"tEvents: compute time when a targeted number of events is made","text":"example, verify tEvents() AHR().","code":"enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1  x <- AHR(enrollRates = enrollRates, failRates = failRates,           ratio = ratio, totalDuration = 20) cat(\"The number of events by 20 months is \", x$Events, \".\\n\") ## The number of events by 20 months is  208.3641 . y <- tEvents(enrollRates = enrollRates, failRates = failRates,              ratio = ratio, targetEvents = x$Events)  cat(\"The time to get \", x$Events, \" is \", y$Time, \"months.\\n\") ## The time to get  208.3641  is  20 months."},{"path":"https://merck.github.io/gsDesign2/articles/usage_tEvents.html","id":"inner-logic-of-tevents","dir":"Articles","previous_headings":"","what":"Inner Logic of tEvents()","title":"tEvents: compute time when a targeted number of events is made","text":"inner logic tEvents() uniroot AHR() totalDuration. Step 1: find difference AHR() different values totalDuration. Step 2: uniroot AHR() totalDuration.","code":"foo <- function(x){   ans <- AHR(enrollRates = enrollRates, failRates = failRates,               totalDuration = x, ratio = ratio)$Events - targetEvents   return(ans) } enrollRates <- tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18), hr = c(.9, .6), dropoutRate = rep(.001, 2)) ratio <- 1 targetEvents <- 200  cat(\"The difference between `targetEvents = 200` and the events after 30 months is \", foo(30), \".\\n\") ## The difference between `targetEvents = 200` and the events after 30 months is  92.45484 . res <- uniroot(foo, interval = c(0.01, 100))  ans <- AHR(enrollRates = enrollRates, failRates = failRates,             totalDuration = res$root, ratio = ratio) cat(\"After \", ans$Time, \" months, there will be \", targetEvents, \" events .\\n\") ## After  19.16437  months, there will be  200  events ."},{"path":"https://merck.github.io/gsDesign2/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Keaven Anderson. Author. Yilong Zhang. Author. Yujie Zhao. Author, maintainer. Jianxiao Yang. Contributor. Nan Xiao. Contributor. Amin Shirazi. Contributor. Ruixue Wang. Contributor. Yi Cui. Contributor. Ping Yang. Contributor. Xin Tong Li. Contributor. Yalin Zhu. Contributor. Merck & Co., Inc., Rahway, NJ, USA affiliates. Copyright holder.","code":""},{"path":"https://merck.github.io/gsDesign2/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Anderson K, Zhang Y, Zhao Y (2022). gsDesign2: Group Sequential Design Non-Constant Effect. https://merck.github.io/gsDesign2/, https://github.com/Merck/gsDesign2.","code":"@Manual{,   title = {gsDesign2: Group Sequential Design with Non-Constant Effect},   author = {Keaven Anderson and Yilong Zhang and Yujie Zhao},   year = {2022},   note = {https://merck.github.io/gsDesign2/, https://github.com/Merck/gsDesign2}, }"},{"path":"https://merck.github.io/gsDesign2/index.html","id":"objective","dir":"","previous_headings":"","what":"Objective","title":"Group Sequential Design with Non-Constant Effect","text":"goal gsDesign2 enable fixed group sequential design non-proportional hazards. Piecewise constant enrollment, failure rates dropout rates stratified population available enable highly flexible enrollment, time--event time--dropout assumptions. Substantial flexibility top gsDesign package intended selecting boundaries. work progress, substantial capabilities enabled. Comments usability features encouraged development version package. goal gsDesign2 enable group sequential trial design time--event endpoints non-proportional hazards assumptions. package still maturing; package functions become stable, likely included gsDesign2 package.","code":""},{"path":"https://merck.github.io/gsDesign2/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Group Sequential Design with Non-Constant Effect","text":"can install gsDesign2 :","code":"remotes::install_github(\"Merck/gsDesign2\")"},{"path":[]},{"path":"https://merck.github.io/gsDesign2/index.html","id":"step-1-specifying-enrollment-and-failure-rates","dir":"","previous_headings":"Use cases","what":"Step 1: specifying enrollment and failure rates","title":"Group Sequential Design with Non-Constant Effect","text":"basic example shows solve common problem. assume 4 month delay treatment effect. Specifically, assume hazard ratio 1 4 months 0.6 thereafter. example assume exponential failure rate low exponential dropout rate. enrollRates specification indicates expected enrollment duration 12 months exponential inter-arrival times. resulting failure rate specification following table. many rows strata needed can specified approximate whatever patterns wish.","code":"library(gsDesign) library(gsDesign2) library(dplyr) library(gt)  # Basic example  # Constant enrollment over 12 months # Rate will be adjusted later by gsDesignNPH to get sample size enrollRates <- tibble::tibble(Stratum = \"All\", duration = 12, rate = 1)  # 12 month median exponential failure rate in control # 4 month delay in effect with HR=0.6 after # Low exponential dropout rate medianSurv <- 12 failRates <- tibble::tibble(   Stratum = \"All\",   duration = c(4, Inf),   failRate = log(2) / medianSurv,   hr = c(1, .6),   dropoutRate = .001 ) failRates %>%   gt() %>%   as_raw_html(inline_css = FALSE)"},{"path":"https://merck.github.io/gsDesign2/index.html","id":"step-2-compute-the-design","dir":"","previous_headings":"Use cases","what":"Step 2: compute the design","title":"Group Sequential Design with Non-Constant Effect","text":"Computing fixed sample size design 2.5% one-sided Type error 90% power. specify trial duration 36 months analysisTimes. Since single analysis, specify upper p-value bound 0.025 upar = qnorm(0.975). lower bound specified lpar = -Inf. input enrollment rates scaled achieve power: failure dropout rates remain unchanged input: Additionally, summary bounds crossing probability available Finally, expected analysis time Time, sample size N, events required Events average hazard ratio AHR x$analysis. Note AHR average hazard ratio used calculate targeted event counts. natural parameter (log(AHR)) theta corresponding statistical information alternate hypothesis info null hypothesis info0.","code":"x <- gs_design_ahr(   enrollRates, failRates,   upper = gs_b, upar = qnorm(.975),   lower = gs_b, lpar = -Inf,   IF = 1, analysisTimes = 36 ) x$enrollRates %>%   gt() %>%   as_raw_html(inline_css = FALSE) x$failRates %>%   gt() %>%   as_raw_html(inline_css = FALSE) x$bounds %>%   gt() %>%   as_raw_html(inline_css = FALSE) x$analysis %>%   gt() %>%   as_raw_html(inline_css = FALSE)"},{"path":"https://merck.github.io/gsDesign2/index.html","id":"step-3-summarize-the-design","dir":"","previous_headings":"Use cases","what":"Step 3: summarize the design","title":"Group Sequential Design with Non-Constant Effect","text":"","code":"x %>%   summary() %>%   as_gt() %>%   as_raw_html(inline_css = FALSE)"},{"path":"https://merck.github.io/gsDesign2/reference/AHR.html","id":null,"dir":"Reference","previous_headings":"","what":"Average hazard ratio under non-proportional hazards (test version) — AHR","title":"Average hazard ratio under non-proportional hazards (test version) — AHR","text":"AHR() provides geometric average hazard ratio various non-proportional hazards assumptions either single multiple strata studies. piecewise exponential distribution allows simple method specify distribution enrollment pattern enrollment, failure dropout rates changes time.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/AHR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Average hazard ratio under non-proportional hazards (test version) — AHR","text":"","code":"AHR(   enrollRates = tibble::tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6,     9)),   failRates = tibble::tibble(Stratum = \"All\", duration = c(3, 100), failRate =     log(2)/c(9, 18), hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   totalDuration = 30,   ratio = 1,   simple = TRUE )"},{"path":"https://merck.github.io/gsDesign2/reference/AHR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Average hazard ratio under non-proportional hazards (test version) — AHR","text":"enrollRates Piecewise constant enrollment rates stratum time period. failRates Piecewise constant control group failure rates, duration piecewise constant period, hazard ratio experimental vs control, dropout rates stratum time period. totalDuration Total follow-start enrollment data cutoff; can single value vector positive numbers. ratio ratio experimental control randomization. simple logical; TRUE (default), value input totalDuration overall event count, statistical information average hazard ratio given; FALSE, hazard ratio, expected events statistical information produced stratum underlying hazard ratio.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/AHR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Average hazard ratio under non-proportional hazards (test version) — AHR","text":"tibble Time (totalDuration), AHR (average hazard ratio), Events (expected number events), info (information given scenarios), info0 (information related null hypothesis) value totalDuration input; simple=FALSE, Stratum t (beginning constant HR period) also returned HR returned instead AHR","code":""},{"path":"https://merck.github.io/gsDesign2/reference/AHR.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Average hazard ratio under non-proportional hazards (test version) — AHR","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/AHR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Average hazard ratio under non-proportional hazards (test version) — AHR","text":"","code":"# Example: default AHR() #> # A tibble: 1 × 5 #>    Time   AHR Events  info info0 #>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1    30 0.695   58.5  14.3  14.6  # Example: default with multiple analysis times (varying totalDuration)  AHR(totalDuration = c(15, 30)) #> # A tibble: 2 × 5 #>    Time   AHR Events  info info0 #>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1    15 0.786   30.3  7.44  7.57 #> 2    30 0.695   58.5 14.3  14.6   # Stratified population enrollRates <- tibble::tibble(Stratum = c(rep(\"Low\", 2), rep(\"High\", 3)),                               duration = c(2, 10, 4, 4, 8),                               rate = c(5, 10, 0, 3, 6)) failRates <- tibble::tibble(Stratum = c(rep(\"Low\", 2), rep(\"High\", 2)),                             duration = 1,                             failRate = c(.1, .2, .3, .4),                             hr = c(.9, .75, .8, .6),                             dropoutRate = .001) AHR(enrollRates = enrollRates, failRates = failRates, totalDuration = c(15, 30)) #> # A tibble: 2 × 5 #>    Time   AHR Events  info info0 #>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1    15 0.733   113.  28.1  28.3 #> 2    30 0.718   166.  41.3  41.5  # Same example, give results by strata and time period AHR(enrollRates = enrollRates, failRates = failRates, totalDuration = c(15, 30), simple = FALSE) #> # A tibble: 8 × 7 #>    Time Stratum     t    HR Events  info info0 #>   <dbl> <chr>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1    15 High        0  0.8   12.1   2.99  3.02 #> 2    15 High        1  0.6   23.1   5.72  5.78 #> 3    15 Low         0  0.9    9.96  2.48  2.49 #> 4    15 Low         1  0.75  68.1  16.9  17.0  #> 5    30 High        0  0.8   14.2   3.51  3.54 #> 6    30 High        1  0.6   45.2  11.2  11.3  #> 7    30 Low         0  0.9    9.96  2.48  2.49 #> 8    30 Low         1  0.75  96.8  24.1  24.2"},{"path":"https://merck.github.io/gsDesign2/reference/ahr_blinded.html","id":null,"dir":"Reference","previous_headings":"","what":"Blinded estimation of average hazard ratio — ahr_blinded","title":"Blinded estimation of average hazard ratio — ahr_blinded","text":"Based blinded data assumed hazard ratios different intervals, compute blinded estimate average hazard ratio (AHR) corresponding estimate statistical information. function intended use computing futility bounds based spending assuming input hazard ratio (hr) values intervals specified .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ahr_blinded.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Blinded estimation of average hazard ratio — ahr_blinded","text":"","code":"ahr_blinded(   Srv = Surv(time = simtrial::Ex1delayedEffect$month, event =     simtrial::Ex1delayedEffect$evntd),   intervals = array(3, 3),   hr = c(1, 0.6),   ratio = 1 )"},{"path":"https://merck.github.io/gsDesign2/reference/ahr_blinded.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Blinded estimation of average hazard ratio — ahr_blinded","text":"Srv input survival object (see Surv); note 0=censored, 1=event Surv intervals Vector containing positive values indicating interval lengths exponential rates assumed. Note final infinite interval added events occur final interval specified. hr vector hazard ratios assumed interval ratio ratio experimental control randomization.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ahr_blinded.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Blinded estimation of average hazard ratio — ahr_blinded","text":"tibble one row containing AHR blinded average hazard ratio based assumed period-specific hazard ratios input failRates observed events corresponding intervals Events total observed number events, info statistical information based Schoenfeld approximation, info0 (information related null hypothesis) value totalDuration input; simple=FALSE, Stratum t (beginning constant HR period) also returned HR returned instead AHR","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ahr_blinded.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Blinded estimation of average hazard ratio — ahr_blinded","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ahr_blinded.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Blinded estimation of average hazard ratio — ahr_blinded","text":"","code":"if (FALSE) { library(simtrial) library(survival) ahr_blinded(Srv = Surv(time = simtrial::Ex2delayedEffect$month,                        event = simtrial::Ex2delayedEffect$evntd),             intervals = c(4, 100),             hr = c(1, .55),             ratio = 1) }"},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.fixed_design.html","id":null,"dir":"Reference","previous_headings":"","what":"This is the function to format the bounds summary table of fixed design into gt style. — as_gt.fixed_design","title":"This is the function to format the bounds summary table of fixed design into gt style. — as_gt.fixed_design","text":"function format bounds summary table fixed design gt style.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.fixed_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This is the function to format the bounds summary table of fixed design into gt style. — as_gt.fixed_design","text":"","code":"# S3 method for fixed_design as_gt(x, title = NULL, footnote = NULL, ...)"},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.fixed_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This is the function to format the bounds summary table of fixed design into gt style. — as_gt.fixed_design","text":"x summary object group sequential design title title displayed footnote footnotes displayed ... additional arguments","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.fixed_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This is the function to format the bounds summary table of fixed design into gt style. — as_gt.fixed_design","text":"gt table","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.fixed_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This is the function to format the bounds summary table of fixed design into gt style. — as_gt.fixed_design","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union library(tibble)  # Enrollment rate enrollRates <- tibble(   Stratum = \"All\",    duration = 18,    rate = 20)  # Failure rates failRates <- tibble(   Stratum = \"All\",    duration = c(4, 100),    failRate = log(2) / 12,   hr = c(1, .6),    dropoutRate = .001)  # Study duration in months studyDuration <- 36  # Experimental / Control randomization ratio ratio <- 1   # 1-sided Type I error alpha <- 0.025   # Type II error (1 - power) beta <- 0.1   # ------------------------- # #        AHR                # # ------------------------- # # under fixed power  fixed_design(   x = \"AHR\",    alpha = alpha, power = 1 - beta,    enrollRates = enrollRates, failRates = failRates,    studyDuration = studyDuration, ratio = ratio   ) %>%    summary() %>%    as_gt() #> <div id=\"esorwsleeu\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"> #>   <style>html { #>   font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; #> } #>  #> #esorwsleeu .gt_table { #>   display: table; #>   border-collapse: collapse; #>   margin-left: auto; #>   margin-right: auto; #>   color: #333333; #>   font-size: 16px; #>   font-weight: normal; #>   font-style: normal; #>   background-color: #FFFFFF; #>   width: auto; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #A8A8A8; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #A8A8A8; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_heading { #>   background-color: #FFFFFF; #>   text-align: center; #>   border-bottom-color: #FFFFFF; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_title { #>   color: #333333; #>   font-size: 125%; #>   font-weight: initial; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-color: #FFFFFF; #>   border-bottom-width: 0; #> } #>  #> #esorwsleeu .gt_subtitle { #>   color: #333333; #>   font-size: 85%; #>   font-weight: initial; #>   padding-top: 0; #>   padding-bottom: 6px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-color: #FFFFFF; #>   border-top-width: 0; #> } #>  #> #esorwsleeu .gt_bottom_border { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_col_headings { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_col_heading { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 6px; #>   padding-left: 5px; #>   padding-right: 5px; #>   overflow-x: hidden; #> } #>  #> #esorwsleeu .gt_column_spanner_outer { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   padding-top: 0; #>   padding-bottom: 0; #>   padding-left: 4px; #>   padding-right: 4px; #> } #>  #> #esorwsleeu .gt_column_spanner_outer:first-child { #>   padding-left: 0; #> } #>  #> #esorwsleeu .gt_column_spanner_outer:last-child { #>   padding-right: 0; #> } #>  #> #esorwsleeu .gt_column_spanner { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 5px; #>   overflow-x: hidden; #>   display: inline-block; #>   width: 100%; #> } #>  #> #esorwsleeu .gt_group_heading { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #> } #>  #> #esorwsleeu .gt_empty_group_heading { #>   padding: 0.5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: middle; #> } #>  #> #esorwsleeu .gt_from_md > :first-child { #>   margin-top: 0; #> } #>  #> #esorwsleeu .gt_from_md > :last-child { #>   margin-bottom: 0; #> } #>  #> #esorwsleeu .gt_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   margin: 10px; #>   border-top-style: solid; #>   border-top-width: 1px; #>   border-top-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #>   overflow-x: hidden; #> } #>  #> #esorwsleeu .gt_stub { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #esorwsleeu .gt_stub_row_group { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #>   vertical-align: top; #> } #>  #> #esorwsleeu .gt_row_group_first td { #>   border-top-width: 2px; #> } #>  #> #esorwsleeu .gt_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #esorwsleeu .gt_first_summary_row { #>   border-top-style: solid; #>   border-top-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_first_summary_row.thick { #>   border-top-width: 2px; #> } #>  #> #esorwsleeu .gt_last_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_grand_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #esorwsleeu .gt_first_grand_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-style: double; #>   border-top-width: 6px; #>   border-top-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_striped { #>   background-color: rgba(128, 128, 128, 0.05); #> } #>  #> #esorwsleeu .gt_table_body { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_footnotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_footnote { #>   margin: 0px; #>   font-size: 90%; #>   padding-left: 4px; #>   padding-right: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #esorwsleeu .gt_sourcenotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #esorwsleeu .gt_sourcenote { #>   font-size: 90%; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #esorwsleeu .gt_left { #>   text-align: left; #> } #>  #> #esorwsleeu .gt_center { #>   text-align: center; #> } #>  #> #esorwsleeu .gt_right { #>   text-align: right; #>   font-variant-numeric: tabular-nums; #> } #>  #> #esorwsleeu .gt_font_normal { #>   font-weight: normal; #> } #>  #> #esorwsleeu .gt_font_bold { #>   font-weight: bold; #> } #>  #> #esorwsleeu .gt_font_italic { #>   font-style: italic; #> } #>  #> #esorwsleeu .gt_super { #>   font-size: 65%; #> } #>  #> #esorwsleeu .gt_footnote_marks { #>   font-style: italic; #>   font-weight: normal; #>   font-size: 75%; #>   vertical-align: 0.4em; #> } #>  #> #esorwsleeu .gt_asterisk { #>   font-size: 100%; #>   vertical-align: 0; #> } #>  #> #esorwsleeu .gt_indent_1 { #>   text-indent: 5px; #> } #>  #> #esorwsleeu .gt_indent_2 { #>   text-indent: 10px; #> } #>  #> #esorwsleeu .gt_indent_3 { #>   text-indent: 15px; #> } #>  #> #esorwsleeu .gt_indent_4 { #>   text-indent: 20px; #> } #>  #> #esorwsleeu .gt_indent_5 { #>   text-indent: 25px; #> } #> <\/style> #>   <table class=\"gt_table\"> #>   <thead class=\"gt_header\"> #>     <tr> #>       <td colspan=\"7\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Fixed Design under AHR Method<sup class=\"gt_footnote_marks\">1<\/sup><\/td> #>     <\/tr> #>      #>   <\/thead> #>   <thead class=\"gt_col_headings\"> #>     <tr> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Design<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">N<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Events<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Time<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Bound<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">alpha<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Power<\/th> #>     <\/tr> #>   <\/thead> #>   <tbody class=\"gt_table_body\"> #>     <tr><td class=\"gt_row gt_left\">AHR<\/td> #> <td class=\"gt_row gt_right\">463.078<\/td> #> <td class=\"gt_row gt_right\">324.7077<\/td> #> <td class=\"gt_row gt_right\">36<\/td> #> <td class=\"gt_row gt_right\">1.959964<\/td> #> <td class=\"gt_row gt_right\">0.025<\/td> #> <td class=\"gt_row gt_right\">0.9<\/td><\/tr> #>   <\/tbody> #>    #>   <tfoot class=\"gt_footnotes\"> #>     <tr> #>       <td class=\"gt_footnote\" colspan=\"7\"><sup class=\"gt_footnote_marks\">1<\/sup> Power computed with average hazard ratio method.<\/td> #>     <\/tr> #>   <\/tfoot> #> <\/table> #> <\/div>    # ------------------------- # #        FH                 # # ------------------------- # # under fixed power fixed_design(   x = \"FH\",    alpha = alpha, power = 1 - beta,    enrollRates = enrollRates, failRates = failRates,    studyDuration = studyDuration, ratio = ratio   ) %>%    summary() %>%    as_gt() #> <div id=\"ryttrfjein\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\"> #>   <style>html { #>   font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; #> } #>  #> #ryttrfjein .gt_table { #>   display: table; #>   border-collapse: collapse; #>   margin-left: auto; #>   margin-right: auto; #>   color: #333333; #>   font-size: 16px; #>   font-weight: normal; #>   font-style: normal; #>   background-color: #FFFFFF; #>   width: auto; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #A8A8A8; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #A8A8A8; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_heading { #>   background-color: #FFFFFF; #>   text-align: center; #>   border-bottom-color: #FFFFFF; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_title { #>   color: #333333; #>   font-size: 125%; #>   font-weight: initial; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-color: #FFFFFF; #>   border-bottom-width: 0; #> } #>  #> #ryttrfjein .gt_subtitle { #>   color: #333333; #>   font-size: 85%; #>   font-weight: initial; #>   padding-top: 0; #>   padding-bottom: 6px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-color: #FFFFFF; #>   border-top-width: 0; #> } #>  #> #ryttrfjein .gt_bottom_border { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_col_headings { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_col_heading { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 6px; #>   padding-left: 5px; #>   padding-right: 5px; #>   overflow-x: hidden; #> } #>  #> #ryttrfjein .gt_column_spanner_outer { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: normal; #>   text-transform: inherit; #>   padding-top: 0; #>   padding-bottom: 0; #>   padding-left: 4px; #>   padding-right: 4px; #> } #>  #> #ryttrfjein .gt_column_spanner_outer:first-child { #>   padding-left: 0; #> } #>  #> #ryttrfjein .gt_column_spanner_outer:last-child { #>   padding-right: 0; #> } #>  #> #ryttrfjein .gt_column_spanner { #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: bottom; #>   padding-top: 5px; #>   padding-bottom: 5px; #>   overflow-x: hidden; #>   display: inline-block; #>   width: 100%; #> } #>  #> #ryttrfjein .gt_group_heading { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #> } #>  #> #ryttrfjein .gt_empty_group_heading { #>   padding: 0.5px; #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   vertical-align: middle; #> } #>  #> #ryttrfjein .gt_from_md > :first-child { #>   margin-top: 0; #> } #>  #> #ryttrfjein .gt_from_md > :last-child { #>   margin-bottom: 0; #> } #>  #> #ryttrfjein .gt_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   margin: 10px; #>   border-top-style: solid; #>   border-top-width: 1px; #>   border-top-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 1px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 1px; #>   border-right-color: #D3D3D3; #>   vertical-align: middle; #>   overflow-x: hidden; #> } #>  #> #ryttrfjein .gt_stub { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #ryttrfjein .gt_stub_row_group { #>   color: #333333; #>   background-color: #FFFFFF; #>   font-size: 100%; #>   font-weight: initial; #>   text-transform: inherit; #>   border-right-style: solid; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #>   padding-left: 5px; #>   padding-right: 5px; #>   vertical-align: top; #> } #>  #> #ryttrfjein .gt_row_group_first td { #>   border-top-width: 2px; #> } #>  #> #ryttrfjein .gt_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #ryttrfjein .gt_first_summary_row { #>   border-top-style: solid; #>   border-top-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_first_summary_row.thick { #>   border-top-width: 2px; #> } #>  #> #ryttrfjein .gt_last_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_grand_summary_row { #>   color: #333333; #>   background-color: #FFFFFF; #>   text-transform: inherit; #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #ryttrfjein .gt_first_grand_summary_row { #>   padding-top: 8px; #>   padding-bottom: 8px; #>   padding-left: 5px; #>   padding-right: 5px; #>   border-top-style: double; #>   border-top-width: 6px; #>   border-top-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_striped { #>   background-color: rgba(128, 128, 128, 0.05); #> } #>  #> #ryttrfjein .gt_table_body { #>   border-top-style: solid; #>   border-top-width: 2px; #>   border-top-color: #D3D3D3; #>   border-bottom-style: solid; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_footnotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_footnote { #>   margin: 0px; #>   font-size: 90%; #>   padding-left: 4px; #>   padding-right: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #ryttrfjein .gt_sourcenotes { #>   color: #333333; #>   background-color: #FFFFFF; #>   border-bottom-style: none; #>   border-bottom-width: 2px; #>   border-bottom-color: #D3D3D3; #>   border-left-style: none; #>   border-left-width: 2px; #>   border-left-color: #D3D3D3; #>   border-right-style: none; #>   border-right-width: 2px; #>   border-right-color: #D3D3D3; #> } #>  #> #ryttrfjein .gt_sourcenote { #>   font-size: 90%; #>   padding-top: 4px; #>   padding-bottom: 4px; #>   padding-left: 5px; #>   padding-right: 5px; #> } #>  #> #ryttrfjein .gt_left { #>   text-align: left; #> } #>  #> #ryttrfjein .gt_center { #>   text-align: center; #> } #>  #> #ryttrfjein .gt_right { #>   text-align: right; #>   font-variant-numeric: tabular-nums; #> } #>  #> #ryttrfjein .gt_font_normal { #>   font-weight: normal; #> } #>  #> #ryttrfjein .gt_font_bold { #>   font-weight: bold; #> } #>  #> #ryttrfjein .gt_font_italic { #>   font-style: italic; #> } #>  #> #ryttrfjein .gt_super { #>   font-size: 65%; #> } #>  #> #ryttrfjein .gt_footnote_marks { #>   font-style: italic; #>   font-weight: normal; #>   font-size: 75%; #>   vertical-align: 0.4em; #> } #>  #> #ryttrfjein .gt_asterisk { #>   font-size: 100%; #>   vertical-align: 0; #> } #>  #> #ryttrfjein .gt_indent_1 { #>   text-indent: 5px; #> } #>  #> #ryttrfjein .gt_indent_2 { #>   text-indent: 10px; #> } #>  #> #ryttrfjein .gt_indent_3 { #>   text-indent: 15px; #> } #>  #> #ryttrfjein .gt_indent_4 { #>   text-indent: 20px; #> } #>  #> #ryttrfjein .gt_indent_5 { #>   text-indent: 25px; #> } #> <\/style> #>   <table class=\"gt_table\"> #>   <thead class=\"gt_header\"> #>     <tr> #>       <td colspan=\"7\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Fixed Design under Fleming-Harrington Method<sup class=\"gt_footnote_marks\">1<\/sup><\/td> #>     <\/tr> #>      #>   <\/thead> #>   <thead class=\"gt_col_headings\"> #>     <tr> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Design<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">N<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Events<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Time<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Bound<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">alpha<\/th> #>       <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Power<\/th> #>     <\/tr> #>   <\/thead> #>   <tbody class=\"gt_table_body\"> #>     <tr><td class=\"gt_row gt_left\">FH<\/td> #> <td class=\"gt_row gt_right\">355.5725<\/td> #> <td class=\"gt_row gt_right\">249.3255<\/td> #> <td class=\"gt_row gt_right\">36<\/td> #> <td class=\"gt_row gt_right\">1.959964<\/td> #> <td class=\"gt_row gt_right\">0.025<\/td> #> <td class=\"gt_row gt_right\">0.9<\/td><\/tr> #>   <\/tbody> #>    #>   <tfoot class=\"gt_footnotes\"> #>     <tr> #>       <td class=\"gt_footnote\" colspan=\"7\"><sup class=\"gt_footnote_marks\">1<\/sup> Power for Fleming-Harrington test  FH(0, 0.5) using method of Yung and Liu.<\/td> #>     <\/tr> #>   <\/tfoot> #> <\/table> #> <\/div>"},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.gs_design.html","id":null,"dir":"Reference","previous_headings":"","what":"This is the function to format the bounds summary table into gt style. — as_gt.gs_design","title":"This is the function to format the bounds summary table into gt style. — as_gt.gs_design","text":"function format bounds summary table gt style.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.gs_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"This is the function to format the bounds summary table into gt style. — as_gt.gs_design","text":"","code":"# S3 method for gs_design as_gt(   x,   title = NULL,   subtitle = NULL,   colname_spanner = \"Cumulative boundary crossing probability\",   colname_spannersub = c(\"Alternate hypothesis\", \"Null hypothesis\"),   footnote = NULL,   display_bound = c(\"Efficacy\", \"Futility\"),   display_columns = NULL,   display_inf_bound = TRUE,   ... )"},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.gs_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"This is the function to format the bounds summary table into gt style. — as_gt.gs_design","text":"x object returned summary_bound title string specify title gt table subtitle string specify subtitle gt table colname_spanner string specify spanner gt table colname_spannersub vector strings specify spanner details gt table footnote list containing content, location, attr. content vector string specify footnote text; location vector string specify locations put superscript footnote index; attr vector string specify attributes footnotes, e.g., c(\"colname\", \"title\", \"subtitle\", \"analysis\", \"spanner\"); users can use functions gt package custom . display_bound vector strings specifying label bounds. default c(\"Efficacy\", \"Futility\") display_columns vector strings specifying variables displayed summary table display_inf_bound logic value (TRUE FALSE) whether display +-inf bound ... additional arguments","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.gs_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"This is the function to format the bounds summary table into gt style. — as_gt.gs_design","text":"gt table summarizing bounds table group sequential designs","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.gs_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"This is the function to format the bounds summary table into gt style. — as_gt.gs_design","text":"","code":"if (FALSE) { # the default output  library(dplyr)  gs_design_ahr() %>%    summary() %>%    as_gt()    gs_power_ahr() %>%    summary() %>%    as_gt()    gs_design_wlr() %>%    summary() %>%    as_gt()    gs_power_wlr() %>%   summary() %>%   as_gt()   gs_design_combo() %>%    summary() %>%    as_gt()   gs_power_combo() %>%    summary() %>%    as_gt()  gs_design_rd() %>%    summary() %>%    as_gt()  gs_power_rd() %>%    summary() %>%    as_gt()   # usage of title = ..., subtitle = ... # to edit the title/subtitle  gs_power_wlr() %>%    summary() %>%   as_gt(     title = \"Bound Summary\",     subtitle = \"from gs_power_wlr\")  # usage of colname_spanner = ..., colname_spannersub = ... # to edit the spanner and its sub-spanner gs_power_wlr() %>%    summary() %>%   as_gt(     colname_spanner = \"Cumulative probability to cross boundaries\",     colname_spannersub = c(\"under H1\", \"under H0\"))      # usage of footnote = ... # to edit the footnote gs_power_wlr() %>%    summary() %>%   as_gt(     footnote = list(content = c(\"approximate weighted hazard ratio to cross bound.\",                                  \"wAHR is the weighted AHR.\",                                 \"the crossing probability.\",                                 \"this table is generated by gs_power_wlr.\"),                    location = c(\"~wHR at bound\", NA, NA, NA),                    attr = c(\"colname\", \"analysis\", \"spanner\", \"title\")))                     # usage of display_bound = ... # to either show efficacy bound or futility bound, or both(default)  gs_power_wlr() %>%    summary() %>%    as_gt(display_bound = \"Efficacy\")    # usage of display_columns = ... # to select the columns to display in the summary table gs_power_wlr() %>%   summary() %>%   as_gt(display_columns = c(\"Analysis\", \"Bound\", \"Nominal p\", \"Z\", \"Probability\")) }"},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.html","id":null,"dir":"Reference","previous_headings":"","what":"S3 class method to get summary table into a gt table — as_gt","title":"S3 class method to get summary table into a gt table — as_gt","text":"S3 class method get summary table gt table","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3 class method to get summary table into a gt table — as_gt","text":"","code":"as_gt(x, ...)"},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3 class method to get summary table into a gt table — as_gt","text":"x summary fixed group sequential design ... additional arguments","code":""},{"path":"https://merck.github.io/gsDesign2/reference/as_gt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3 class method to get summary table into a gt table — as_gt","text":"gt table","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eAccrual.html","id":null,"dir":"Reference","previous_headings":"","what":"Piecewise constant expected accrual — eAccrual","title":"Piecewise constant expected accrual — eAccrual","text":"eAccrual() computes expected cumulative enrollment (accrual) given set piecewise constant enrollment rates times.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eAccrual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Piecewise constant expected accrual — eAccrual","text":"","code":"eAccrual(   x = 0:24,   enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20)) )"},{"path":"https://merck.github.io/gsDesign2/reference/eAccrual.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Piecewise constant expected accrual — eAccrual","text":"x times enrollment computed. enrollRates Piecewise constant enrollment rates expressed tibble duration piecewise constant period rate enrollment period.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eAccrual.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Piecewise constant expected accrual — eAccrual","text":"vector expected cumulative enrollment specified times.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eAccrual.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Piecewise constant expected accrual — eAccrual","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eAccrual.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Piecewise constant expected accrual — eAccrual","text":"","code":"library(tibble)  # Example 1: default eAccrual() #>  [1]   0   5  10  15  25  35  45  65  85 105 125 145 165 185 205 225 245 265 285 #> [20] 305 325 345 365 385 405  # Example 2: unstratified design eAccrual(x = c(5, 10, 20),           enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20))) #> [1]  35 125 325  eAccrual(x = c(5, 10, 20),           enrollRates = tibble(duration = c(3, 3, 18), rate = c(5, 10, 20),           Stratum = \"All\")) #> [1]  35 125 325           # Example 3: stratified design eAccrual(x = c(24, 30, 40),           enrollRates = tibble(Stratum=c(\"subgroup\", \"complement\"),                                duration = 33,                                rate = c(30, 30))) #> [1] 1440 1800 1980"},{"path":"https://merck.github.io/gsDesign2/reference/eEvents_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected events observed under piecewise exponential model — eEvents_df","title":"Expected events observed under piecewise exponential model — eEvents_df","text":"eEvents_df computes expected events time strata assumption piecewise constant enrollment rates piecewise exponential failure censoring rates. piecewise exponential distribution allows simple method specify distribtuion enrollment pattern enrollment, failure dropout rates changes time. main purpose may generate trial can analyzed single point time using group sequential methods, routine can also used simulate adaptive trial design. intent enable sample size calculations non-proportional hazards assumptions stratified populations.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eEvents_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected events observed under piecewise exponential model — eEvents_df","text":"","code":"eEvents_df(   enrollRates = tibble::tibble(duration = c(2, 2, 10), rate = c(3, 6, 9)),   failRates = tibble::tibble(duration = c(3, 100), failRate = log(2)/c(9, 18),     dropoutRate = rep(0.001, 2)),   totalDuration = 25,   simple = TRUE )"},{"path":"https://merck.github.io/gsDesign2/reference/eEvents_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected events observed under piecewise exponential model — eEvents_df","text":"enrollRates Enrollment rates; see details examples failRates Failure rates dropout rates period totalDuration Total follow-start enrollment data cutoff simple default (TRUE), return numeric expected number events, otherwise tibble described .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eEvents_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected events observed under piecewise exponential model — eEvents_df","text":"default simple=TRUE return total expected number events real number. Otherwise, simple=FALSE tibble returned following variables period specified 'failRates': t start period, failRate failure rate period Events expected events period, records returned tibble correspond input tibble  failRates.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/eEvents_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Expected events observed under piecewise exponential model — eEvents_df","text":"periods generally supplied output input. intent enable expected event calculations tidy format maximize flexibility variety purposes.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/reference/eEvents_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expected events observed under piecewise exponential model — eEvents_df","text":"","code":"library(tibble) library(gsDesign2)  # Default arguments, simple output (total event count only) eEvents_df() #> [1] 57.3537  # Event count by time period eEvents_df(simple = FALSE) #> # A tibble: 2 × 3 #>       t failRate Events #>   <dbl>    <dbl>  <dbl> #> 1     0   0.0770   22.2 #> 2     3   0.0385   35.1  # Early cutoff eEvents_df(totalDuration = .5) #> [1] 0.02850923  # Single time period example eEvents_df(enrollRates = tibble(duration = 10,rate = 10),            failRates = tibble(duration=100, failRate = log(2) / 6 ,dropoutRate = .01),            totalDuration = 22,            simple = FALSE) #> # A tibble: 1 × 3 #>       t failRate Events #>   <dbl>    <dbl>  <dbl> #> 1     0    0.116   80.4  # Single time period example, multiple enrollment periods eEvents_df(enrollRates = tibble(duration = c(5,5), rate = c(10, 20)),            failRates = tibble(duration = 100, failRate = log(2)/6, dropoutRate = .01),            totalDuration = 22, simple = FALSE) #> # A tibble: 1 × 3 #>       t failRate Events #>   <dbl>    <dbl>  <dbl> #> 1     0    0.116   119."},{"path":"https://merck.github.io/gsDesign2/reference/fixed_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Fixed design sample size — fixed_design","title":"Fixed design sample size — fixed_design","text":"Computes fixed design sample size many sample size methods. Returns tibble basic summary","code":""},{"path":"https://merck.github.io/gsDesign2/reference/fixed_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fixed design sample size — fixed_design","text":"","code":"fixed_design(   x = c(\"AHR\", \"FH\", \"MB\", \"LF\", \"RD\", \"MaxCombo\", \"RMST\", \"Milestone\"),   alpha = 0.025,   power = NULL,   ratio = 1,   studyDuration = 36,   ... )"},{"path":"https://merck.github.io/gsDesign2/reference/fixed_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fixed design sample size — fixed_design","text":"x Sample size method; default \"AHR\"; options include \"FH\", \"MB\", \"LF\", \"RD\", \"MaxCombo\", \"Milestone\". alpha One-sided Type error (strictly 0 1) power Power (NULL compute power strictly 0 1 - alpha otherwise) ratio Experimental:Control randomization ratio studyDuration study duration ... additional arguments like enrollRates, failRates, rho, gamma, tau","code":""},{"path":"https://merck.github.io/gsDesign2/reference/fixed_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fixed design sample size — fixed_design","text":"table","code":""},{"path":"https://merck.github.io/gsDesign2/reference/fixed_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fixed design sample size — fixed_design","text":"","code":"library(dplyr)  # Average hazard ratio x <- fixed_design(\"AHR\",                    alpha = .025, power = .9,                    enrollRates = tibble::tibble(Stratum = \"All\",  duration = 18, rate = 1),                   failRates = tibble::tibble(Stratum = \"All\", duration = c(4, 100), failRate = log(2) / 12, hr = c(1, .6), dropoutRate = .001),                   studyDuration = 36) x %>% summary()             #> # A tibble: 1 × 7 #>   Design                   N Events  Time Bound alpha Power #>   <chr>                <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Average hazard ratio  463.   325.    36  1.96 0.025   0.9  # Lachin and Foulkes (uses gsDesign::nSurv()) x <- fixed_design(\"LF\",                    alpha = .025, power = .9,                    enrollRates = tibble::tibble(Stratum = \"All\",  duration = 18, rate = 1),                   failRates = tibble::tibble(Stratum = \"All\", duration = 100, failRate = log(2) / 12, hr = .7, dropoutRate = .001),                   studyDuration = 36) x %>% summary() #> # A tibble: 1 × 7 #>   Design                 N Events  Time Bound alpha Power #>   <chr>              <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Lachin and Foulkes  463.   329.    36  1.96 0.025   0.9  # RMST x <- fixed_design(\"RMST\", alpha = .025, power = .9,                    enrollRates = tibble::tibble(Stratum = \"All\",  duration = 18, rate = 1),                   failRates = tibble::tibble(Stratum = \"All\", duration = 100, failRate = log(2) / 12, hr = .7, dropoutRate = .001),                   studyDuration = 36,                   tau = 18) x %>% summary() #> # A tibble: 1 × 7 #>   Design             N Events  Time Bound alpha Power #>   <chr>          <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 RMST: tau = 18  671.   477.    36  1.96 0.025   0.9  # Milestone  x <- fixed_design(\"Milestone\", alpha = .025, power = .9,                    enrollRates = tibble::tibble(Stratum = \"All\",  duration = 18, rate = 1),                   failRates = tibble::tibble(Stratum = \"All\", duration = 100, failRate = log(2) / 12, hr = .7, dropoutRate = .001),                   studyDuration = 36,                   tau = 18) x %>% summary() #> # A tibble: 1 × 7 #>   Design                  N Events  Time Bound alpha Power #>   <chr>               <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Milestone: tau = 18  606.   431.    36  1.96 0.025   0.9"},{"path":"https://merck.github.io/gsDesign2/reference/gsDesign2-package.html","id":null,"dir":"Reference","previous_headings":"","what":"gsDesign2: Group Sequential Design with Non-Constant Effect — gsDesign2-package","title":"gsDesign2: Group Sequential Design with Non-Constant Effect — gsDesign2-package","text":"Basic group sequential design computations extended.","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/reference/gsDesign2-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gsDesign2: Group Sequential Design with Non-Constant Effect — gsDesign2-package","text":"Maintainer: Yujie Zhao yujie.zhao@merck.com Authors: Keaven Anderson keaven_anderson@merck.com Yilong Zhang elong0527@gmail.com contributors: Jianxiao Yang yangjx@ucla.edu [contributor] Nan Xiao nan.xiao1@merck.com [contributor] Amin Shirazi ashirazist@gmail.com [contributor] Ruixue Wang ruixue.wang@merck.com [contributor] Yi Cui yi.cui@merck.com [contributor] Ping Yang ping.yang1@merck.com [contributor] Xin Tong Li xin.tong.li@merck.com [contributor] Yalin Zhu yalin.zhu@merck.com [contributor] Merck & Co., Inc., Rahway, NJ, USA affiliates [copyright holder]","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_b.html","id":null,"dir":"Reference","previous_headings":"","what":"gs_b: Default boundary generation — gs_b","title":"gs_b: Default boundary generation — gs_b","text":"gs_b() simplest version function used upper lower arguments gs_prob(), gs_power_nph gs_design_nph(); simply returns vector input input vector Z , k specified par[k]j returned. Note bounds need change changing information analyses, gs_b() used. instance, spending function bounds use","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_b.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"gs_b: Default boundary generation — gs_b","text":"","code":"gs_b(par = NULL, k = NULL, ...)"},{"path":"https://merck.github.io/gsDesign2/reference/gs_b.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"gs_b: Default boundary generation — gs_b","text":"par gs_b(), just Z-values boundaries; can include infinite values k NULL (default), return par, else return par[k] ... arguments passed methods","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_b.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"gs_b: Default boundary generation — gs_b","text":"returns vector input par k NULL, otherwise, par[k]","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_b.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"gs_b: Default boundary generation — gs_b","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_b.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"gs_b: Default boundary generation — gs_b","text":"","code":"# Simple: enter a vector of length 3 for bound gs_b(par = 4:2) #> [1] 4 3 2  # 2nd element of par gs_b(par = 4:2, k = 2) #> [1] 3  # Generate an efficacy bound using a spending function # Use Lan-DeMets spending approximation of O'Brien-Fleming bound # as 50%, 75% and 100% of final spending # Information fraction IF <- c(.5, .75, 1) gs_b(par = gsDesign::gsDesign(alpha = .025, k = length(IF),       test.type = 1, sfu = gsDesign::sfLDOF,       timing = IF)$upper$bound) #> [1] 2.962588 2.359018 2.014084"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"Group sequential design using average hazard ratio non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"","code":"gs_design_ahr(   enrollRates = tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)),   failRates = tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   ratio = 1,   alpha = 0.025,   beta = 0.1,   IF = NULL,   analysisTimes = 36,   binding = FALSE,   upper = gs_b,   upar = gsDesign::gsDesign(k = 3, test.type = 1, n.I = c(0.25, 0.75, 1), sfu = sfLDOF,     sfupar = NULL)$upper$bound,   lower = gs_b,   lpar = c(qnorm(0.1), -Inf, -Inf),   h1_spending = TRUE,   test_upper = TRUE,   test_lower = TRUE,   info_scale = c(0, 1, 2),   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"enrollRates enrollment rates failRates failure dropout rates ratio Experimental:Control randomization ratio (yet implemented) alpha One-sided Type error beta Type II error Targeted information fraction analysis analysisTimes Minimum time analysis binding indicator whether futility bound binding; default FALSE recommended upper Function compute upper bound upar Parameter passed upper() lower Function compute lower bound lpar Parameter passed lower() h1_spending Indicator lower bound set spending alternate hypothesis (input failRates) spending used lower bound test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default) indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound info_scale information scale calculation r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"tibble columns Analysis, Bound, Z, Probability, theta, Time, AHR, Events","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"Need added","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_ahr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_ahr","text":"","code":"library(gsDesign) library(gsDesign2) library(dplyr)  # call with defaults gs_design_ahr() #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  13.2 #> 2 All            2  26.4 #> 3 All           10  39.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 1 × 7 #>   Analysis Bound Probability Probability0     Z `~HR at bound` `Nominal p` #>      <dbl> <chr>       <dbl>        <dbl> <dbl>          <dbl>       <dbl> #> 1        1 Upper         0.9        0.025  1.96          0.795      0.0250 #>  #> $analysis #> # A tibble: 1 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    36  476.   292. 0.683 0.381  71.7  73.0     1 #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # Single analysis gs_design_ahr(analysisTimes = 40) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  11.9 #> 2 All            2  23.8 #> 3 All           10  35.6 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 1 × 7 #>   Analysis Bound Probability Probability0     Z `~HR at bound` `Nominal p` #>      <dbl> <chr>       <dbl>        <dbl> <dbl>          <dbl>       <dbl> #> 1        1 Upper         0.9        0.025  1.96          0.791      0.0250 #>  #> $analysis #> # A tibble: 1 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    40  428.   280. 0.678 0.389  68.8  69.9     1 #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # Multiple analysisTimes gs_design_ahr(analysisTimes = c(12, 24, 36)) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  14.0 #> 2 All            2  27.9 #> 3 All           10  41.9 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper    0.000507   0.00000848    4.33          0.411  0.00000737 #> 2        1 Lower    0.0111     0            -1.28          1.30   0.9        #> 3        2 Upper    0.566      0.00965       2.34          0.734  0.00965    #> 4        2 Lower    0.0111     0          -Inf           Inf      1          #> 5        3 Upper    0.900      0.0251        2.01          0.795  0.0221     #> 6        3 Lower    0.0111     0          -Inf           Inf      1          #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12  419.   95.0 0.811 0.210  23.4  23.8 0.309 #> 2        2    24  503.  228.  0.715 0.335  55.9  57.1 0.738 #> 3        3    36  503.  308.  0.683 0.381  75.8  77.1 1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # Specified information fraction gs_design_ahr(IF = c(.25, .75, 1), analysisTimes = 36) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  14.2 #> 2 All            2  28.4 #> 3 All           10  42.5 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper    0.000282   0.00000836    4.33          0.376  0.00000737 #> 2        1 Lower    0.0166     0            -1.28          1.34   0.9        #> 3        2 Upper    0.585      0.00965       2.34          0.737  0.00965    #> 4        2 Lower    0.0166     0          -Inf           Inf      1          #> 5        3 Upper    0.900      0.0250        2.01          0.797  0.0221     #> 6        3 Lower    0.0166     0          -Inf           Inf      1          #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  10.7  371.   78.3 0.823 0.195  19.3  19.6 0.251 #> 2        2  24.4  510.  235.  0.714 0.337  57.4  58.7 0.747 #> 3        3  36    510.  313.  0.683 0.381  76.9  78.3 1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # multiple analysis times & IF # driven by times gs_design_ahr(IF = c(.25, .75, 1), analysisTimes = c(12, 25, 36)) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  14.0 #> 2 All            2  27.9 #> 3 All           10  41.9 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper    0.000507   0.00000848    4.33          0.411  0.00000737 #> 2        1 Lower    0.0111     0            -1.28          1.30   0.9        #> 3        2 Upper    0.600      0.00965       2.34          0.738  0.00965    #> 4        2 Lower    0.0111     0          -Inf           Inf      1          #> 5        3 Upper    0.900      0.0248        2.01          0.795  0.0221     #> 6        3 Lower    0.0111     0          -Inf           Inf      1          #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12  419.   95.0 0.811 0.210  23.4  23.7 0.309 #> 2        2    25  503.  236.  0.711 0.341  57.8  59.1 0.763 #> 3        3    36  503.  308.  0.683 0.381  75.7  77.1 1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"      # driven by IF gs_design_ahr(IF = c(1/3, .8, 1), analysisTimes = c(12, 25, 36)) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  13.9 #> 2 All            2  27.8 #> 3 All           10  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper    0.000645   0.00000852    4.33          0.425  0.00000737 #> 2        1 Lower    0.00928    0            -1.28          1.29   0.9        #> 3        2 Upper    0.640      0.00965       2.34          0.742  0.00965    #> 4        2 Lower    0.00928    0          -Inf           Inf      1          #> 5        3 Upper    0.900      0.0244        2.01          0.795  0.0221     #> 6        3 Lower    0.00928    0          -Inf           Inf      1          #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  12.5  439.   102. 0.806 0.216  25.2  25.6 0.334 #> 2        2  26.4  501.   246. 0.706 0.348  60.1  61.4 0.797 #> 3        3  36    501.   307. 0.683 0.381  75.4  76.8 1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # 2-sided symmetric design with O'Brien-Fleming spending gs_design_ahr(   analysisTimes = c(12, 24, 36),   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   h1_spending = FALSE) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  13.7 #> 2 All            2  27.5 #> 3 All           10  41.2 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0     Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl> <dbl>          <dbl>       <dbl> #> 1        1 Upper 0.00226        0.0000603  3.87          0.449   0.0000538 #> 2        1 Lower 0.000000613    0.0000603 -3.87          2.23    1.00      #> 3        2 Upper 0.550          0.00922    2.36          0.730   0.00919   #> 4        2 Lower 0.00000125     0.00922   -2.36          1.37    0.991     #> 5        3 Upper 0.900          0.0250     2.01          0.794   0.0222    #> 6        3 Lower 0.00000128     0.0250    -2.01          1.26    0.978     #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12  412.   93.4 0.811 0.210  23.0  23.3 0.309 #> 2        2    24  494.  224.  0.715 0.335  54.9  56.1 0.738 #> 3        3    36  494.  303.  0.683 0.381  74.4  75.8 1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # 2-sided asymmetric design with O'Brien-Fleming upper spending # Pocock lower spending under H1 (NPH) gs_design_ahr(   analysisTimes = c(12, 24, 36),   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDPocock, total_spend = 0.1, param = NULL, timing = NULL),   h1_spending = TRUE) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2  16.5 #> 2 All            2  32.9 #> 3 All           10  49.4 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper     0.00305    0.0000603  3.87           0.481   0.0000538 #> 2        1 Lower     0.0430     0.269     -0.619          1.12    0.732     #> 3        2 Upper     0.638      0.00922    2.36           0.750   0.00920   #> 4        2 Lower     0.0823     0.875      1.13           0.871   0.129     #> 5        3 Upper     0.900      0.0250     1.98           0.813   0.0240    #> 6        3 Lower     0.100      0.976      1.97           0.813   0.0243    #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12  494.   112. 0.811 0.210  27.6  28.0 0.309 #> 2        2    24  593.   269. 0.715 0.335  65.9  67.3 0.738 #> 3        3    36  593.   364. 0.683 0.381  89.3  90.9 1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_combo.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design using MaxCombo test under non-proportional hazards — gs_design_combo","title":"Group sequential design using MaxCombo test under non-proportional hazards — gs_design_combo","text":"Group sequential design using MaxCombo test non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_combo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design using MaxCombo test under non-proportional hazards — gs_design_combo","text":"","code":"gs_design_combo(   enrollRates = tibble(Stratum = \"All\", duration = 12, rate = 500/12),   failRates = tibble(Stratum = \"All\", duration = c(4, 100), failRate = log(2)/15, hr =     c(1, 0.6), dropoutRate = 0.001),   fh_test = rbind(data.frame(rho = 0, gamma = 0, tau = -1, test = 1, Analysis = 1:3,     analysisTimes = c(12, 24, 36)), data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1,     test = 2:3, Analysis = 3, analysisTimes = 36)),   ratio = 1,   alpha = 0.025,   beta = 0.2,   binding = FALSE,   upper = gs_b,   upar = c(3, 2, 1),   lower = gs_b,   lpar = c(-1, 0, 1),   algorithm = mvtnorm::GenzBretz(maxpts = 1e+05, abseps = 1e-05),   n_upper_bound = 1000,   ... )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_combo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design using MaxCombo test under non-proportional hazards — gs_design_combo","text":"enrollRates enrollment rates failRates failure dropout rates fh_test data frame summarize test analysis. Refer examples data structure. ratio Experimental:Control randomization ratio (yet implemented) alpha One-sided Type error beta Type II error binding indicator whether futility bound binding; default FALSE recommended upper Function compute upper bound upar Parameter passed upper() lower Function compute lower bound lpar Parameter passed lower() algorithm object class GenzBretz,                     Miwa TVPACK                     specifying algorithm used well                     associated hyper parameters. n_upper_bound numeric value upper limit sample size ... additional parameters transfer mvtnorm::pmvnorm","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_combo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design using MaxCombo test under non-proportional hazards — gs_design_combo","text":"","code":"# The example is slow to run library(dplyr) library(mvtnorm) library(gsDesign) library(tibble)  enrollRates <- tibble(   Stratum = \"All\",    duration = 12,    rate = 500/12)    failRates <- tibble(   Stratum = \"All\",   duration = c(4, 100),   failRate = log(2) / 15,  # median survival 15 month   hr = c(1, .6),   dropoutRate = 0.001)    fh_test <- rbind(    data.frame(rho = 0, gamma = 0, tau = -1,              test = 1, Analysis = 1:3, analysisTimes = c(12, 24, 36)),   data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1,              test = 2:3, Analysis = 3, analysisTimes = 36))  x <- gsSurv(    k = 3 ,    test.type = 4 ,    alpha = 0.025 ,   beta = 0.2 ,    astar = 0 ,    timing = 1,   sfu = sfLDOF ,    sfupar = 0,    sfl = sfLDOF ,   sflpar = 0,    lambdaC = 0.1,   hr = 0.6,    hr0 = 1,    eta = 0.01,   gamma = 10,   R = 12,    S = NULL,   T = 36,    minfup = 24,    ratio = 1)  # -------------------------# #       example 1          # # ------------------------ # if (FALSE) { # User defined boundary gs_design_combo(   enrollRates,   failRates,   fh_test,   alpha = 0.025, beta = 0.2,   ratio = 1,   binding = FALSE,          upar = x$upper$bound,   lpar = x$lower$bound) }  # -------------------------# #       example 2          # # ------------------------ # # Boundary derived by spending function gs_design_combo(   enrollRates,   failRates,   fh_test,   alpha = 0.025,    beta = 0.2,   ratio = 1,   binding = FALSE,                    upper = gs_spending_combo,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   # alpha spending   lower = gs_spending_combo,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.2),     # beta spending ) #> The AHR reported in the `analysis` table is under the log-rank test. #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  25.1 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #>   Analysis Bound  Probability Probability0         Z    Nominal p #> 1        1 Upper 2.086896e-08 3.299865e-10  6.175397 3.299865e-10 #> 2        1 Lower 3.269655e-04 0.000000e+00 -2.716138 9.966976e-01 #> 3        2 Upper 2.202673e-01 2.565830e-03  2.798651 2.565830e-03 #> 4        2 Lower 8.468735e-02 0.000000e+00  0.652965 2.568894e-01 #> 5        3 Upper 8.000004e-01 2.497218e-02  2.096972 1.799803e-02 #> 6        3 Lower 1.999988e-01 0.000000e+00  2.096972 1.799803e-02 #>  #> $analysis #>   Analysis Time        N    Events        EF       AHR #> 1        1   12 301.1933  64.69287 0.3241690 0.8418858 #> 2        2   24 301.1933 148.35783 0.7434051 0.7164215 #> 3        3   36 301.1933 199.56524 1.0000000 0.6831740 #>  #> attr(,\"class\") #> [1] \"combo\"     \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design computation with non-constant effect and information — gs_design_npe","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"gs_design_npe() derives group sequential design size, bounds boundary crossing probabilities based proportionate information effect size analyses. allows non-constant treatment effect time, also can applied usual homogeneous effect size designs. requires treatment effect proportionate statistical information analysis well method deriving bounds, spending. routine enables two things available gsDesign package: 1) non-constant effect, 2) flexibility boundary selection. many applications, non-proportional-hazards design function gs_design_nph() used; calls function. Initial bound types supported 1) spending bounds, 2) fixed bounds, 3) Haybittle-Peto-like bounds. requirement boundary update method can bound without knowledge future bounds. example, bounds based conditional power require knowledge future bounds supported routine; limited conditional power method demonstrated. Boundary family designs Wang-Tsiatis designs including original (non-spending-function-based) O'Brien-Fleming Pocock designs supported gs_power_npe().","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"","code":"gs_design_npe(   theta = 0.1,   theta0 = NULL,   theta1 = NULL,   info = 1,   info0 = NULL,   info1 = NULL,   info_scale = c(0, 1, 2),   alpha = 0.025,   beta = 0.1,   upper = gs_b,   upar = qnorm(0.975),   lower = gs_b,   lpar = -Inf,   test_upper = TRUE,   test_lower = TRUE,   binding = FALSE,   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"theta natural parameter group sequential design representing expected incremental drift analyses; used power calculation theta0 natural parameter used upper bound spending; NULL, set 0 theta1 natural parameter used lower bound spending; NULL, set theta yields usual beta-spending. set 0, spending 2-sided null hypothesis. info proportionate statistical information analyses input theta info0 proportionate statistical information null hypothesis, different alternative; impacts null hypothesis bound calculation info1 proportionate statistical information alternate hypothesis; impacts null hypothesis bound calculation info_scale information scale calculation alpha One-sided Type error beta Type II error upper function compute upper bound upar parameter pass function provided upper lower function compare lower bound lpar Parameter passed function provided lower test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default) indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound binding indicator whether futility bound binding; default FALSE recommended r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"tibble columns Analysis, Bound, Z, Probability,  theta, info, info0","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"inputs info info0 vectors length increasing positive numbers. design returned change constant scale factor ensure design power 1 - beta. bound specifications upper, lower, upar, lpar used ensure Type error boundary properties specified.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_npe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design computation with non-constant effect and information — gs_design_npe","text":"","code":"library(dplyr) library(gsDesign)  # ---------------------------------#  #         example 1                # # ---------------------------------#  # Single analysis # Lachin book p 71 difference of proportions example pc <- .28            # Control response rate pe <- .40            # Experimental response rate p0 <- (pc + pe) / 2  # Ave response rate under H0  # Information per increment of 1 in sample size info0 <- 1 / (p0 * (1 - p0) * 4) info <- 1 / (pc * (1 - pc) * 2 + pe * (1 - pe) * 2)  # Result should round up to next even number = 652 # Divide information needed under H1 by information per patient added gs_design_npe(theta = pe - pc, info = info, info0 = info0) #> # A tibble: 1 × 10 #>   Analysis Bound     Z Probability Probability0 theta  info info0 info1    IF #>      <dbl> <chr> <dbl>       <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  1.96         0.9        0.025  0.12  737.  725.  737.     1   # ---------------------------------#  #         example 2                # # ---------------------------------#  # Fixed bound x <- gs_design_npe(   theta = c(.1, .2, .3),   info = (1:3) * 80,   info0 = (1:3) * 80,   upper = gs_b,   upar = gsDesign::gsDesign(k = 3, sfu = gsDesign::sfLDOF)$upper$bound,   lower = gs_b,   lpar = c(-1, 0, 0)) x #> # A tibble: 6 × 10 #>   Analysis Bound     Z Probability Probability0 theta    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71     0.00120     0.000104   0.1 0.333  45.6  45.6  45.6 #> 2        1 Lower -1        0.0470      0          0.1 0.333  45.6  45.6  45.6 #> 3        2 Upper  2.51     0.273       0.00605    0.2 0.667  91.1  91.1  91.1 #> 4        2 Lower  0        0.0619      0          0.2 0.667  91.1  91.1  91.1 #> 5        3 Upper  1.99     0.900       0.0250     0.3 1     137.  137.  137.  #> 6        3 Lower  0        0.0619      0          0.3 1     137.  137.  137.   # Same upper bound; this represents non-binding Type I error and will total 0.025 gs_power_npe(   theta = rep(0, 3),   info = (x %>% filter(Bound == \"Upper\"))$info,   upper = gs_b,   upar = (x %>% filter(Bound == \"Upper\"))$Z,   lower = gs_b,   lpar = rep(-Inf, 3)) #> # A tibble: 6 × 10 #>   Analysis Bound       Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr>   <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper    3.71    0.000104     0      0 0.333  45.6  45.6  45.6 #> 2        2 Upper    2.51    0.00605      0      0 0.667  91.1  91.1  91.1 #> 3        3 Upper    1.99    0.0250       0      0 1     137.  137.  137.  #> 4        1 Lower -Inf       0            0      0 0.333  45.6  45.6  45.6 #> 5        2 Lower -Inf       0            0      0 0.667  91.1  91.1  91.1 #> 6        3 Lower -Inf       0            0      0 1     137.  137.  137.   # ---------------------------------#  #         example 3                # # ---------------------------------#  # Spending bound examples # Design with futility only at analysis 1; efficacy only at analyses 2, 3 # Spending bound for efficacy; fixed bound for futility # NOTE: test_upper and test_lower DO NOT WORK with gs_b; must explicitly make bounds infinite # test_upper and test_lower DO WORK with gs_spending_bound gs_design_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   info0 = (1:3) * 40,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_b,   lpar = c(-1, -Inf, -Inf),   test_upper = c(FALSE, TRUE, TRUE)) #> # A tibble: 6 × 10 #>   Analysis Bound       Z Probability Probability0 theta    IF  info info0 info1 #>      <int> <chr>   <dbl>       <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  Inf         0           0         0.1 0.333  44.6  44.6  44.6 #> 2        1 Lower   -1         0.0477      0         0.1 0.333  44.6  44.6  44.6 #> 3        2 Upper    2.51      0.267       0.00605   0.2 0.667  89.1  89.1  89.1 #> 4        2 Lower -Inf         0.0477      0         0.2 0.667  89.1  89.1  89.1 #> 5        3 Upper    1.99      0.900       0.0250    0.3 1     134.  134.  134.  #> 6        3 Lower -Inf         0.0477      0         0.3 1     134.  134.  134.     # one can try `info_scale = 1` or `info_scale = 0` here gs_design_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   info0 = (1:3) * 30,   info_scale = 1,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_b,   lpar = c(-1, -Inf, -Inf),   test_upper = c(FALSE, TRUE, TRUE)) #> # A tibble: 6 × 10 #>   Analysis Bound       Z Probability Probability0 theta    IF  info info0 info1 #>      <int> <chr>   <dbl>       <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  Inf         0           0         0.1 0.333  44.6  44.6  44.6 #> 2        1 Lower   -1         0.0477      0         0.1 0.333  44.6  44.6  44.6 #> 3        2 Upper    2.51      0.267       0.00605   0.2 0.667  89.1  89.1  89.1 #> 4        2 Lower -Inf         0.0477      0         0.2 0.667  89.1  89.1  89.1 #> 5        3 Upper    1.99      0.900       0.0250    0.3 1     134.  134.  134.  #> 6        3 Lower -Inf         0.0477      0         0.3 1     134.  134.  134.   # ---------------------------------#  #         example 4                # # ---------------------------------#  # Spending function bounds # 2-sided asymmetric bounds # Lower spending based on non-zero effect gs_design_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   info0 = (1:3) * 30,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfHSD, total_spend = 0.1, param = -1, timing = NULL)) #> # A tibble: 6 × 10 #>   Analysis Bound      Z Probability Probability0 theta    IF  info info0 info1 #>      <int> <chr>  <dbl>       <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71     0.000145   0.00000917   0.1 0.333  43.5  32.7  43.5 #> 2        1 Lower -1.34     0.0139     0            0.1 0.333  43.5  32.7  43.5 #> 3        2 Upper  2.51     0.258      0.00595      0.2 0.667  87.1  65.3  87.1 #> 4        2 Lower  0.150    0.0460     0            0.2 0.667  87.1  65.3  87.1 #> 5        3 Upper  1.99     0.900      0.0249       0.3 1     131.   98.0 131.  #> 6        3 Lower  2.00     0.0908     0            0.3 1     131.   98.0 131.   # ---------------------------------#  #         example 5                # # ---------------------------------#  # Two-sided symmetric spend, O'Brien-Fleming spending # Typically, 2-sided bounds are binding xx <- gs_design_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)) xx #> # A tibble: 6 × 10 #>   Analysis Bound      Z Probability Probability0 theta    IF  info info0 info1 #>      <int> <chr>  <dbl>       <dbl>        <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71     0.00104      0.000104   0.1 0.333  39.8  39.8  39.8 #> 2        1 Lower -3.08     0.000104     0.00104    0.1 0.333  39.8  39.8  39.8 #> 3        2 Upper  2.51     0.233        0.00605    0.2 0.667  79.5  79.5  79.5 #> 4        2 Lower -0.728    0.00605      0.233      0.2 0.667  79.5  79.5  79.5 #> 5        3 Upper  1.99     0.900        0.0250     0.3 1     119.  119.  119.  #> 6        3 Lower  1.28     0.0250       0.900      0.3 1     119.  119.  119.   # Re-use these bounds under alternate hypothesis # Always use binding = TRUE for power calculations gs_power_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   binding = TRUE,   upper = gs_b,   lower = gs_b,   upar = (xx %>% filter(Bound == \"Upper\"))$Z,   lpar = -(xx %>% filter(Bound == \"Upper\"))$Z) #> # A tibble: 6 × 10 #>   Analysis Bound     Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71  0.00104      0.1    0.1 0.333    40    40    40 #> 2        2 Upper  2.51  0.235        0.2    0.2 0.667    80    80    80 #> 3        3 Upper  1.99  0.902        0.3    0.3 1       120   120   120 #> 4        1 Lower -3.71  0.00000704   0.1    0.1 0.333    40    40    40 #> 5        2 Lower -2.51  0.0000151    0.2    0.2 0.667    80    80    80 #> 6        3 Lower -1.99  0.0000151    0.3    0.3 1       120   120   120"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_rd.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","text":"Group sequential design using average hazard ratio non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_rd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","text":"","code":"gs_design_rd(   p_c = tibble(Stratum = \"All\", Rate = 0.2),   p_e = tibble(Stratum = \"All\", Rate = 0.15),   IF = 1:3/3,   rd0 = 0,   alpha = 0.025,   beta = 0.1,   ratio = 1,   stratum_prev = NULL,   weight = c(\"un-stratified\", \"ss\", \"invar\"),   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(0.1), rep(-Inf, 2)),   test_upper = TRUE,   test_lower = TRUE,   info_scale = c(0, 1, 2),   binding = FALSE,   r = 18,   tol = 1e-06,   h1_spending = FALSE )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_rd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","text":"p_c rate control group p_e rate experimental group statistical information fraction rd0 treatment effect super-superiority designs, default 0 alpha One-sided Type error beta Type II error ratio Experimental:Control randomization ratio (yet implemented) stratum_prev randomization ratio different stratum. un-stratified design NULL. Otherwise tibble containing two columns (Stratum prevalence). weight weighting scheme stratified population upper Function compute upper bound lower Function compute lower bound upar Parameter passed upper() lpar Parameter passed lower() test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default) indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound info_scale information scale calculation binding indicator whether futility bound binding; default FALSE recommended r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale) h1_spending Indicator lower bound set spending alternate hypothesis (input failRates) spending used lower bound","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_rd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","text":"tibble columns Analysis, Bound, Z, Probability, theta, Time, AHR, Events","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_rd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","text":"Need added","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_rd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design using average hazard ratio under non-proportional hazards — gs_design_rd","text":"","code":"library(tibble) library(gsDesign)  # ----------------- # #    example 1      # #------------------ # # un-stratified group sequential design gs_design_rd(   p_c = tibble(Stratum = \"All\", Rate = .2),   p_e = tibble(Stratum = \"All\", Rate = .15),   IF = c(0.7, 1),   rd0 = 0,    alpha = .025,                     beta = .1,                       ratio = 1,   stratum_prev = NULL,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2))   ) #> $bounds #> # A tibble: 4 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper  0.297          0.000100    3.71                 0.0582 1.04e-4 #> 2        1 Lower  0.00000389     0          -1.28                -0.0201 9   e-1 #> 3        2 Upper  0.900          0.00602     2.51                 0.0330 6.01e-3 #> 4        2 Lower  0.00000389     0        -Inf                 -Inf      1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 2 × 8 #>   Analysis     N    rd   rd0  info info0    IF   IF0 #>      <int> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 2336.  0.05     0 4062. 4044.   0.7   0.7 #> 2        2 3337.  0.05     0 5803. 5778.   1     1   #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"         # ----------------- # #     example 2     # # ----------------- # # stratified group sequential design gs_design_rd(   p_c = tibble(Stratum = c(\"biomarker positive\", \"biomarker negative\"), Rate = c(.2, .25)),   p_e = tibble(Stratum = c(\"biomarker positive\", \"biomarker negative\"), Rate = c(.15,.22)),   IF = c(0.7, 1),   rd0 = 0,    alpha = .025,                     beta = .1,                       ratio = 1,   stratum_prev = tibble(Stratum = c(\"biomarker positive\", \"biomarker negative\"), prevalence = c(.4, .6)),   weight = \"ss\",   upper = gs_spending_bound,lower = gs_b,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lpar = rep(-Inf, 2) ) #> $bounds #> # A tibble: 4 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper       0.616      0.00733    2.44                 0.0339 0.00738 #> 2        1 Lower       0          0       -Inf                 -Inf      1       #> 3        2 Upper       0.900      0.0249     2.00                 0.0232 0.0228  #> 4        2 Lower       0          0       -Inf                 -Inf      1       #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 2 × 8 #>   Analysis     N    rd   rd0  info info0    IF   IF0 #>      <int> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 3426. 0.038     0 5184. 5172.   0.7   0.7 #> 2        2 4894. 0.038     0 7406. 7388.   1     1   #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_wlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design using weighted log-rank test under non-proportional hazards — gs_design_wlr","title":"Group sequential design using weighted log-rank test under non-proportional hazards — gs_design_wlr","text":"Group sequential design using weighted log-rank test non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_wlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design using weighted log-rank test under non-proportional hazards — gs_design_wlr","text":"","code":"gs_design_wlr(   enrollRates = tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)),   failRates = tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   weight = wlr_weight_fh,   approx = \"asymptotic\",   alpha = 0.025,   beta = 0.1,   ratio = 1,   IF = NULL,   info_scale = c(0, 1, 2),   analysisTimes = 36,   binding = FALSE,   upper = gs_b,   upar = gsDesign(k = 3, test.type = 1, n.I = c(0.25, 0.75, 1), sfu = sfLDOF, sfupar =     NULL)$upper$bound,   lower = gs_b,   lpar = c(qnorm(0.1), -Inf, -Inf),   test_upper = TRUE,   test_lower = TRUE,   h1_spending = TRUE,   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_wlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design using weighted log-rank test under non-proportional hazards — gs_design_wlr","text":"enrollRates enrollment rates failRates failure dropout rates weight weight weighted log rank test \"1\"= unweighted, \"n\"= Gehan-Breslow, \"sqrtN\"= Tarone-Ware, \"FH_p[]_q[b]\"= Fleming-Harrington p=q=b approx approximate estimation method Z statistics \"event driven\" = work proportional hazard model log rank test \"asymptotic\" alpha One-sided Type error beta Type II error ratio Experimental:Control randomization ratio (yet implemented) Targeted information fraction analysis info_scale information scale calculation analysisTimes Minimum time analysis binding indicator whether futility bound binding; default FALSE recommended upper Function compute upper bound upar Parameter passed upper() lower Function compute lower bound lpar Parameter passed lower() test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default) indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound h1_spending Indicator lower bound set spending alternate hypothesis (input failRates) spending used lower bound r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_wlr.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential design using weighted log-rank test under non-proportional hazards — gs_design_wlr","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_design_wlr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design using weighted log-rank test under non-proportional hazards — gs_design_wlr","text":"","code":"library(dplyr) library(mvtnorm) library(gsDesign) library(tibble) library(gsDesign2)  # set enrollment rates enrollRates <- tibble(Stratum = \"All\", duration = 12, rate = 500/12)  # set failure rates failRates <- tibble(   Stratum = \"All\",   duration = c(4, 100),   failRate = log(2) / 15,  # median survival 15 month   hr = c(1, .6),   dropoutRate = 0.001)  # -------------------------# #       example 1          # # ------------------------ # # Boundary is fixed  x <- gsSurv(   k = 3,    test.type = 4,    alpha = 0.025, beta = 0.2,    astar = 0, timing = 1,   sfu = sfLDOF, sfupar = 0,    sfl = sfLDOF, sflpar = 0,    lambdaC = 0.1,    hr = 0.6, hr0 = 1,    eta = 0.01, gamma = 10,   R = 12, S = NULL,   T = 36, minfup = 24,    ratio = 1)  gs_design_wlr(   enrollRates = enrollRates,    failRates = failRates,   ratio = 1,    alpha = 0.025, beta = 0.2,   weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)},   upper = gs_b,   upar = x$upper$bound,   lower = gs_b,   lpar = x$lower$bound,   analysisTimes = c(12, 24, 36)) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  30.6 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper     0.00366     0.000108  3.71           0.434    0.000104 #> 2        1 Lower     0.105       0        -0.236          1.05     0.593    #> 3        2 Upper     0.504       0.00609   2.51           0.688    0.00601  #> 4        2 Lower     0.158       0         1.17           0.840    0.121    #> 5        3 Upper     0.800       0.0258    1.99           0.775    0.0231   #> 6        3 Lower     0.200       0         1.99           0.775    0.0231   #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12  368.   78.9 0.781 0.626  2.65  2.66 0.133 #> 2        2    24  368.  181.  0.666 0.765 11.3  11.6  0.565 #> 3        3    36  368.  244.  0.639 0.732 20.0  20.9  1     #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\"       # -------------------------# #       example 2          # # ------------------------ # # Boundary derived by spending function gs_design_wlr(   enrollRates = enrollRates,    failRates = failRates,   ratio = 1,    alpha = 0.025, beta = 0.2,   weight = function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)},   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.2),   analysisTimes = c(12, 24, 36)) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  24.0 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound  Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>        <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper 0.0000000732     3.65e-10  6.18           0.208    3.30e-10 #> 2        1 Lower 0.000441         0        -2.43           1.85     9.92e- 1 #> 3        2 Upper 0.301            2.57e- 3  2.80           0.625    2.57e- 3 #> 4        2 Lower 0.0882           0         0.925          0.856    1.77e- 1 #> 5        3 Upper 0.800            2.50e- 2  1.97           0.751    2.42e- 2 #> 6        3 Lower 0.200            0         1.97           0.751    2.42e- 2 #>  #> $analysis #> # A tibble: 3 × 9 #>   Analysis  Time     N Events   AHR theta  info info0    IF #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12  288.   61.9 0.781 0.626  2.08  2.09 0.133 #> 2        2    24  288.  142.  0.666 0.765  8.86  9.07 0.565 #> 3        3    36  288.  191.  0.639 0.732 15.7  16.4  1     #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":null,"dir":"Reference","previous_headings":"","what":"Information and effect size based on AHR approximation — gs_info_ahr","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"Based piecewise enrollment rate, failure rate, dropout rates computes approximate information effect size using average hazard ratio model.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"","code":"gs_info_ahr(   enrollRates = tibble::tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6,     9)),   failRates = tibble::tibble(Stratum = \"All\", duration = c(3, 100), failRate =     log(2)/c(9, 18), hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   ratio = 1,   events = NULL,   analysisTimes = NULL )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"enrollRates enrollment rates failRates failure dropout rates ratio Experimental:Control randomization ratio events Targeted minimum events analysis analysisTimes Targeted minimum study duration analysis","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"tibble columns Analysis, Time, AHR, Events, theta, info, info0. info, info0 contains statistical information H1, H0, respectively. analysis k, Time[k] maximum analysisTimes[k] expected time required accrue targeted events[k]. AHR expected average hazard ratio analysis.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"AHR() function computes statistical information targeted event times. tEvents() function used get events average HR targeted analysisTimes.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_ahr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information and effect size based on AHR approximation — gs_info_ahr","text":"","code":"library(gsDesign) library(gsDesign2)  # ------------------------ # #       Example 1          # # ------------------------ # # Only put in targeted events gs_info_ahr(events = c(30, 40, 50)) #> # A tibble: 3 × 7 #>   Analysis  Time Events   AHR theta  info info0 #>      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  14.9   30.0 0.787 0.240  7.37  7.50 #> 2        2  19.2   40.0 0.744 0.295  9.79 10.0  #> 3        3  24.5   50.0 0.713 0.339 12.2  12.5   # ------------------------ # #       Example 2          # # ------------------------ # # Only put in targeted analysis times gs_info_ahr(analysisTimes = c(18, 27, 36)) #> # A tibble: 3 × 7 #>   Analysis  Time Events   AHR theta  info info0 #>      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    18   37.6 0.755 0.282  9.21  9.40 #> 2        2    27   54.0 0.704 0.351 13.2  13.5  #> 3        3    36   66.2 0.683 0.381 16.3  16.6   # ------------------------ # #       Example 3          # # ------------------------ # # Some analysis times after time at which targeted events accrue # Check that both Time >= input analysisTime and Events >= input events gs_info_ahr(events = c(30, 40, 50), analysisTimes = c(16, 19, 26)) #> # A tibble: 3 × 7 #>   Analysis  Time Events   AHR theta  info info0 #>      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  16     33.1 0.776 0.254  8.12  8.27 #> 2        2  19.2   40.0 0.744 0.295  9.79 10.0  #> 3        3  26     52.4 0.707 0.346 12.8  13.1  gs_info_ahr(events = c(30, 40, 50), analysisTimes = c(14, 20, 24)) #> # A tibble: 3 × 7 #>   Analysis  Time Events   AHR theta  info info0 #>      <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  14.9   30.0 0.787 0.240  7.37  7.50 #> 2        2  20     41.7 0.738 0.304 10.2  10.4  #> 3        3  24.5   50.0 0.713 0.339 12.2  12.5"},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_combo.html","id":null,"dir":"Reference","previous_headings":"","what":"Information and effect size for max combo test — gs_info_combo","title":"Information and effect size for max combo test — gs_info_combo","text":"Information effect size max combo test","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_combo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information and effect size for max combo test — gs_info_combo","text":"","code":"gs_info_combo(   enrollRates = tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)),   failRates = tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   ratio = 1,   events = NULL,   analysisTimes = NULL,   rho,   gamma,   tau = rep(-1, length(rho)),   approx = \"asymptotic\" )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_combo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information and effect size for max combo test — gs_info_combo","text":"enrollRates enrollment rates failRates failure dropout rates ratio Experimental:Control randomization ratio (yet implemented) events Targeted events analysis analysisTimes Minimum time analysis rho Weighting parameters gamma Weighting parameters tau Weighting parameters approx Approximation method","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_rd.html","id":null,"dir":"Reference","previous_headings":"","what":"Information and effect size under risk difference — gs_info_rd","title":"Information and effect size under risk difference — gs_info_rd","text":"Information effect size risk difference","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_rd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information and effect size under risk difference — gs_info_rd","text":"","code":"gs_info_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = 0.2),   p_e = tibble::tibble(Stratum = \"All\", Rate = 0.15),   N = tibble::tibble(Stratum = \"All\", N = c(100, 200, 300), Analysis = 1:3),   rd0 = 0,   ratio = 1,   weight = c(\"un-stratified\", \"ss\", \"invar\") )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_rd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information and effect size under risk difference — gs_info_rd","text":"p_c rate control group p_e rate experimental group N sample size rd0 risk difference H0 ratio Experimental:Control randomization ratio weight weigting method, either \"un-stratified\" \"ss\" \"invar\"","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_rd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information and effect size under risk difference — gs_info_rd","text":"","code":"library(tibble) # --------------------- # #      example 1        # # --------------------- # # un-stratified case with H0: rd0 = 0 gs_info_rd(   p_c = tibble(Stratum = \"All\", Rate = .15),   p_e = tibble(Stratum = \"All\", Rate = .1),   N = tibble(Stratum = \"All\", N = c(100, 200, 300), Analysis = 1:3),   rd0 = 0,   ratio = 1 ) #> # A tibble: 3 × 8 #>   Analysis     N    rd   rd0 theta1 theta0 info1 info0 #>      <int> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   100  0.05     0  0.758      0  230.  229. #> 2        2   200  0.05     0  1.07       0  460.  457. #> 3        3   300  0.05     0  1.31       0  690.  686.  # --------------------- # #      example 2        # # --------------------- # # un-stratified case with H0: rd0 != 0 gs_info_rd(   p_c = tibble(Stratum = \"All\", Rate = .2),   p_e = tibble(Stratum = \"All\", Rate = .15),   N = tibble(Stratum = \"All\", N = c(100, 200, 300), Analysis = 1:3),   rd0 = 0.005,   ratio = 1 ) #> # A tibble: 3 × 8 #>   Analysis     N    rd   rd0 theta1 theta0 info1 info0 #>      <int> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   100  0.05 0.005  0.659 0.0658  174.  173. #> 2        2   200  0.05 0.005  0.933 0.0930  348.  346. #> 3        3   300  0.05 0.005  1.14  0.114   522.  519.  # --------------------- # #      example 3        # # --------------------- # # stratified case under sample size weighting and H0: rd0 = 0 gs_info_rd(   p_c = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), Rate = c(.15, .2, .25)),   p_e = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"), Rate = c(.1, .16, .19)),   N = tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),              Analysis = rep(1:3, 3),              N = c(50, 100, 200, 40, 80, 160, 60, 120, 240)),   rd0 = 0,   ratio = 1,   weight = \"ss\") #> # A tibble: 3 × 8 #>   Analysis     N     rd   rd0 theta1 theta0 info1 info0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   150 0.0513     0  0.829      0  261.  260. #> 2        2   300 0.0513     0  1.17       0  522.  519. #> 3        3   600 0.0513     0  1.66       0 1043. 1038.  # --------------------- # #      example 4        # # --------------------- # # stratified case under inverse variance weighting and H0: rd0 = 0 gs_info_rd(   p_c = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.15, .2, .25)),   p_e = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.1, .16, .19)),   N = tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),              Analysis = rep(1:3, 3),              N = c(50, 100, 200, 40, 80, 160, 60, 120, 240)),   rd0 = 0,   ratio = 1,   weight = \"invar\") #> # A tibble: 3 × 8 #>   Analysis     N     rd   rd0 theta1 theta0 info1 info0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   150 0.0507     0  0.835      0  271.  269. #> 2        2   300 0.0507     0  1.18       0  542.  539. #> 3        3   600 0.0507     0  1.67       0 1083. 1078.  # --------------------- # #      example 5        # # --------------------- # # stratified case under sample size weighting and H0: rd0 != 0 gs_info_rd(   p_c = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.15, .2, .25)),   p_e = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.1, .16, .19)),   N = tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),              Analysis = rep(1:3, 3),              N = c(50, 100, 200, 40, 80, 160, 60, 120, 240)),   rd0 = 0.02,   ratio = 1,   weight = \"ss\") #> # A tibble: 3 × 8 #>   Analysis     N     rd   rd0 theta1 theta0 info1 info0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   150 0.0513  0.02  0.829  0.322  261.  260. #> 2        2   300 0.0513  0.02  1.17   0.456  522.  519. #> 3        3   600 0.0513  0.02  1.66   0.644 1043. 1038.  # --------------------- # #      example 6        # # --------------------- # # stratified case under inverse variance weighting and H0: rd0 != 0 gs_info_rd(   p_c = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.15, .2, .25)),   p_e = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.1, .16, .19)),   N = tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),              Analysis = rep(1:3, 3),              N = c(50, 100, 200, 40, 80, 160, 60, 120, 240)),   rd0 = 0.02,   ratio = 1,   weight = \"invar\") #> # A tibble: 3 × 8 #>   Analysis     N     rd   rd0 theta1 theta0 info1 info0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   150 0.0507  0.02  0.835  0.328  271.  269. #> 2        2   300 0.0507  0.02  1.18   0.464  542.  539. #> 3        3   600 0.0507  0.02  1.67   0.657 1083. 1078.  # --------------------- # #      example 7        # # --------------------- # # stratified case under inverse variance weighting and H0: rd0 != 0 and  # rd0 difference for different statum gs_info_rd(   p_c = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.15, .2, .25)),   p_e = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                Rate = c(.1, .16, .19)),   N = tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),              Analysis = rep(1:3, 3),              N = c(50, 100, 200, 40, 80, 160, 60, 120, 240)),   rd0 = tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                rd0 = c(0.01, 0.02, 0.03)),   ratio = 1,   weight = \"invar\") #> # A tibble: 3 × 8 #>   Analysis     N     rd    rd0 theta1 theta0 info1 info0 #>      <int> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1        1   150 0.0507 0.0190  0.835  0.312  271.  269. #> 2        2   300 0.0507 0.0190  1.18   0.441  542.  539. #> 3        3   600 0.0507 0.0190  1.67   0.624 1083. 1078."},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_wlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Information and effect size for Weighted Log-rank test — gs_info_wlr","title":"Information and effect size for Weighted Log-rank test — gs_info_wlr","text":"Based piecewise enrollment rate, failure rate, dropout rates computes approximate information effect size using average hazard ratio model.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_wlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information and effect size for Weighted Log-rank test — gs_info_wlr","text":"","code":"gs_info_wlr(   enrollRates = tibble::tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6,     9)),   failRates = tibble::tibble(Stratum = \"All\", duration = c(3, 100), failRate =     log(2)/c(9, 18), hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   ratio = 1,   events = NULL,   analysisTimes = NULL,   weight = wlr_weight_fh,   approx = \"asymptotic\" )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_wlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information and effect size for Weighted Log-rank test — gs_info_wlr","text":"enrollRates enrollment rates failRates failure dropout rates ratio Experimental:Control randomization ratio events Targeted minimum events analysis analysisTimes Targeted minimum study duration analysis weight weight weighted log rank test \"1\"= unweighted, \"n\"= Gehan-Breslow, \"sqrtN\"= Tarone-Ware, \"FH_p[]_q[b]\"= Fleming-Harrington p=q=b approx approximate estimation method Z statistics \"event driven\" = work proportional hazard model log rank test \"asymptotic\"","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_wlr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information and effect size for Weighted Log-rank test — gs_info_wlr","text":"tibble columns Analysis, Time, N, Events, AHR, delta, sigma2, theta, info, info0. info, info0 contains statistical information H1, H0, respectively. analysis k, Time[k] maximum analysisTimes[k] expected time required accrue targeted events[k]. AHR expected average hazard ratio analysis.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_info_wlr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Information and effect size for Weighted Log-rank test — gs_info_wlr","text":"AHR() function computes statistical information targeted event times. tEvents() function used get events average HR targeted analysisTimes.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"Group sequential design power using average hazard ratio non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"","code":"gs_power_ahr(   enrollRates = tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)),   failRates = tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   events = c(30, 40, 50),   analysisTimes = NULL,   upper = gs_b,   upar = gsDesign(k = length(events), test.type = 1, n.I = events, maxn.IPlan =     max(events), sfu = sfLDOF, sfupar = NULL)$upper$bound,   lower = gs_b,   lpar = c(qnorm(0.1), rep(-Inf, 2)),   test_lower = TRUE,   test_upper = TRUE,   ratio = 1,   binding = FALSE,   info_scale = c(0, 1, 2),   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"enrollRates enrollment rates failRates failure dropout rates events Targeted events analysis analysisTimes Minimum time analysis upper Function compute upper bound upar Parameter passed upper() lower Function compute lower bound lpar Parameter passed lower() test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default) indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound ratio Experimental:Control randomization ratio (yet implemented) binding indicator whether futility bound binding; default FALSE recommended info_scale information scale calculation r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"tibble columns Analysis, Bound, Z, Probability, theta, Time, AHR, Events. Contains row analysis bound.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"Bound satisfy input upper bound specification upper, upar lower bound specification lower, lpar. AHR() function computes statistical information targeted event times. tEvents() function used get events average HR targeted analysisTimes.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_ahr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design power using average hazard ratio under non-proportional hazards — gs_power_ahr","text":"","code":"library(gsDesign2) library(dplyr)  # -------------------------# #       example 1          # # ------------------------ # # The default output of \\code{gs_power_ahr} is driven by events, i.e., # \\code{events = c(30, 40, 50), analysisTimes = NULL} gs_power_ahr()  #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2     3 #> 2 All            2     6 #> 3 All           10     9 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper      0.0231      0.00381    2.67          0.374     0.00381 #> 2        1 Lower      0.0273      0.100     -1.28          1.60      0.9     #> 3        2 Upper      0.0897      0.0122     2.29          0.481     0.0110  #> 4        2 Lower      0.0273      0.100   -Inf           Inf         1       #> 5        3 Upper      0.207       0.0250     2.03          0.559     0.0211  #> 6        3 Lower      0.0273      0.100   -Inf           Inf         1       #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis  Time     N Events   AHR theta  info info0    IF   IF0 #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  14.9   108   30.0 0.787 0.240  7.37  7.50 0.603 0.600 #> 2        2  19.2   108   40.0 0.744 0.295  9.79 10.0  0.801 0.800 #> 3        3  24.5   108   50.0 0.713 0.339 12.2  12.5  1     1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # -------------------------# #       example 2          # # -------------------------# # 2-sided symmetric O'Brien-Fleming spending bound,  # driven by analysis time, i.e., \\code{events = NULL, analysisTimes = c(12, 24, 36)} gs_power_ahr(   analysisTimes = c(12, 24, 36),   events = NULL,   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL))  #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2     3 #> 2 All            2     6 #> 3 All           10     9 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper   0.000370     0.0000538  3.87           0.178   0.0000538 #> 2        1 Lower   0.0000612    0.0000538 -3.40           4.55    1.00      #> 3        2 Upper   0.116        0.00921    2.36           0.506   0.00919   #> 4        2 Lower   0.00907      0.00921   -1.20           1.42    0.885     #> 5        3 Upper   0.324        0.0250     2.01           0.608   0.0222    #> 6        3 Lower   0.0250       0.0250    -0.473          1.12    0.682     #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis  Time     N Events   AHR theta  info info0    IF   IF0 #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    12    90   20.4 0.811 0.210  5.03  5.10 0.309 0.308 #> 2        2    24   108   49.1 0.715 0.335 12.0  12.3  0.738 0.741 #> 3        3    36   108   66.2 0.683 0.381 16.3  16.6  1     1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # -------------------------# #       example 3          # # -------------------------# # 2-sided symmetric O'Brien-Fleming spending bound, # driven by events, i.e., \\code{events = c(20, 50, 70), analysisTimes = NULL} gs_power_ahr(   analysisTimes = NULL,   events = c(20, 50, 70),   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2     3 #> 2 All            2     6 #> 3 All           10     9 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper   0.000198     0.0000275  4.03           0.163   0.0000275 #> 2        1 Lower   0.0000312    0.0000275 -3.57           4.98    1.00      #> 3        2 Upper   0.110        0.00800    2.41           0.502   0.00799   #> 4        2 Lower   0.00782      0.00800   -1.23           1.42    0.891     #> 5        3 Upper   0.352        0.0250     2.00           0.617   0.0226    #> 6        3 Lower   0.0250       0.0250    -0.393          1.10    0.653     #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis  Time     N Events   AHR theta  info info0    IF   IF0 #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  11.9  88.8   20.0 0.812 0.208  4.93  5.00 0.286 0.286 #> 2        2  24.5 108     50.0 0.713 0.339 12.2  12.5  0.710 0.714 #> 3        3  39.4 108     70.0 0.679 0.388 17.2  17.5  1     1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\"       # -------------------------# #       example 4          # # -------------------------# # 2-sided symmetric O'Brien-Fleming spending bound, # driven by both `events` and `analysisTimes`, i.e., # both `events` and `analysisTimes` are not `NULL`, # then the analysis will driven by the maximal one, i.e., # Time = max(analysisTime, calculated Time for targeted events) # Events = max(events, calculated events for targeted analysisTime) gs_power_ahr(   analysisTimes = c(12, 24, 36),   events = c(30, 40, 50),   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)) #> $enrollRates #> # A tibble: 3 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All            2     3 #> 2 All            2     6 #> 3 All           10     9 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            3   0.0770   0.9       0.001 #> 2 All          100   0.0385   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper    0.00706      0.000867  3.13           0.316    0.000867 #> 2        1 Lower    0.000935     0.000867 -2.48           2.49     0.993    #> 3        2 Upper    0.115        0.00921   2.37           0.505    0.00892  #> 4        2 Lower    0.00912      0.00921  -1.21           1.42     0.888    #> 5        3 Upper    0.324        0.0250    2.01           0.607    0.0222   #> 6        3 Lower    0.0251       0.0250   -0.474          1.12     0.682    #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis  Time     N Events   AHR theta  info info0    IF   IF0 #>      <int> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1  14.9   108   30.0 0.787 0.240  7.37  7.50 0.453 0.453 #> 2        2  24     108   49.1 0.715 0.335 12.0  12.3  0.738 0.741 #> 3        3  36     108   66.2 0.683 0.381 16.3  16.6  1     1     #>  #> attr(,\"class\") #> [1] \"ahr\"       \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_combo.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design power using MaxCombo test under non-proportional hazards — gs_power_combo","title":"Group sequential design power using MaxCombo test under non-proportional hazards — gs_power_combo","text":"Group sequential design power using MaxCombo test non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_combo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design power using MaxCombo test under non-proportional hazards — gs_power_combo","text":"","code":"gs_power_combo(   enrollRates = tibble(Stratum = \"All\", duration = 12, rate = 500/12),   failRates = tibble(Stratum = \"All\", duration = c(4, 100), failRate = log(2)/15, hr =     c(1, 0.6), dropoutRate = 0.001),   fh_test = rbind(data.frame(rho = 0, gamma = 0, tau = -1, test = 1, Analysis = 1:3,     analysisTimes = c(12, 24, 36)), data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1,     test = 2:3, Analysis = 3, analysisTimes = 36)),   ratio = 1,   binding = FALSE,   upper = gs_b,   upar = c(3, 2, 1),   lower = gs_b,   lpar = c(-1, 0, 1),   algorithm = GenzBretz(maxpts = 1e+05, abseps = 1e-05),   ... )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_combo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design power using MaxCombo test under non-proportional hazards — gs_power_combo","text":"enrollRates enrollment rates failRates failure dropout rates fh_test data frame summarize test analysis. Refer examples data structure. ratio Experimental:Control randomization ratio (yet implemented) binding indicator whether futility bound binding; default FALSE recommended upper Function compute upper bound upar Parameter passed upper() lower Function compute lower bound lpar Parameter passed lower() algorithm object class GenzBretz,                     Miwa TVPACK                     specifying algorithm used well                     associated hyper parameters. ... additional parameters transfer mvtnorm::pmvnorm","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_combo.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential design power using MaxCombo test under non-proportional hazards — gs_power_combo","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_combo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design power using MaxCombo test under non-proportional hazards — gs_power_combo","text":"","code":"library(dplyr) library(mvtnorm) library(gsDesign) library(gsDesign2) library(tibble)  enrollRates <- tibble(   Stratum = \"All\",    duration = 12,    rate = 500/12)  failRates <- tibble(   Stratum = \"All\",   duration = c(4, 100),   failRate = log(2) / 15,  # median survival 15 month   hr = c(1, .6),   dropoutRate = 0.001)  fh_test <- rbind(   data.frame(rho = 0, gamma = 0, tau = -1, test = 1, Analysis = 1:3, analysisTimes = c(12, 24, 36)),   data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1, test = 2:3, Analysis = 3, analysisTimes = 36) )  # -------------------------# #       example 1          # # ------------------------ # # Minimal Information Fraction derived bound gs_power_combo(   enrollRates,    failRates,    fh_test,   upper = gs_spending_combo,   upar  = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_combo,   lpar  = list(sf = gsDesign::sfLDOF, total_spend = 0.2)) #> The AHR reported in the `analysis` table is under the log-rank test. #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #>   Analysis Bound  Probability Probability0         Z    Nominal p #> 1        1 Upper 6.329275e-08 3.299865e-10  6.175397 3.299865e-10 #> 2        1 Lower 3.269613e-04 0.000000e+00 -2.516527 9.940741e-01 #> 3        2 Upper 4.260145e-01 2.565830e-03  2.798651 2.565830e-03 #> 4        2 Lower 8.468664e-02 0.000000e+00  1.237721 1.079098e-01 #> 5        3 Upper 9.016101e-01 2.498202e-02  2.097189 1.798842e-02 #> 6        3 Lower 9.838738e-02 0.000000e+00  2.097189 1.798842e-02 #>  #> $analysis #>   Analysis Time        N   Events        EF       AHR #> 1        1   12 500.0001 107.3943 0.3241690 0.8418858 #> 2        2   24 500.0001 246.2834 0.7434051 0.7164215 #> 3        3   36 500.0001 331.2910 1.0000000 0.6831740 #>  #> attr(,\"class\") #> [1] \"combo\"     \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_npe.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential bound computation with non-constant effect — gs_power_npe","title":"Group sequential bound computation with non-constant effect — gs_power_npe","text":"gs_power_npe() derives group sequential bounds boundary crossing probabilities design. allows non-constant treatment effect time, also can applied usual homogeneous effect size designs. requires treatment effect statistical information analysis well method deriving bounds, spending. routine enables two things available gsDesign package: 1) non-constant effect, 2) flexibility boundary selection. many applications, non-proportional-hazards design function gs_design_nph() used; calls function. Initial bound types supported 1) spending bounds, 2) fixed bounds, 3) Haybittle-Peto-like bounds. requirement boundary update method can bound without knowledge future bounds. example, bounds based conditional power require knowledge future bounds supported routine; limited conditional power method demonstrated. Boundary family designs Wang-Tsiatis designs including original (non-spending-function-based) O'Brien-Fleming Pocock designs supported gs_power_npe().","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_npe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential bound computation with non-constant effect — gs_power_npe","text":"","code":"gs_power_npe(   theta = 0.1,   theta0 = NULL,   theta1 = NULL,   info = 1,   info0 = NULL,   info1 = NULL,   info_scale = c(0, 1, 2),   upper = gs_b,   upar = qnorm(0.975),   lower = gs_b,   lpar = -Inf,   test_upper = TRUE,   test_lower = TRUE,   binding = FALSE,   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_npe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential bound computation with non-constant effect — gs_power_npe","text":"theta natural parameter group sequential design representing expected incremental drift analyses; used power calculation theta0 natural parameter null hypothesis, needed upper bound computation theta1 natural parameter alternate hypothesis, needed lower bound computation info statistical information analyses input theta info0 statistical information null hypothesis, different info; impacts null hypothesis bound calculation info1 statistical information hypothesis used futility bound calculation different info; impacts futility hypothesis bound calculation info_scale information scale calculation, default 2, options 0 1. upper function compute upper bound upar parameter pass upper lower function compare lower bound lpar parameter pass lower test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default)  indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound binding indicator whether futility bound binding; default FALSE recommended r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_npe.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential bound computation with non-constant effect — gs_power_npe","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_npe.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Group sequential bound computation with non-constant effect — gs_power_npe","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_npe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential bound computation with non-constant effect — gs_power_npe","text":"","code":"library(gsDesign) library(gsDesign2) library(dplyr)  # Default (single analysis; Type I error controlled) gs_power_npe(theta = 0) %>% filter(Bound == \"Upper\") #> # A tibble: 1 × 10 #>   Analysis Bound     Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  1.96      0.0250     0      0     1     1     1     1  # Fixed bound gs_power_npe(   theta = c(.1, .2, .3),    info = (1:3) * 40,    upper = gs_b,    upar = gsDesign::gsDesign(k = 3,sfu = gsDesign::sfLDOF)$upper$bound,   lower = gs_b,    lpar =  c(-1, 0, 0)) #> # A tibble: 6 × 10 #>   Analysis Bound     Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71     0.00104   0.1    0.1 0.333    40    40    40 #> 2        2 Upper  2.51     0.235     0.2    0.2 0.667    80    80    80 #> 3        3 Upper  1.99     0.869     0.3    0.3 1       120   120   120 #> 4        1 Lower -1        0.0513    0.1    0.1 0.333    40    40    40 #> 5        2 Lower  0        0.0715    0.2    0.2 0.667    80    80    80 #> 6        3 Lower  0        0.0715    0.3    0.3 1       120   120   120  # Same fixed efficacy bounds, no futility bound (i.e., non-binding bound), null hypothesis gs_power_npe(   theta = rep(0, 3),    info = (1:3) * 40,   upar = gsDesign::gsDesign(k = 3,sfu = gsDesign::sfLDOF)$upper$bound,   lpar = rep(-Inf, 3)) %>%    filter(Bound == \"Upper\") #> # A tibble: 3 × 10 #>   Analysis Bound     Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71    0.000104     0      0 0.333    40    40    40 #> 2        2 Upper  2.51    0.00605      0      0 0.667    80    80    80 #> 3        3 Upper  1.99    0.0250       0      0 1       120   120   120  # Fixed bound with futility only at analysis 1; efficacy only at analyses 2, 3 gs_power_npe(   theta = c(.1, .2, .3),    info = (1:3) * 40,   upper = gs_b,   upar = c(Inf, 3, 2),    lower = gs_b,   lpar = c(qnorm(.1), -Inf, -Inf)) #> # A tibble: 6 × 10 #>   Analysis Bound       Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr>   <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  Inf         0        0.1    0.1 0.333    40    40    40 #> 2        2 Upper    3         0.113    0.2    0.2 0.667    80    80    80 #> 3        3 Upper    2         0.887    0.3    0.3 1       120   120   120 #> 4        1 Lower   -1.28      0.0278   0.1    0.1 0.333    40    40    40 #> 5        2 Lower -Inf         0.0278   0.2    0.2 0.667    80    80    80 #> 6        3 Lower -Inf         0.0278   0.3    0.3 1       120   120   120  # Spending function bounds # Lower spending based on non-zero effect gs_power_npe(   theta = c(.1, .2, .3),    info = (1:3) * 40,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfHSD, total_spend = 0.1, param = -1, timing = NULL)) #> # A tibble: 6 × 10 #>   Analysis Bound       Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr>   <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71       0.00104   0.1    0.1 0.333    40    40    40 #> 2        2 Upper  2.51       0.235     0.2    0.2 0.667    80    80    80 #> 3        3 Upper  1.99       0.883     0.3    0.3 1       120   120   120 #> 4        1 Lower -1.36       0.0230    0.1    0.1 0.333    40    40    40 #> 5        2 Lower  0.0726     0.0552    0.2    0.2 0.667    80    80    80 #> 6        3 Lower  1.86       0.100     0.3    0.3 1       120   120   120  # Same bounds, but power under different theta gs_power_npe(   theta = c(.15, .25, .35),    info = (1:3) * 40,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfHSD, total_spend = 0.1, param = -1, timing = NULL)) #> # A tibble: 6 × 10 #>   Analysis Bound      Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr>  <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71      0.00288  0.15   0.15 0.333    40    40    40 #> 2        2 Upper  2.51      0.391    0.25   0.25 0.667    80    80    80 #> 3        3 Upper  1.99      0.931    0.35   0.35 1       120   120   120 #> 4        1 Lower -1.05      0.0230   0.15   0.15 0.333    40    40    40 #> 5        2 Lower  0.520     0.0552   0.25   0.25 0.667    80    80    80 #> 6        3 Lower  2.41      0.100    0.35   0.35 1       120   120   120  # Two-sided symmetric spend, O'Brien-Fleming spending # Typically, 2-sided bounds are binding x <- gs_power_npe(   theta = rep(0, 3),    info = (1:3) * 40,   binding = TRUE,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL))  # Re-use these bounds under alternate hypothesis # Always use binding = TRUE for power calculations gs_power_npe(   theta = c(.1, .2, .3),   info = (1:3) * 40,   binding = TRUE,   upar = (x %>% filter(Bound == \"Upper\"))$Z,   lpar = -(x %>% filter(Bound == \"Upper\"))$Z) #> # A tibble: 6 × 10 #>   Analysis Bound     Z Probability theta theta1    IF  info info0 info1 #>      <int> <chr> <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1 Upper  3.71  0.00104      0.1    0.1 0.333    40    40    40 #> 2        2 Upper  2.51  0.235        0.2    0.2 0.667    80    80    80 #> 3        3 Upper  1.99  0.902        0.3    0.3 1       120   120   120 #> 4        1 Lower -3.71  0.00000704   0.1    0.1 0.333    40    40    40 #> 5        2 Lower -2.51  0.0000151    0.2    0.2 0.667    80    80    80 #> 6        3 Lower -1.99  0.0000151    0.3    0.3 1       120   120   120"},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_rd.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design power under risk difference — gs_power_rd","title":"Group sequential design power under risk difference — gs_power_rd","text":"Group sequential design power risk difference","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_rd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design power under risk difference — gs_power_rd","text":"","code":"gs_power_rd(   p_c = tibble::tibble(Stratum = \"All\", Rate = 0.2),   p_e = tibble::tibble(Stratum = \"All\", Rate = 0.15),   N = tibble::tibble(Stratum = \"All\", N = c(40, 50, 60), Analysis = 1:3),   rd0 = 0,   ratio = 1,   weight = c(\"un-stratified\", \"ss\", \"invar\"),   upper = gs_b,   lower = gs_b,   upar = list(par = gsDesign(k = length(N), test.type = 1, sfu = sfLDOF, sfupar =     NULL)$upper$bound),   lpar = list(par = c(qnorm(0.1), rep(-Inf, length(N) - 1))),   info_scale = c(0, 1, 2),   binding = FALSE,   test_upper = TRUE,   test_lower = TRUE,   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_rd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design power under risk difference — gs_power_rd","text":"p_c rate control group p_e rate experimental group N sample size rd0 treatment effect super-superiority designs, default 0 ratio experimental:control randomization ratio weight weigting method, either \"un-stratified\" \"ss\" \"invar\" upper function compute upper bound lower function compare lower bound upar parameter pass upper lpar parameter pass lower info_scale information scale calculation binding indicator whether futility bound binding; default FALSE recommended test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default)  indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_rd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Group sequential design power under risk difference — gs_power_rd","text":"tibble columns Analysis, Bound, Z, Probability, theta, Time, AHR, Events","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_rd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design power under risk difference — gs_power_rd","text":"","code":"# --------------------- # #      example 1        # # --------------------- # library(gsDesign)  # un-stratified case with H0: rd0 = 0 gs_power_rd(   p_c = tibble::tibble(Stratum = \"All\",                        Rate = .2),   p_e = tibble::tibble(Stratum = \"All\",                        Rate = .15),   N = tibble::tibble(Stratum = \"All\",                      N = c(20, 40, 60),                      Analysis = 1:3),   rd0 = 0,   ratio = 1,   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)) ) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000309     0.000104    3.71                  0.629 1.04e-4 #> 2        2 Upper    0.0182       0.00605     2.51                  0.301 6.01e-3 #> 3        3 Upper    0.0728       0.0250      1.99                  0.195 2.31e-2 #> 4        1 Lower    0.0571       0.100      -1.28                 -0.217 9   e-1 #> 5        2 Lower    0.0571       0.100    -Inf                  -Inf     1   e+0 #> 6        3 Lower    0.0571       0.100    -Inf                  -Inf     1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N    rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    20  0.05     0  0.295      0  34.8  34.6 0.333 0.333 #> 2        2    40  0.05     0  0.417      0  69.6  69.3 0.667 0.667 #> 3        3    60  0.05     0  0.511      0 104.  104.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"       # --------------------- # #      example 2        # # --------------------- # # un-stratified case with H0: rd0 != 0 gs_power_rd(   p_c = tibble::tibble(Stratum = \"All\",                        Rate = .2),   p_e = tibble::tibble(Stratum = \"All\",                        Rate = .15),   N = tibble::tibble(Stratum = \"All\",                      N = c(20, 40, 60),                      Analysis = 1:3),   rd0 = 0.005,   ratio = 1,   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)) ) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000309     0.000116    3.71                  0.571 1.04e-4 #> 2        2 Upper    0.0182       0.00680     2.51                  0.276 6.01e-3 #> 3        3 Upper    0.0728       0.0281      1.99                  0.181 2.31e-2 #> 4        1 Lower    0.0571       0.0949     -1.28                 -0.191 9   e-1 #> 5        2 Lower    0.0571       0.0949   -Inf                  -Inf     1   e+0 #> 6        3 Lower    0.0571       0.0949   -Inf                  -Inf     1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N    rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    20  0.05 0.005  0.295 0.0294  34.8  34.6 0.333 0.333 #> 2        2    40  0.05 0.005  0.417 0.0416  69.6  69.3 0.667 0.667 #> 3        3    60  0.05 0.005  0.511 0.0510 104.  104.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"       # use spending function gs_power_rd(   p_c = tibble::tibble(Stratum = \"All\",                        Rate = .2),   p_e = tibble::tibble(Stratum = \"All\",                        Rate = .15),   N = tibble::tibble(Stratum = \"All\",                      N = c(20, 40, 60),                      Analysis = 1:3),   rd0 = 0.005,   ratio = 1,   upper = gs_spending_bound,   lower = gs_b,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL),   lpar = c(qnorm(.1), rep(-Inf, 2)) ) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000309     0.000116    3.71                  0.571 1.04e-4 #> 2        2 Upper    0.0182       0.00680     2.51                  0.276 6.01e-3 #> 3        3 Upper    0.0728       0.0281      1.99                  0.181 2.31e-2 #> 4        1 Lower    0.0571       0.0949     -1.28                 -0.191 9   e-1 #> 5        2 Lower    0.0571       0.0949   -Inf                  -Inf     1   e+0 #> 6        3 Lower    0.0571       0.0949   -Inf                  -Inf     1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N    rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    20  0.05 0.005  0.295 0.0294  34.8  34.6 0.333 0.333 #> 2        2    40  0.05 0.005  0.417 0.0416  69.6  69.3 0.667 0.667 #> 3        3    60  0.05 0.005  0.511 0.0510 104.  104.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"       # --------------------- # #      example 3        # # --------------------- # # stratified case under sample size weighting and H0: rd0 = 0 gs_power_rd(   p_c = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.15, .2, .25)),   p_e = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.1, .16, .19)),   N = tibble::tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),                      Analysis = rep(1:3, 3),                      N = c(10, 20, 24, 18, 26, 30, 10, 20, 24)),   rd0 = 0,   ratio = 1,   weight = \"ss\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000437     0.000104    3.71                  0.456 1.04e-4 #> 2        2 Upper    0.0237       0.00604     2.51                  0.228 6.01e-3 #> 3        3 Upper    0.0795       0.0237      1.99                  0.166 2.31e-2 #> 4        1 Lower    0.0470       0.100      -1.28                 -0.157 9   e-1 #> 5        2 Lower    0.0470       0.100    -Inf                  -Inf     1   e+0 #> 6        3 Lower    0.0470       0.100    -Inf                  -Inf     1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N     rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    38 0.0479     0  0.390      0  66.3  66.0 0.485 0.485 #> 2        2    66 0.0491     0  0.528      0 116.  115.  0.846 0.846 #> 3        3    78 0.0492     0  0.576      0 137.  136.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"       # --------------------- # #      example 4        # # --------------------- # # stratified case under inverse variance weighting and H0: rd0 = 0 gs_power_rd(   p_c = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.15, .2, .25)),   p_e = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.1, .16, .19)),   N = tibble::tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),                      Analysis = rep(1:3, 3),                      N = c(10, 20, 24, 18, 26, 30, 10, 20, 24)),   rd0 = 0,   ratio = 1,   weight = \"invar\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000443     0.000104    3.71                  0.449 1.04e-4 #> 2        2 Upper    0.0240       0.00604     2.51                  0.225 6.01e-3 #> 3        3 Upper    0.0803       0.0237      1.99                  0.164 2.31e-2 #> 4        1 Lower    0.0467       0.100      -1.28                 -0.155 9   e-1 #> 5        2 Lower    0.0467       0.100    -Inf                  -Inf     1   e+0 #> 6        3 Lower    0.0467       0.100    -Inf                  -Inf     1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N     rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    38 0.0477     0  0.394      0  68.2  67.9 0.483 0.483 #> 2        2    66 0.0487     0  0.533      0 119.  119.  0.845 0.845 #> 3        3    78 0.0489     0  0.581      0 141.  141.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"       # --------------------- # #      example 5        # # --------------------- # # stratified case under sample size weighting and H0: rd0 != 0 gs_power_rd(   p_c = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.15, .2, .25)),   p_e = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.1, .16, .19)),   N = tibble::tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),                      Analysis = rep(1:3, 3),                      N = c(10, 20, 24, 18, 26, 30, 10, 20, 24)),   rd0 = 0.02,   ratio = 1,   weight = \"ss\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000437     0.000194    3.71                 0.285  1.04e-4 #> 2        2 Upper    0.0237       0.0109      2.51                 0.153  6.01e-3 #> 3        3 Upper    0.0795       0.0401      1.99                 0.117  2.31e-2 #> 4        1 Lower    0.0470       0.0744     -1.28                -0.0717 9   e-1 #> 5        2 Lower    0.0470       0.0744   -Inf                 -Inf      1   e+0 #> 6        3 Lower    0.0470       0.0744   -Inf                 -Inf      1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N     rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    38 0.0479  0.02  0.390  0.163  66.3  66.0 0.485 0.485 #> 2        2    66 0.0491  0.02  0.528  0.215 116.  115.  0.846 0.846 #> 3        3    78 0.0492  0.02  0.576  0.233 137.  136.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\"       # --------------------- # #      example 6        # # --------------------- # # stratified case under inverse variance weighting and H0: rd0 != 0 gs_power_rd(   p_c = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.15, .2, .25)),   p_e = tibble::tibble(Stratum = c(\"S1\", \"S2\", \"S3\"),                        Rate = c(.1, .16, .19)),   N = tibble::tibble(Stratum = rep(c(\"S1\", \"S2\", \"S3\"), each = 3),                      Analysis = rep(1:3, 3),                      N = c(10, 20, 24, 18, 26, 30, 10, 20, 24)),   rd0 = 0.03,   ratio = 1,   weight = \"invar\",   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, sfu = sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z ~Risk difference at …¹ Nomin…² #>      <int> <chr>       <dbl>        <dbl>   <dbl>                  <dbl>   <dbl> #> 1        1 Upper    0.000443     0.000267    3.71                 0.196  1.04e-4 #> 2        2 Upper    0.0240       0.0145      2.51                 0.113  6.01e-3 #> 3        3 Upper    0.0803       0.0518      1.99                 0.0906 2.31e-2 #> 4        1 Lower    0.0467       0.0632     -1.28                -0.0275 9   e-1 #> 5        2 Lower    0.0467       0.0632   -Inf                 -Inf      1   e+0 #> 6        3 Lower    0.0467       0.0632   -Inf                 -Inf      1   e+0 #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p` #>  #> $analysis #> # A tibble: 3 × 10 #>   Analysis     N     rd   rd0 theta1 theta0  info info0    IF   IF0 #>      <int> <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1        1    38 0.0477  0.03  0.394  0.247  68.2  67.9 0.483 0.483 #> 2        2    66 0.0487  0.03  0.533  0.327 119.  119.  0.845 0.845 #> 3        3    78 0.0489  0.03  0.581  0.356 141.  141.  1     1     #>  #> attr(,\"class\") #> [1] \"rd\"        \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_wlr.html","id":null,"dir":"Reference","previous_headings":"","what":"Group sequential design power using weighted log rank test under non-proportional hazards — gs_power_wlr","title":"Group sequential design power using weighted log rank test under non-proportional hazards — gs_power_wlr","text":"Group sequential design power using weighted log rank test non-proportional hazards","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_wlr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group sequential design power using weighted log rank test under non-proportional hazards — gs_power_wlr","text":"","code":"gs_power_wlr(   enrollRates = tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)),   failRates = tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2)/c(9, 18),     hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   events = c(30, 40, 50),   analysisTimes = NULL,   binding = FALSE,   upper = gs_b,   lower = gs_b,   upar = gsDesign(k = 3, test.type = 1, n.I = c(30, 40, 50), maxn.IPlan = 50, sfu =     sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(0.1), rep(-Inf, 2)),   test_upper = TRUE,   test_lower = TRUE,   ratio = 1,   weight = wlr_weight_fh,   info_scale = c(0, 1, 2),   approx = \"asymptotic\",   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_wlr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group sequential design power using weighted log rank test under non-proportional hazards — gs_power_wlr","text":"enrollRates enrollment rates failRates failure dropout rates events Targeted events analysis analysisTimes Minimum time analysis binding indicator whether futility bound binding; default FALSE recommended upper Function compute upper bound lower Function compute lower bound upar Parameter passed upper() lpar Parameter passed lower() test_upper indicator analyses include upper (efficacy) bound; single value TRUE (default) indicates analyses; otherwise, logical vector length info indicate analyses efficacy bound test_lower indicator analyses include lower bound; single value TRUE (default) indicates analyses; single value FALSE indicated lower bound; otherwise, logical vector length info indicate analyses lower bound ratio Experimental:Control randomization ratio (yet implemented) weight weight weighted log rank test \"1\"= unweighted, \"n\"= Gehan-Breslow, \"sqrtN\"= Tarone-Ware, \"FH_p[]_q[b]\"= Fleming-Harrington p=q=b info_scale information scale calculation approx approximate estimation method Z statistics \"event driven\" = work proportional hazard model log rank test \"asymptotic\" r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter boundary convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_wlr.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Group sequential design power using weighted log rank test under non-proportional hazards — gs_power_wlr","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_power_wlr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Group sequential design power using weighted log rank test under non-proportional hazards — gs_power_wlr","text":"","code":"library(tibble) library(gsDesign) library(gsDesign2)  # set enrollment rates enrollRates <- tibble(Stratum = \"All\", duration = 12, rate = 500/12)  # set failure rates failRates <- tibble(   Stratum = \"All\",   duration = c(4, 100),   failRate = log(2) / 15,  # median survival 15 month   hr = c(1, .6),   dropoutRate = 0.001)    # set the targeted number of events and analysis time target_events <- c(30, 40, 50) target_analysisTime <- c(10, 24, 30)  # -------------------------# #       example 1          # # ------------------------ # # fixed bounds and calculate the power for targeted number of events gs_power_wlr(   enrollRates = enrollRates,   failRates = failRates,   events = target_events,   analysisTimes = NULL,   upper = gs_b,   upar = gsDesign(k = length(target_events), test.type = 1, n.I = target_events, maxn.IPlan = max(target_events), sfu = sfLDOF, sfupar = NULL)$upper$bound,   lower = gs_b,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper     0.00470      0.00381    2.67          0.377     0.00381 #> 2        1 Lower     0.0881       0.100     -1.28          1.60      0.9     #> 3        2 Upper     0.0182       0.0127     2.29          0.485     0.0110  #> 4        2 Lower     0.0881       0.100   -Inf           Inf         1       #> 5        3 Upper     0.0439       0.0268     2.03          0.563     0.0211  #> 6        3 Lower     0.0881       0.100   -Inf           Inf         1       #>  #> $analysis #>   Analysis     Time        N   Events       AHR      theta     info    info0 #> 1        1 5.893973 245.5822 30.00022 0.9636346 0.03704306 3.683843 3.684245 #> 2        2 6.900914 287.5381 39.99994 0.9373448 0.06470406 5.749098 5.750773 #> 3        3 7.808461 325.3525 50.00009 0.9155821 0.08819526 8.132517 8.136765 #>          IF       IF0 #> 1 0.4529769 0.4527898 #> 2 0.7069273 0.7067640 #> 3 1.0000000 1.0000000 #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\"         # -------------------------# #       example 2          # # ------------------------ # # fixed bounds and calculate the power for targeted analysis time gs_power_wlr(   enrollRates = enrollRates,   failRates = failRates,   events = NULL,   analysisTimes = target_analysisTime,   upper = gs_b,   upar = gsDesign(k = length(target_events), test.type = 1, n.I = target_events, maxn.IPlan = max(target_events), sfu = sfLDOF, sfupar = NULL)$upper$bound,   lower = gs_b,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper      0.0172      0.00381    2.67          0.546     0.00381 #> 2        1 Lower      0.0335      0.100     -1.28          1.34      0.9     #> 3        2 Upper      0.622       0.0141     2.29          0.747     0.0110  #> 4        2 Lower      0.0335      0.100   -Inf           Inf         1       #> 5        3 Upper      0.842       0.0263     2.03          0.789     0.0211  #> 6        3 Lower      0.0335      0.100   -Inf           Inf         1       #>  #> $analysis #>   Analysis Time        N    Events       AHR     theta     info    info0 #> 1        1   10 416.6667  77.80361 0.8720599 0.1368971 16.20843 16.22923 #> 2        2   24 500.0000 246.28341 0.7164215 0.3334865 61.35217 62.08666 #> 3        3   30 500.0000 293.69568 0.6955693 0.3630247 72.91885 74.25144 #>          IF       IF0 #> 1 0.2222803 0.2185712 #> 2 0.8413760 0.8361677 #> 3 1.0000000 1.0000000 #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\"       # -------------------------# #       example 3          # # ------------------------ # # fixed bounds and calculate the power for targeted analysis time & number of events gs_power_wlr(   enrollRates = enrollRates,   failRates = failRates,   events = target_events,   analysisTimes = target_analysisTime,   upper = gs_b,   upar = gsDesign(k = length(target_events), test.type = 1, n.I = target_events, maxn.IPlan = max(target_events), sfu = sfLDOF, sfupar = NULL)$upper$bound,   lower = gs_b,   lpar = c(qnorm(.1), rep(-Inf, 2))) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0       Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>   <dbl>          <dbl>       <dbl> #> 1        1 Upper      0.0172      0.00381    2.67          0.546     0.00381 #> 2        1 Lower      0.0335      0.100     -1.28          1.34      0.9     #> 3        2 Upper      0.622       0.0141     2.29          0.747     0.0110  #> 4        2 Lower      0.0335      0.100   -Inf           Inf         1       #> 5        3 Upper      0.842       0.0263     2.03          0.789     0.0211  #> 6        3 Lower      0.0335      0.100   -Inf           Inf         1       #>  #> $analysis #>   Analysis Time        N    Events       AHR     theta     info    info0 #> 1        1   10 416.6667  77.80361 0.8720599 0.1368971 16.20843 16.22923 #> 2        2   24 500.0000 246.28341 0.7164215 0.3334865 61.35217 62.08666 #> 3        3   30 500.0000 293.69568 0.6955693 0.3630247 72.91885 74.25144 #>          IF       IF0 #> 1 0.2222803 0.2185712 #> 2 0.8413760 0.8361677 #> 3 1.0000000 1.0000000 #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\"         # -------------------------# #       example 4          # # ------------------------ # # spending bounds and calculate the power for targeted number of events gs_power_wlr(   enrollRates = enrollRates,   failRates = failRates,   events = target_events,   analysisTimes = NULL,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.2)) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper     0.00110     0.000865  3.13           0.319    0.000865 #> 2        1 Lower     0.0569      0.0568   -1.58           1.78     0.943    #> 3        2 Upper     0.0115      0.00767   2.44           0.463    0.00739  #> 4        2 Lower     0.127       0.127    -1.22           1.47     0.889    #> 5        3 Upper     0.0427      0.0250    2.00           0.568    0.0226   #> 6        3 Lower     0.200       0.2      -0.990          1.32     0.839    #>  #> $analysis #>   Analysis     Time        N   Events       AHR      theta     info    info0 #> 1        1 5.893973 245.5822 30.00022 0.9636346 0.03704306 3.683843 3.684245 #> 2        2 6.900914 287.5381 39.99994 0.9373448 0.06470406 5.749098 5.750773 #> 3        3 7.808461 325.3525 50.00009 0.9155821 0.08819526 8.132517 8.136765 #>          IF       IF0 #> 1 0.4529769 0.4527898 #> 2 0.7069273 0.7067640 #> 3 1.0000000 1.0000000 #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\"         # -------------------------# #       example 5          # # ------------------------ # # spending bounds and calculate the power for targeted analysis time gs_power_wlr(   enrollRates = enrollRates,   failRates = failRates,   events = NULL,   analysisTimes = target_analysisTime,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.2)) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper   0.0000207   0.00000163  4.65           0.348  0.00000163 #> 2        1 Lower   0.00659     0.00612    -2.51           1.76   0.994      #> 3        2 Upper   0.663       0.0142      2.19           0.756  0.0142     #> 4        2 Lower   0.162       0.161      -0.998          1.14   0.841      #> 5        3 Upper   0.811       0.0250      2.04           0.789  0.0209     #> 6        3 Lower   0.200       0.2        -1.00           1.12   0.842      #>  #> $analysis #>   Analysis Time        N    Events       AHR     theta     info    info0 #> 1        1   10 416.6667  77.80361 0.8720599 0.1368971 16.20843 16.22923 #> 2        2   24 500.0000 246.28341 0.7164215 0.3334865 61.35217 62.08666 #> 3        3   30 500.0000 293.69568 0.6955693 0.3630247 72.91885 74.25144 #>          IF       IF0 #> 1 0.2222803 0.2185712 #> 2 0.8413760 0.8361677 #> 3 1.0000000 1.0000000 #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\"         # -------------------------# #       example 6          # # ------------------------ # # spending bounds and calculate the power for targeted analysis time & number of events gs_power_wlr(   enrollRates = enrollRates,   failRates = failRates,   events = target_events,   analysisTimes = target_analysisTime,   upper = gs_spending_bound,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_bound,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.2)) #> $enrollRates #> # A tibble: 1 × 3 #>   Stratum duration  rate #>   <chr>      <dbl> <dbl> #> 1 All           12  41.7 #>  #> $failRates #> # A tibble: 2 × 5 #>   Stratum duration failRate    hr dropoutRate #>   <chr>      <dbl>    <dbl> <dbl>       <dbl> #> 1 All            4   0.0462   1         0.001 #> 2 All          100   0.0462   0.6       0.001 #>  #> $bounds #> # A tibble: 6 × 7 #>   Analysis Bound Probability Probability0      Z `~HR at bound` `Nominal p` #>      <int> <chr>       <dbl>        <dbl>  <dbl>          <dbl>       <dbl> #> 1        1 Upper   0.0000207   0.00000163  4.65           0.348  0.00000163 #> 2        1 Lower   0.00659     0.00612    -2.51           1.76   0.994      #> 3        2 Upper   0.663       0.0142      2.19           0.756  0.0142     #> 4        2 Lower   0.162       0.161      -0.998          1.14   0.841      #> 5        3 Upper   0.811       0.0250      2.04           0.789  0.0209     #> 6        3 Lower   0.200       0.2        -1.00           1.12   0.842      #>  #> $analysis #>   Analysis Time        N    Events       AHR     theta     info    info0 #> 1        1   10 416.6667  77.80361 0.8720599 0.1368971 16.20843 16.22923 #> 2        2   24 500.0000 246.28341 0.7164215 0.3334865 61.35217 62.08666 #> 3        3   30 500.0000 293.69568 0.6955693 0.3630247 72.91885 74.25144 #>          IF       IF0 #> 1 0.2222803 0.2185712 #> 2 0.8413760 0.8361677 #> 3 1.0000000 1.0000000 #>  #> attr(,\"class\") #> [1] \"wlr\"       \"gs_design\" \"list\""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive spending bound for group sequential boundary — gs_spending_bound","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"Computes one bound time based spending given distributional assumptions. user specifies gs_spending_bound() use functions, intended use . important user specifications made list provided functions using gs_spending_bound(). Function uses numerical integration Newton-Raphson iteration derive individual bound group sequential design satisfies targeted boundary crossing probability. Algorithm simple extension Chapter 19 Jennison Turnbull (2000).","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"","code":"gs_spending_bound(   k = 1,   par = list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL,     max_info = NULL),   hgm1 = NULL,   theta = 0.1,   info = 1:3,   efficacy = TRUE,   test_bound = TRUE,   r = 18,   tol = 1e-06 )"},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"k analysis bound computed par list following items: sf (class spending function), total_spend (total spend), param (parameters needed spending function sf()), timing (vector containing values spending function evaluated NULL information-based spending used), max_info (timing NULL, can input positive number used info information fraction analysis) hgm1 subdensity grid h1 (k=2) hupdate (k>2) analysis k-1; k=1, used may NULL theta natural parameter used lower bound spending; represents average drift time analysis least analysis k; upper bound spending always set null hypothesis (theta = 0) info statistical information analyses, least analysis k efficacy TRUE (default) efficacy bound, FALSE otherwise test_bound logical vector length info indicate analyses bound r Integer, least 2; default 18 recommended Jennison Turnbull tol Tolerance parameter convergence (Z-scale)","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"returns numeric bound (possibly infinite) , upon failure, generates error message.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"Jennison C Turnbull BW (2000), Group Sequential Methods Applications Clinical Trials. Boca Raton: Chapman Hall.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_bound.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Derive spending bound for group sequential boundary — gs_spending_bound","text":"Keaven Anderson keaven_anderson@merck.com","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_combo.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive spending bound for MaxCombo group sequential boundary — gs_spending_combo","title":"Derive spending bound for MaxCombo group sequential boundary — gs_spending_combo","text":"Derive spending bound MaxCombo group sequential boundary","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_combo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive spending bound for MaxCombo group sequential boundary — gs_spending_combo","text":"","code":"gs_spending_combo(par = NULL, info = NULL, ...)"},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_combo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive spending bound for MaxCombo group sequential boundary — gs_spending_combo","text":"par list following items: sf (class spending function), total_spend (total spend), param (parameters needed spending function sf()), timing (vector containing values spending function evaluated NULL information-based spending used), max_info (timing NULL, can input positive number used info information fraction analysis) info statistical information analyses, least analysis k ... additional parameters transfered par$sf.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/gs_spending_combo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Derive spending bound for MaxCombo group sequential boundary — gs_spending_combo","text":"","code":"# alpha-spending par <- list(sf = gsDesign::sfLDOF, total_spend = 0.025) gs_spending_combo(par, info = 1:3/3) #> [1] 0.0001035057 0.0060483891 0.0250000000  # beta-spending par <- list(sf = gsDesign::sfLDOF, total_spend = 0.2) gs_spending_combo(par, info = 1:3/3) #> [1] 0.02643829 0.11651432 0.20000000"},{"path":"https://merck.github.io/gsDesign2/reference/pmvnorm_combo.html","id":null,"dir":"Reference","previous_headings":"","what":"Multivariate Normal Distribution for Multivariate Maximum Statistics — pmvnorm_combo","title":"Multivariate Normal Distribution for Multivariate Maximum Statistics — pmvnorm_combo","text":"Computes distribution function multivariate normal distribution maximum statistics arbitrary limits correlation matrices","code":""},{"path":"https://merck.github.io/gsDesign2/reference/pmvnorm_combo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multivariate Normal Distribution for Multivariate Maximum Statistics — pmvnorm_combo","text":"","code":"pmvnorm_combo(   lower,   upper,   group,   mean,   corr,   algorithm = GenzBretz(maxpts = 1e+05, abseps = 1e-05),   ... )"},{"path":"https://merck.github.io/gsDesign2/reference/pmvnorm_combo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multivariate Normal Distribution for Multivariate Maximum Statistics — pmvnorm_combo","text":"lower vector lower limits length n. upper vector upper limits length n. group vector test statistics group. mean mean vector length n. corr correlation matrix dimension n. algorithm object class GenzBretz,                     Miwa TVPACK                     specifying algorithm used well                     associated hyper parameters. ... additional parameters transfer mvtnorm::pmvnorm","code":""},{"path":"https://merck.github.io/gsDesign2/reference/pmvnorm_combo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multivariate Normal Distribution for Multivariate Maximum Statistics — pmvnorm_combo","text":"Let $Z = Z_ij$ multivariate normal distribution. group indicator j within group statistics indicator. Let G_i = max(Z_ij) test within one group. program calculating probability $$Pr( lower < max(G) < upper )$$","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":null,"dir":"Reference","previous_headings":"","what":"Piecewise exponential cumulative distribution function — ppwe","title":"Piecewise exponential cumulative distribution function — ppwe","text":"ppwe computes cumulative distribution function (CDF) survival rate piecewise exponential distribution.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Piecewise exponential cumulative distribution function — ppwe","text":"","code":"ppwe(   x = 0:20,   failRates = tibble::tibble(duration = c(3, 100), rate = log(2)/c(9, 18)),   lower.tail = FALSE )"},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Piecewise exponential cumulative distribution function — ppwe","text":"x times distribution computed. failRates Piecewise constant failure rates rate, duration piecewise constant failure rate period. lower.tail Indicator whether lower (TRUE) upper tail (FALSE; default) CDF computed.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Piecewise exponential cumulative distribution function — ppwe","text":"vector cumulative distribution function survival values","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Piecewise exponential cumulative distribution function — ppwe","text":"Suppose \\(\\lambda_i\\) failure rate interval \\((t_{-1},t_i], =1,2,\\ldots,M\\) \\(0=t_0<t_i\\ldots,t_M=\\infty\\). cumulative hazard function arbitrary time \\(t>0\\) : $$\\Lambda(t)=\\sum_{=1}^M \\delta(t\\le t_i)(\\min(t,t_i)-t_{-1})\\lambda_i.$$ survival time \\(t\\) $$S(t)=\\exp(-\\Lambda(t)).$$","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Piecewise exponential cumulative distribution function — ppwe","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/reference/ppwe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Piecewise exponential cumulative distribution function — ppwe","text":"","code":"# Example: default ppwe(seq(0:10)) #>  [1] 0.9258747 0.8572440 0.7937005 0.7637176 0.7348672 0.7071068 0.6803950 #>  [8] 0.6546923 0.6299605 0.6061630 0.5832645 # Example: plot a survival function with 2 different sets of time values # to demonstrate plot precision corresponding to input parameters. fr <- tibble::tibble(duration=c(3,3,1),rate=c(.2,.1,.005)) Time <- seq(0,10,10/pi) Survival <-  ppwe(Time,fr) plot(Time,Survival,type=\"l\",ylim=c(0,1)) Time <- seq(0,10,.25) Survival <-  ppwe(Time,fr) lines(Time,Survival,col=2)"},{"path":"https://merck.github.io/gsDesign2/reference/s2pwe.html","id":null,"dir":"Reference","previous_headings":"","what":"Approximate survival distribution with piecewise exponential distribution — s2pwe","title":"Approximate survival distribution with piecewise exponential distribution — s2pwe","text":"s2pwe converts discrete set points arbitrary survival distribution piecewise exponential approximation","code":""},{"path":"https://merck.github.io/gsDesign2/reference/s2pwe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Approximate survival distribution with piecewise exponential distribution — s2pwe","text":"","code":"s2pwe(times, survival)"},{"path":"https://merck.github.io/gsDesign2/reference/s2pwe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Approximate survival distribution with piecewise exponential distribution — s2pwe","text":"times Positive increasing times survival distribution provided. survival Survival (1 - cumulative distribution function) specified times","code":""},{"path":"https://merck.github.io/gsDesign2/reference/s2pwe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Approximate survival distribution with piecewise exponential distribution — s2pwe","text":"tibble containing duration rate.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/s2pwe.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Approximate survival distribution with piecewise exponential distribution — s2pwe","text":"contents section shown PDF user manual .#' @return tibble duration 'rate'","code":""},{"path":"https://merck.github.io/gsDesign2/reference/s2pwe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Approximate survival distribution with piecewise exponential distribution — s2pwe","text":"","code":"# Example: arbitrary numbers s2pwe(1:9, (9:1)/10) #> # A tibble: 9 × 2 #>   duration  rate #>      <dbl> <dbl> #> 1        1 0.105 #> 2        1 0.118 #> 3        1 0.134 #> 4        1 0.154 #> 5        1 0.182 #> 6        1 0.223 #> 7        1 0.288 #> 8        1 0.405 #> 9        1 0.693 # Example: lognormal s2pwe(c(1:6,9), plnorm(c(1:6,9),meanlog = 0, sdlog = 2,lower.tail = FALSE)) #> # A tibble: 7 × 2 #>   duration  rate #>      <dbl> <dbl> #> 1        1 0.693 #> 2        1 0.316 #> 3        1 0.224 #> 4        1 0.177 #> 5        1 0.148 #> 6        1 0.128 #> 7        3 0.103"},{"path":"https://merck.github.io/gsDesign2/reference/summary.fixed_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary for fixed design objects — summary.fixed_design","title":"Summary for fixed design objects — summary.fixed_design","text":"Summary fixed_design() objects","code":""},{"path":"https://merck.github.io/gsDesign2/reference/summary.fixed_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary for fixed design objects — summary.fixed_design","text":"","code":"# S3 method for fixed_design summary(object, ...)"},{"path":"https://merck.github.io/gsDesign2/reference/summary.fixed_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary for fixed design objects — summary.fixed_design","text":"object fixed design object returned fixed_design() ... Additional arguments","code":""},{"path":"https://merck.github.io/gsDesign2/reference/summary.fixed_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary for fixed design objects — summary.fixed_design","text":"data frame","code":""},{"path":"https://merck.github.io/gsDesign2/reference/summary.fixed_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary for fixed design objects — summary.fixed_design","text":"","code":"library(dplyr)  # Enrollment rate enrollRates <- tibble::tibble(   Stratum = \"All\",   duration = 18,   rate = 20)  # Failure rates failRates <- tibble::tibble(   Stratum = \"All\",   duration = c(4, 100),   failRate = log(2) / 12,   hr = c(1, .6),   dropoutRate = .001)  # Study duration in months studyDuration <- 36  # Experimental / Control randomization ratio ratio <- 1  # 1-sided Type I error alpha <- 0.025 # Type II error (1 - power) beta <- 0.1  # ------------------------- # #        AHR                # # ------------------------- # # under fixed power fixed_design(   x = \"AHR\",   alpha = alpha,   power = 1 - beta,   enrollRates = enrollRates,   failRates = failRates,   studyDuration = studyDuration,   ratio = ratio   ) %>% summary() #> # A tibble: 1 × 7 #>   Design                   N Events  Time Bound alpha Power #>   <chr>                <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Average hazard ratio  463.   325.    36  1.96 0.025   0.9  # ------------------------- # #        FH                 # # ------------------------- # # under fixed power fixed_design(   x = \"FH\",   alpha = alpha,   power = 1 - beta,   enrollRates = enrollRates,   failRates = failRates,   studyDuration = studyDuration,    ratio = ratio   ) %>% summary() #> # A tibble: 1 × 7 #>   Design                            N Events  Time Bound alpha Power #>   <chr>                         <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl> #> 1 Fleming-Harrington FH(0, 0.5)  356.   249.    36  1.96 0.025   0.9"},{"path":"https://merck.github.io/gsDesign2/reference/summary.gs_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a table summarizing the bounds in the group sequential design — summary.gs_design","title":"Generate a table summarizing the bounds in the group sequential design — summary.gs_design","text":"Generate table summarizing bounds group sequential design generated gs_design_ahr(), gs_design_wlr(), gs_design_combo().","code":""},{"path":"https://merck.github.io/gsDesign2/reference/summary.gs_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a table summarizing the bounds in the group sequential design — summary.gs_design","text":"","code":"# S3 method for gs_design summary(   object,   analysis_vars = NULL,   analysis_decimals = NULL,   col_vars = NULL,   col_decimals = NULL,   bound_names = c(\"Efficacy\", \"Futility\"),   ... )"},{"path":"https://merck.github.io/gsDesign2/reference/summary.gs_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a table summarizing the bounds in the group sequential design — summary.gs_design","text":"object object returned gs_design_ahr(), gs_design_wlr(), gs_design_combo() analysis_vars variables put summary header analysis analysis_decimals displayed number digits analysis_vars col_vars variables displayed col_decimals decimals displayed displayed variables col_vars bound_names Names bounds; default c(\"Efficacy\", \"Futility\"). ... Additional arguments","code":""},{"path":"https://merck.github.io/gsDesign2/reference/summary.gs_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a table summarizing the bounds in the group sequential design — summary.gs_design","text":"summary table","code":""},{"path":"https://merck.github.io/gsDesign2/reference/summary.gs_design.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a table summarizing the bounds in the group sequential design — summary.gs_design","text":"","code":"# ---------------------------- # #     design parameters        # # ---------------------------- # library(tibble) library(gsDesign) library(gsDesign2) library(dplyr)  # enrollment/failure rates enrollRates <- tibble(Stratum = \"All\",                       duration = 12,                       rate = 1) failRates <- tibble(Stratum = \"All\", duration = c(4, 100),                     failRate = log(2) / 12,                     hr = c(1, .6),                      dropoutRate = .001)  # Information fraction IF <- (1:3)/3  # Analysis times in months; first 2 will be ignored as IF will not be achieved analysisTimes <- c(.01, .02, 36)  # Experimental / Control randomization ratio ratio <- 1  # 1-sided Type I error alpha <- 0.025  # Type II error (1 - power) beta <- .1  # Upper bound upper <- gs_spending_bound upar <- list(sf = gsDesign::sfLDOF, total_spend = 0.025, param = NULL, timing = NULL)  # Lower bound lower <- gs_spending_bound lpar <- list(sf = gsDesign::sfHSD, total_spend = 0.1, param = 0, timing = NULL)  # weight function in WLR wgt00 <- function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)} wgt05 <- function(x, arm0, arm1){wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = .5)}  # test in COMBO fh_test <- rbind(   data.frame(rho = 0, gamma = 0, tau = -1, test = 1, Analysis = 1:3,analysisTimes = c(12, 24, 36)),   data.frame(rho = c(0, 0.5), gamma = 0.5, tau = -1, test = 2:3, Analysis = 3, analysisTimes = 36) )  # ---------------------------- # #          ahr                 # # ---------------------------- # x_ahr <- gs_design_ahr(   enrollRates = enrollRates,   failRates = failRates,   IF = IF, # Information fraction   analysisTimes = analysisTimes,   ratio = ratio,   alpha = alpha,   beta = beta,   upper = upper,   upar = upar,   lower = lower,   lpar = lpar)  x_ahr %>% summary() #> # A tibble: 6 × 7 #> # Groups:   Analysis [3] #>   Analysis                           Bound     Z ~HR a…¹ Nomin…² Alter…³ Null …⁴ #>   <chr>                              <chr> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1 Analysis: 1 Time: 11.7 N: 479.6 E… Futi… -0.94   1.19   0.826   0.0338  0      #> 2 Analysis: 1 Time: 11.7 N: 479.6 E… Effi…  3.71   0.510  0.0001  0.0027  0.0001 #> 3 Analysis: 2 Time: 20.3 N: 493.1 E… Futi…  0.63   0.923  0.266   0.0666  0      #> 4 Analysis: 2 Time: 20.3 N: 493.1 E… Effi…  2.51   0.725  0.006   0.414   0.0061 #> 5 Analysis: 3 Time: 36 N: 493.1 Eve… Futi…  1.99   0.812  0.0233  0.101   0      #> 6 Analysis: 3 Time: 36 N: 493.1 Eve… Effi…  1.99   0.812  0.0231  0.9     0.0251 #> # … with abbreviated variable names ¹​`~HR at bound`, ²​`Nominal p`, #> #   ³​`Alternate hypothesis`, ⁴​`Null hypothesis` x_ahr %>% summary(analysis_vars = c(\"Time\", \"Events\", \"IF\"), analysis_decimals = c(1, 0, 2)) #> # A tibble: 6 × 7 #> # Groups:   Analysis [3] #>   Analysis                           Bound     Z ~HR a…¹ Nomin…² Alter…³ Null …⁴ #>   <chr>                              <chr> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1 Analysis: 1 Time: 11.7 Events: 12… Futi… -0.94   1.19   0.826   0.0338  0      #> 2 Analysis: 1 Time: 11.7 Events: 12… Effi…  3.71   0.510  0.0001  0.0027  0.0001 #> 3 Analysis: 2 Time: 20.3 Events: 24… Futi…  0.63   0.923  0.266   0.0666  0      #> 4 Analysis: 2 Time: 20.3 Events: 24… Effi…  2.51   0.725  0.006   0.414   0.0061 #> 5 Analysis: 3 Time: 36 Events: 365 … Futi…  1.99   0.812  0.0233  0.101   0      #> 6 Analysis: 3 Time: 36 Events: 365 … Effi…  1.99   0.812  0.0231  0.9     0.0251 #> # … with abbreviated variable names ¹​`~HR at bound`, ²​`Nominal p`, #> #   ³​`Alternate hypothesis`, ⁴​`Null hypothesis` x_ahr %>% summary(bound_names = c(\"A is better\", \"B is better\")) #> # A tibble: 6 × 7 #> # Groups:   Analysis [3] #>   Analysis                           Bound     Z ~HR a…¹ Nomin…² Alter…³ Null …⁴ #>   <chr>                              <chr> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1 Analysis: 1 Time: 11.7 N: 479.6 E… B is… -0.94   1.19   0.826   0.0338  0      #> 2 Analysis: 1 Time: 11.7 N: 479.6 E… A is…  3.71   0.510  0.0001  0.0027  0.0001 #> 3 Analysis: 2 Time: 20.3 N: 493.1 E… B is…  0.63   0.923  0.266   0.0666  0      #> 4 Analysis: 2 Time: 20.3 N: 493.1 E… A is…  2.51   0.725  0.006   0.414   0.0061 #> 5 Analysis: 3 Time: 36 N: 493.1 Eve… B is…  1.99   0.812  0.0233  0.101   0      #> 6 Analysis: 3 Time: 36 N: 493.1 Eve… A is…  1.99   0.812  0.0231  0.9     0.0251 #> # … with abbreviated variable names ¹​`~HR at bound`, ²​`Nominal p`, #> #   ³​`Alternate hypothesis`, ⁴​`Null hypothesis`  # ---------------------------- # #         wlr                  # # ---------------------------- # x_wlr <- gs_design_wlr(   enrollRates = enrollRates,   failRates = failRates,   weight = wgt05,   IF = NULL,   analysisTimes = sort(unique(x_ahr$analysis$Time)),   ratio = ratio,   alpha = alpha,   beta = beta,   upper = upper,   upar = upar,   lower = lower,   lpar = lpar ) x_wlr %>% summary() #> # A tibble: 6 × 7 #> # Groups:   Analysis [3] #>   Analysis                           Bound     Z ~wHR …¹ Nomin…² Alter…³ Null …⁴ #>   <chr>                              <chr> <dbl>   <dbl>   <dbl>   <dbl>   <dbl> #> 1 Analysis: 1 Time: 11.7 N: 361.4 E… Futi… -1.17   1.28   0.879   0.0141  0      #> 2 Analysis: 1 Time: 11.7 N: 361.4 E… Effi…  6.02   0.284  0       0       0      #> 3 Analysis: 2 Time: 20.3 N: 371.6 E… Futi…  0.57   0.919  0.283   0.0464  0      #> 4 Analysis: 2 Time: 20.3 N: 371.6 E… Effi…  3.16   0.627  0.0008  0.214   0.0008 #> 5 Analysis: 3 Time: 36 N: 371.6 Eve… Futi…  1.96   0.789  0.0247  0.100   0      #> 6 Analysis: 3 Time: 36 N: 371.6 Eve… Effi…  1.96   0.789  0.0247  0.9     0.025  #> # … with abbreviated variable names ¹​`~wHR at bound`, ²​`Nominal p`, #> #   ³​`Alternate hypothesis`, ⁴​`Null hypothesis`  # ---------------------------- # #         max combo            # # ---------------------------- # x_combo <- gs_design_combo(   ratio = 1,   alpha = 0.025,   beta = 0.2,   enrollRates = tibble::tibble(Stratum = \"All\", duration = 12, rate = 500/12),   failRates = tibble::tibble(Stratum = \"All\", duration = c(4, 100),                              failRate = log(2) / 15, hr = c(1, .6), dropoutRate = .001),   fh_test = fh_test,   upper = gs_spending_combo,   upar = list(sf = gsDesign::sfLDOF, total_spend = 0.025),   lower = gs_spending_combo,   lpar = list(sf = gsDesign::sfLDOF, total_spend = 0.2)) #> The AHR reported in the `analysis` table is under the log-rank test. x_combo %>% summary() #> # A tibble: 6 × 6 #> # Groups:   Analysis [3] #>   Analysis                                   Bound     Z Nomin…¹ Alter…² Null …³ #>   <chr>                                      <chr> <dbl>   <dbl>   <dbl>   <dbl> #> 1 Analysis: 1 Time: 12 N: 301.4 Events: 64.… Futi… -2.72  0.997   0.0003  0      #> 2 Analysis: 1 Time: 12 N: 301.4 Events: 64.… Effi…  6.18  0       0       0      #> 3 Analysis: 2 Time: 24 N: 301.4 Events: 148… Futi…  0.65  0.257   0.0847  0      #> 4 Analysis: 2 Time: 24 N: 301.4 Events: 148… Effi…  2.8   0.0026  0.220   0.0026 #> 5 Analysis: 3 Time: 36 N: 301.4 Events: 199… Futi…  2.1   0.018   0.2     0      #> 6 Analysis: 3 Time: 36 N: 301.4 Events: 199… Effi…  2.1   0.018   0.8     0.025  #> # … with abbreviated variable names ¹​`Nominal p`, ²​`Alternate hypothesis`, #> #   ³​`Null hypothesis`  # ---------------------------- # #      risk difference         # # ---------------------------- # gs_design_rd(   p_c = tibble(Stratum = \"All\", Rate = .2),   p_e = tibble(Stratum = \"All\", Rate = .15),   IF = c(0.7, 1),   rd0 = 0,   alpha = .025,   beta = .1,   ratio = 1,   stratum_prev = NULL,   weight = \"un-stratified\",   upper = gs_b,   lower = gs_b,   upar = gsDesign::gsDesign(k = 3, test.type = 1, sfu = gsDesign::sfLDOF, sfupar = NULL)$upper$bound,   lpar = c(qnorm(.1), rep(-Inf, 2)) ) %>% summary() #> # A tibble: 4 × 7 #> # Groups:   Analysis [2] #>   Analysis                       Bound       Z ~Risk d…¹ Nomin…² Alter…³ Null …⁴ #>   <chr>                          <chr>   <dbl>     <dbl>   <dbl>   <dbl>   <dbl> #> 1 Analysis: 1 N: 2335.7 risk di… Futi…   -1.28   -0.0201  0.9      0      0      #> 2 Analysis: 1 N: 2335.7 risk di… Effi…    3.71    0.0582  0.0001   0.298  0.0001 #> 3 Analysis: 2 N: 3336.7 risk di… Futi… -Inf    -Inf       1        0      0      #> 4 Analysis: 2 N: 3336.7 risk di… Effi…    2.51    0.033   0.006    0.9    0.006  #> # … with abbreviated variable names ¹​`~Risk difference at bound`, ²​`Nominal p`, #> #   ³​`Alternate hypothesis`, ⁴​`Null hypothesis`"},{"path":"https://merck.github.io/gsDesign2/reference/tEvents.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict time at which a targeted event count is achieved — tEvents","title":"Predict time at which a targeted event count is achieved — tEvents","text":"tEvents() made match input format AHR() solve time expected accumulated events equal input target. Enrollment failure rate distributions specified follows. piecewise exponential distribution allows simple method specify distribtuion enrollment pattern enrollment, failure dropout rates changes time.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/tEvents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict time at which a targeted event count is achieved — tEvents","text":"","code":"tEvents(   enrollRates = tibble::tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9)     * 5),   failRates = tibble::tibble(Stratum = \"All\", duration = c(3, 100), failRate =     log(2)/c(9, 18), hr = c(0.9, 0.6), dropoutRate = rep(0.001, 2)),   targetEvents = 150,   ratio = 1,   interval = c(0.01, 100) )"},{"path":"https://merck.github.io/gsDesign2/reference/tEvents.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict time at which a targeted event count is achieved — tEvents","text":"enrollRates Piecewise constant enrollment rates stratum time period. failRates Piecewise constant control group failure rates, duration piecewise constant period, hazard ratio experimental vs control, dropout rates stratum time period. targetEvents targeted number events achieved. ratio Experimental:Control randomization ratio. interval interval presumed include time expected event count equal targetEvents.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/tEvents.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict time at which a targeted event count is achieved — tEvents","text":"tibble Time (computed match events targetEvents), AHR (average hazard ratio), Events (targetEvents input), info (information given scenarios), info0 (information related null hypothesis) value totalDuration input;","code":""},{"path":[]},{"path":"https://merck.github.io/gsDesign2/reference/tEvents.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict time at which a targeted event count is achieved — tEvents","text":"","code":"# ------------------------#  #      Example 1          # # ------------------------# # default tEvents() #> # A tibble: 1 × 5 #>    Time   AHR Events  info info0 #>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1  14.9 0.787   150.  36.9  37.5  # ------------------------#  #      Example 2          # # ------------------------# # check that result matches a finding using AHR() # Start by deriving an expected event count enrollRates <- tibble::tibble(Stratum = \"All\", duration = c(2, 2, 10), rate = c(3, 6, 9) * 5) failRates <- tibble::tibble(Stratum = \"All\", duration = c(3, 100), failRate = log(2) / c(9, 18),                              hr = c(.9,.6), dropoutRate = rep(.001, 2)) totalDuration <- 20 xx <- AHR(enrollRates, failRates, totalDuration) xx #> # A tibble: 1 × 5 #>    Time   AHR Events  info info0 #>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1    20 0.738   208.  51.0  52.1  # Next we check that the function confirms the timing of the final analysis. tEvents(enrollRates, failRates,          targetEvents = xx$Events, interval = c(.5, 1.5) * xx$Time) #> # A tibble: 1 × 5 #>    Time   AHR Events  info info0 #>   <dbl> <dbl>  <dbl> <dbl> <dbl> #> 1  20.0 0.738   208.  51.0  52.1"},{"path":"https://merck.github.io/gsDesign2/reference/wlr_weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Weight Function of Weighted Log-rank Test — wlr_weight","title":"Weight Function of Weighted Log-rank Test — wlr_weight","text":"wlr_weight_fh Fleming-Harriongton, FH(rho, gamma) weight function. wlr_weight_1  constant log rank test wlr_weight_power Gehan-Breslow Tarone-Ware weight function.","code":""},{"path":"https://merck.github.io/gsDesign2/reference/wlr_weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weight Function of Weighted Log-rank Test — wlr_weight","text":"","code":"wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0, tau = NULL)  wlr_weight_1(x, arm0, arm1)  wlr_weight_n(x, arm0, arm1, power = 1)"},{"path":"https://merck.github.io/gsDesign2/reference/wlr_weight.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weight Function of Weighted Log-rank Test — wlr_weight","text":"x analysis time arm0 \"arm\" object defined npsurvSS package arm1 \"arm\" object defined npsurvSS package rho scalar parameter controls type test gamma scalar parameter controls type test tau scalar parameter cut-time modest weighted log rank test power scalar parameter controls power weight function","code":""},{"path":"https://merck.github.io/gsDesign2/reference/wlr_weight.html","id":"specification","dir":"Reference","previous_headings":"","what":"Specification","title":"Weight Function of Weighted Log-rank Test — wlr_weight","text":"contents section shown PDF user manual .","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-010-may-2021","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.1.0, May, 2021","title":"gsDesign2 0.1.0, May, 2021","text":"Updated AHR vignette introduce average hazard ratio concept well Added arbitrary distribution vignette demonstrate s2pwe() function Corrected calculations AHR() using stratified population Release Regulatory/Industry Symposium training","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-0009006-december-2019","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.0.0.9006, December, 2019","title":"gsDesign2 0.0.0.9006, December, 2019","text":"Added eEvents_df() vignette explaining methods thoroughly Updated eEvents_df() simplify output simple=FALSE option","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-0009005-december-2019","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.0.0.9005, December, 2019","title":"gsDesign2 0.0.0.9005, December, 2019","text":"Updated docs directory correct reference materials web site Minor fix eAccrual","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-0009004-november-2019","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.0.0.9004, November, 2019","title":"gsDesign2 0.0.0.9004, November, 2019","text":"Moved new simulation functions simtrial package (simfix, simfix2simPWSurv, pMaxCombo).","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-0009003-november-2019","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.0.0.9003, November, 2019","title":"gsDesign2 0.0.0.9003, November, 2019","text":"Tried make AHR simfix compatible . Improved vignette group sequential design. Added web site documentation vignettes docs/index.html. Added support functions support approximation using visualization piecewise model.","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-0002-october-2019","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.0.0.2, October, 2019","title":"gsDesign2 0.0.0.2, October, 2019","text":"Update AHR() output trial duration, expected events average hazard ratio tibble. Vignette AHRvignette demonstrating sample size computations fixed design non-proportional hazards assumptions. Vignette gsNPH demonstrating sample size computations group sequential design non-proportional hazards assumptions. Initial implementation pMaxCombo() compute p-value MaxCombo test; pMaxComboVignette demonstrates capability.","code":""},{"path":"https://merck.github.io/gsDesign2/news/index.html","id":"gsdesign2-0001-september-2019","dir":"Changelog","previous_headings":"","what":"gsDesign2 0.0.0.1, September, 2019","title":"gsDesign2 0.0.0.1, September, 2019","text":"Computations based piecewise constant enrollment piecewise exponential failure rate Expected event count calculation different hazard ratios eEvents_df() Average hazard ratio computation based expected event counts AHR() Vignette demonstrating fixed sample size computation simulation verify power","code":""}]
